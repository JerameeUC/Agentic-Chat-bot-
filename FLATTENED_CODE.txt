# Flattened code dump for: C:\Users\User\Agentic-Chat-bot-\n# Files included: 67\n\n\n================================================================================\nBEGIN FILE: agenticcore\__init__.py\n================================================================================\n\n# package
\n================================================================================\nEND FILE: agenticcore\__init__.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\chatbot\__init__.py\n================================================================================\n\n# package
\n================================================================================\nEND FILE: agenticcore\chatbot\__init__.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\chatbot\services.py\n================================================================================\n\n# /agenticcore/chatbot/services.py
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from typing import Dict

# Delegate sentiment to the unified provider layer
# If you put providers_unified.py under agenticcore/chatbot/, change the import to:
#   from agenticcore.chatbot.providers_unified import analyze_sentiment
from agenticcore.providers_unified import analyze_sentiment
from ..providers_unified import analyze_sentiment


def _trim(s: str, max_len: int = 2000) -> str:
    s = (s or "").strip()
    return s if len(s) <= max_len else s[: max_len - 1] + "â€¦"


@dataclass(frozen=True)
class SentimentResult:
    label: str          # "positive" | "neutral" | "negative" | "mixed" | "unknown"
    confidence: float   # 0.0 .. 1.0


class ChatBot:
    """
    Minimal chatbot that uses provider-agnostic sentiment via providers_unified.
    Public API:
      - reply(text: str) -> Dict[str, object]
      - capabilities() -> Dict[str, object]
    """

    def __init__(self, system_prompt: str = "You are a concise helper.") -> None:
        self._system_prompt = _trim(system_prompt, 800)
        # Expose which provider is intended/active (for diagnostics)
        self._mode = os.getenv("AI_PROVIDER") or "auto"

    def capabilities(self) -> Dict[str, object]:
        """List what this bot can do."""
        return {
            "system": "chatbot",
            "mode": self._mode,  # "auto" or a pinned provider (hf/azure/openai/cohere/deepai/offline)
            "features": ["text-input", "sentiment-analysis", "help"],
            "commands": {"help": "Describe capabilities and usage."},
        }

    def reply(self, text: str) -> Dict[str, object]:
        """Produce a reply and sentiment for one user message."""
        user = _trim(text)
        if not user:
            return self._make_response(
                "I didn't catch that. Please provide some text.",
                SentimentResult("unknown", 0.0),
            )

        if user.lower() in {"help", "/help"}:
            return {"reply": self._format_help(), "capabilities": self.capabilities()}

        s = analyze_sentiment(user)  # -> {"provider", "label", "score", ...}
        sr = SentimentResult(label=str(s.get("label", "neutral")), confidence=float(s.get("score", 0.5)))
        return self._make_response(self._compose(sr), sr)

    # ---- internals ----

    def _format_help(self) -> str:
        caps = self.capabilities()
        feats = ", ".join(caps["features"])
        return f"I can analyze sentiment and respond concisely. Features: {feats}. Send any text or type 'help'."

    @staticmethod
    def _make_response(reply: str, s: SentimentResult) -> Dict[str, object]:
        return {"reply": reply, "sentiment": s.label, "confidence": round(float(s.confidence), 2)}

    @staticmethod
    def _compose(s: SentimentResult) -> str:
        if s.label == "positive":
            return "Thanks for sharing. I detected a positive sentiment."
        if s.label == "negative":
            return "I hear your concern. I detected a negative sentiment."
        if s.label == "neutral":
            return "Noted. The sentiment appears neutral."
        if s.label == "mixed":
            return "Your message has mixed signals. Can you clarify?"
        return "I could not determine the sentiment. Please rephrase."


# Optional: local REPL for quick manual testing
def _interactive_loop() -> None:
    bot = ChatBot()
    try:
        while True:
            msg = input("> ").strip()
            if msg.lower() in {"exit", "quit"}:
                break
            print(json.dumps(bot.reply(msg), ensure_ascii=False))
    except (EOFError, KeyboardInterrupt):
        pass


if __name__ == "__main__":
    _interactive_loop()
\n================================================================================\nEND FILE: agenticcore\chatbot\services.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\cli.py\n================================================================================\n\n# /agenticcore/cli.py
"""
agenticcore.cli
Console entrypoints:
  - agentic: send a message to ChatBot and print reply JSON
  - repo-tree: print a filtered tree view (uses tree.txt if present)
  - repo-flatten: flatten code listing to stdout (uses FLATTENED_CODE.txt if present)
"""
import argparse, json, sys, traceback
from pathlib import Path
from dotenv import load_dotenv
import os

# Load .env variables into os.environ (project root .env by default)
load_dotenv()


def cmd_agentic(argv=None):
    # Lazy import so other commands don't require ChatBot to be importable
    from agenticcore.chatbot.services import ChatBot
    # We call analyze_sentiment only for 'status' to reveal the actual chosen provider
    try:
        from agenticcore.providers_unified import analyze_sentiment
    except Exception:
        analyze_sentiment = None  # still fine; we'll show mode only

    p = argparse.ArgumentParser(prog="agentic", description="Chat with AgenticCore ChatBot")
    p.add_argument("message", nargs="*", help="Message to send")
    p.add_argument("--debug", action="store_true", help="Print debug info")
    args = p.parse_args(argv)
    msg = " ".join(args.message).strip() or "hello"

    if args.debug:
        print(f"DEBUG argv={sys.argv}", flush=True)
        print(f"DEBUG raw message='{msg}'", flush=True)

    bot = ChatBot()

    # Special commands for testing / assignments
        # Special commands for testing / assignments
    if msg.lower() == "status":
        import requests  # local import to avoid hard dep for other commands

        # Try a lightweight provider probe via analyze_sentiment
        provider = None
        if analyze_sentiment is not None:
            try:
                probe = analyze_sentiment("status ping")
                provider = (probe or {}).get("provider")
            except Exception:
                if args.debug:
                    traceback.print_exc()

        # Hugging Face whoami auth probe
        tok = os.getenv("HF_API_KEY", "")
        who = None
        auth_ok = False
        err = None
        try:
            if tok:
                r = requests.get(
                    "https://huggingface.co/api/whoami-v2",
                    headers={"Authorization": f"Bearer {tok}"},
                    timeout=15,
                )
                auth_ok = (r.status_code == 200)
                who = r.json() if auth_ok else None
                if not auth_ok:
                    err = r.text  # e.g., {"error":"Invalid credentials in Authorization header"}
            else:
                err = "HF_API_KEY not set (load .env or export it)"
        except Exception as e:
            err = str(e)

        # Extract fine-grained scopes for visibility
        fg = (((who or {}).get("auth") or {}).get("accessToken") or {}).get("fineGrained") or {}
        scoped = fg.get("scoped") or []
        global_scopes = fg.get("global") or []

        # ---- tiny inference ping (proves 'Make calls to Inference Providers') ----
        infer_ok, infer_err = False, None
        try:
            if tok:
                model = os.getenv(
                    "HF_MODEL_SENTIMENT",
                    "distilbert-base-uncased-finetuned-sst-2-english"
                )
                r2 = requests.post(
                    f"https://api-inference.huggingface.co/models/{model}",
                    headers={"Authorization": f"Bearer {tok}", "x-wait-for-model": "true"},
                    json={"inputs": "ping"},
                    timeout=int(os.getenv("HTTP_TIMEOUT", "60")),
                )
                infer_ok = (r2.status_code == 200)
                if not infer_ok:
                    infer_err = f"HTTP {r2.status_code}: {r2.text}"
        except Exception as e:
            infer_err = str(e)
        # -------------------------------------------------------------------------

        # Mask + length to verify what .env provided
        mask = (tok[:3] + "..." + tok[-4:]) if tok else None
        out = {
            "provider": provider or "unknown",
            "mode": getattr(bot, "_mode", "auto"),
            "auth_ok": auth_ok,
            "whoami": who,
            "token_scopes": {            # <--- added
                "global": global_scopes,
                "scoped": scoped,
            },
            "inference_ok": infer_ok,
            "inference_error": infer_err,
            "env": {
                "HF_API_KEY_len": len(tok) if tok else 0,
                "HF_API_KEY_mask": mask,
                "HF_MODEL_SENTIMENT": os.getenv("HF_MODEL_SENTIMENT"),
                "HTTP_TIMEOUT": os.getenv("HTTP_TIMEOUT"),
            },
            "capabilities": bot.capabilities(),
            "error": err,
        }

    elif msg.lower() == "help":
        out = {"capabilities": bot.capabilities()}

    else:
        try:
            out = bot.reply(msg)
        except Exception as e:
            if args.debug:
                traceback.print_exc()
            out = {"error": str(e), "message": msg}

    if args.debug:
        print(f"DEBUG out={out}", flush=True)

    print(json.dumps(out, indent=2), flush=True)


def cmd_repo_tree(argv=None):
    p = argparse.ArgumentParser(prog="repo-tree", description="Print repo tree (from tree.txt if available)")
    p.add_argument("--path", default="tree.txt", help="Path to precomputed tree file")
    args = p.parse_args(argv)
    path = Path(args.path)
    if path.exists():
        print(path.read_text(encoding="utf-8"), flush=True)
    else:
        print("(no tree.txt found)", flush=True)


def cmd_repo_flatten(argv=None):
    p = argparse.ArgumentParser(prog="repo-flatten", description="Print flattened code listing")
    p.add_argument("--path", default="FLATTENED_CODE.txt", help="Path to pre-flattened code file")
    args = p.parse_args(argv)
    path = Path(args.path)
    if path.exists():
        print(path.read_text(encoding="utf-8"), flush=True)
    else:
        print("(no FLATTENED_CODE.txt found)", flush=True)


def _dispatch():
    # Allow: python -m agenticcore.cli <subcommand> [args...]
    if len(sys.argv) <= 1:
        print("Usage: python -m agenticcore.cli <agentic|repo-tree|repo-flatten> [args]", file=sys.stderr)
        sys.exit(2)
    cmd, argv = sys.argv[1], sys.argv[2:]
    try:
        if cmd == "agentic":
            cmd_agentic(argv)
        elif cmd == "repo-tree":
            cmd_repo_tree(argv)
        elif cmd == "repo-flatten":
            cmd_repo_flatten(argv)
        else:
            print(f"Unknown subcommand: {cmd}", file=sys.stderr)
            sys.exit(2)
    except SystemExit:
        raise
    except Exception:
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    _dispatch()
\n================================================================================\nEND FILE: agenticcore\cli.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\providers_unified.py\n================================================================================\n\n# /agenticcore/providers_unified.py
"""
providers_unified.py
Unified, switchable providers for sentiment + (optional) text generation.
Selection order unless AI_PROVIDER is set:
  HF -> AZURE -> OPENAI -> COHERE -> DEEPAI -> OFFLINE
Env vars:
  HF_API_KEY
  MICROSOFT_AI_SERVICE_ENDPOINT, MICROSOFT_AI_API_KEY
  OPENAI_API_KEY,  OPENAI_MODEL=gpt-3.5-turbo
  COHERE_API_KEY,  COHERE_MODEL=command
  DEEPAI_API_KEY
  AI_PROVIDER = hf|azure|openai|cohere|deepai|offline
  HTTP_TIMEOUT = 20
"""
from __future__ import annotations
import os, json
from typing import Dict, Any, Optional
import requests

TIMEOUT = float(os.getenv("HTTP_TIMEOUT", "20"))

def _env(name: str, default: Optional[str] = None) -> Optional[str]:
    v = os.getenv(name)
    return v if (v is not None and str(v).strip() != "") else default

def _pick_provider() -> str:
    forced = _env("AI_PROVIDER")
    if forced in {"hf", "azure", "openai", "cohere", "deepai", "offline"}:
        return forced
    if _env("HF_API_KEY"): return "hf"
    if _env("MICROSOFT_AI_API_KEY") and _env("MICROSOFT_AI_SERVICE_ENDPOINT"): return "azure"
    if _env("OPENAI_API_KEY"): return "openai"
    if _env("COHERE_API_KEY"): return "cohere"
    if _env("DEEPAI_API_KEY"): return "deepai"
    return "offline"

# ---------------------------
# Sentiment
# ---------------------------

def analyze_sentiment(text: str) -> Dict[str, Any]:
    provider = _pick_provider()
    try:
        if provider == "hf":     return _sentiment_hf(text)
        if provider == "azure":  return _sentiment_azure(text)
        if provider == "openai": return _sentiment_openai_prompt(text)
        if provider == "cohere": return _sentiment_cohere_prompt(text)
        if provider == "deepai": return _sentiment_deepai(text)
        return _sentiment_offline(text)
    except Exception as e:
        return {"provider": provider, "label": "neutral", "score": 0.5, "error": str(e)}

def _sentiment_offline(text: str) -> Dict[str, Any]:
    t = (text or "").lower()
    pos = any(w in t for w in ["love","great","good","awesome","fantastic","thank","excellent","amazing"])
    neg = any(w in t for w in ["hate","bad","terrible","awful","worst","angry","horrible"])
    label = "positive" if pos and not neg else "negative" if neg and not pos else "neutral"
    score = 0.9 if label != "neutral" else 0.5
    return {"provider": "offline", "label": label, "score": score}

def _sentiment_hf(text: str) -> Dict[str, Any]:
    """
    Hugging Face Inference API for sentiment.
    Uses canonical repo id and handles 404/401 and various payload shapes.
    """
    key = _env("HF_API_KEY")
    if not key:
        return _sentiment_offline(text)

    # canonical repo id to avoid 404
    model = _env("HF_MODEL_SENTIMENT", "distilbert/distilbert-base-uncased-finetuned-sst-2-english")
    timeout = int(_env("HTTP_TIMEOUT", "30"))

    headers = {
        "Authorization": f"Bearer {key}",
        "x-wait-for-model": "true",
        "Accept": "application/json",
        "Content-Type": "application/json",
    }

    r = requests.post(
        f"https://api-inference.huggingface.co/models/{model}",
        headers=headers,
        json={"inputs": text},
        timeout=timeout,
    )

    if r.status_code != 200:
        return {"provider": "hf", "label": "neutral", "score": 0.5, "error": f"HTTP {r.status_code}: {r.text[:500]}"}

    try:
        data = r.json()
    except Exception as e:
        return {"provider": "hf", "label": "neutral", "score": 0.5, "error": str(e)}

    if isinstance(data, dict) and "error" in data:
        return {"provider": "hf", "label": "neutral", "score": 0.5, "error": data["error"]}

    # normalize list shape
    arr = data[0] if isinstance(data, list) and data and isinstance(data[0], list) else (data if isinstance(data, list) else [])
    if not (isinstance(arr, list) and arr):
        return {"provider": "hf", "label": "neutral", "score": 0.5, "error": f"Unexpected payload: {data}"}

    top = max(arr, key=lambda x: x.get("score", 0.0) if isinstance(x, dict) else 0.0)
    raw = str(top.get("label", "")).upper()
    score = float(top.get("score", 0.5))

    mapping = {
        "LABEL_0": "negative", "LABEL_1": "neutral", "LABEL_2": "positive",
        "NEGATIVE": "negative", "NEUTRAL": "neutral", "POSITIVE": "positive",
    }
    label = mapping.get(raw, (raw.lower() or "neutral"))

    neutral_floor = float(os.getenv("SENTIMENT_NEUTRAL_THRESHOLD", "0.65"))
    if label in {"positive", "negative"} and score < neutral_floor:
        label = "neutral"

    return {"provider": "hf", "label": label, "score": score}

def _sentiment_azure(text: str) -> Dict[str, Any]:
    try:
        from azure.core.credentials import AzureKeyCredential  # type: ignore
        from azure.ai.textanalytics import TextAnalyticsClient  # type: ignore
    except Exception:
        return _sentiment_offline(text)
    endpoint = _env("MICROSOFT_AI_SERVICE_ENDPOINT")
    key = _env("MICROSOFT_AI_API_KEY")
    if not (endpoint and key): return _sentiment_offline(text)
    client = TextAnalyticsClient(endpoint=endpoint.strip(), credential=AzureKeyCredential(key.strip()))
    resp = client.analyze_sentiment(documents=[text], show_opinion_mining=False)[0]
    scores = {
        "positive": float(getattr(resp.confidence_scores, "positive", 0.0) or 0.0),
        "neutral":  float(getattr(resp.confidence_scores, "neutral",  0.0) or 0.0),
        "negative": float(getattr(resp.confidence_scores, "negative", 0.0) or 0.0),
    }
    label = max(scores, key=scores.get)
    return {"provider": "azure", "label": label, "score": scores[label]}

def _sentiment_openai_prompt(text: str) -> Dict[str, Any]:
    key = _env("OPENAI_API_KEY")
    model = _env("OPENAI_MODEL", "gpt-3.5-turbo")
    if not key: return _sentiment_offline(text)
    url = "https://api.openai.com/v1/chat/completions"
    prompt = f"Classify the sentiment of this text as positive, negative, or neutral. Reply JSON with keys label and score (0..1). Text: {text!r}"
    r = requests.post(
        url,
        headers={"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        json={"model": model, "messages": [{"role": "user", "content": prompt}], "temperature": 0},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    content = r.json()["choices"][0]["message"]["content"]
    try:
        obj = json.loads(content)
        label = str(obj.get("label", "neutral")).lower()
        score = float(obj.get("score", 0.5))
        return {"provider": "openai", "label": label, "score": score}
    except Exception:
        l = "positive" if "positive" in content.lower() else "negative" if "negative" in content.lower() else "neutral"
        return {"provider": "openai", "label": l, "score": 0.5}

def _sentiment_cohere_prompt(text: str) -> Dict[str, Any]:
    key = _env("COHERE_API_KEY")
    model = _env("COHERE_MODEL", "command")
    if not key: return _sentiment_offline(text)
    url = "https://api.cohere.ai/v1/generate"
    prompt = f"Classify the sentiment (positive, negative, neutral) and return JSON with keys label and score (0..1). Text: {text!r}"
    r = requests.post(
        url,
        headers={
            "Authorization": f"Bearer {key}",
            "Content-Type": "application/json",
            "Cohere-Version": "2022-12-06",
        },
        json={"model": model, "prompt": prompt, "max_tokens": 30, "temperature": 0},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    gen = (r.json().get("generations") or [{}])[0].get("text", "")
    try:
        obj = json.loads(gen)
        label = str(obj.get("label", "neutral")).lower()
        score = float(obj.get("score", 0.5))
        return {"provider": "cohere", "label": label, "score": score}
    except Exception:
        l = "positive" if "positive" in gen.lower() else "negative" if "negative" in gen.lower() else "neutral"
        return {"provider": "cohere", "label": l, "score": 0.5}

def _sentiment_deepai(text: str) -> Dict[str, Any]:
    key = _env("DEEPAI_API_KEY")
    if not key: return _sentiment_offline(text)
    url = "https://api.deepai.org/api/sentiment-analysis"
    r = requests.post(url, headers={"api-key": key}, data={"text": text}, timeout=TIMEOUT)
    r.raise_for_status()
    data = r.json()
    label = (data.get("output") or ["neutral"])[0].lower()
    return {"provider": "deepai", "label": label, "score": 0.5 if label == "neutral" else 0.9}

# ---------------------------
# Text generation (optional)
# ---------------------------

def generate_text(prompt: str, max_tokens: int = 128) -> Dict[str, Any]:
    provider = _pick_provider()
    try:
        if provider == "hf":     return _gen_hf(prompt, max_tokens)
        if provider == "openai": return _gen_openai(prompt, max_tokens)
        if provider == "cohere": return _gen_cohere(prompt, max_tokens)
        if provider == "deepai": return _gen_deepai(prompt, max_tokens)
        return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    except Exception as e:
        return {"provider": provider, "text": f"(error) {str(e)}"}

def _gen_hf(prompt: str, max_tokens: int) -> Dict[str, Any]:
    key = _env("HF_API_KEY")
    if not key: return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    model = _env("HF_MODEL_GENERATION", "tiiuae/falcon-7b-instruct")
    r = requests.post(
        f"https://api-inference.huggingface.co/models/{model}",
        headers={"Authorization": f"Bearer {key}"},
        json={"inputs": prompt, "parameters": {"max_new_tokens": max_tokens}},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    data = r.json()
    if isinstance(data, list) and data and "generated_text" in data[0]:
        return {"provider": "hf", "text": data[0]["generated_text"]}
    return {"provider": "hf", "text": str(data)}

def _gen_openai(prompt: str, max_tokens: int) -> Dict[str, Any]:
    key = _env("OPENAI_API_KEY")
    model = _env("OPENAI_MODEL", "gpt-3.5-turbo")
    if not key: return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    url = "https://api.openai.com/v1/chat/completions"
    r = requests.post(
        url,
        headers={"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        json={"model": model, "messages": [{"role": "user", "content": prompt}], "max_tokens": max_tokens},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    data = r.json()
    text = data["choices"][0]["message"]["content"]
    return {"provider": "openai", "text": text}

def _gen_cohere(prompt: str, max_tokens: int) -> Dict[str, Any]:
    key = _env("COHERE_API_KEY")
    model = _env("COHERE_MODEL", "command")
    if not key: return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    url = "https://api.cohere.ai/v1/generate"
    r = requests.post(
        url,
        headers={
            "Authorization": f"Bearer {key}",
            "Content-Type": "application/json",
            "Cohere-Version": "2022-12-06",
        },
        json={"model": model, "prompt": prompt, "max_tokens": max_tokens},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    data = r.json()
    text = data.get("generations", [{}])[0].get("text", "")
    return {"provider": "cohere", "text": text}

def _gen_deepai(prompt: str, max_tokens: int) -> Dict[str, Any]:
    key = _env("DEEPAI_API_KEY")
    if not key: return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    url = "https://api.deepai.org/api/text-generator"
    r = requests.post(url, headers={"api-key": key}, data={"text": prompt}, timeout=TIMEOUT)
    r.raise_for_status()
    data = r.json()
    return {"provider": "deepai", "text": data.get("output", "")}
\n================================================================================\nEND FILE: agenticcore\providers_unified.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\web_agentic.py\n================================================================================\n\n# agenticcore/web_agentic.py
from fastapi import FastAPI, Query
from fastapi.responses import HTMLResponse
from agenticcore.chatbot.services import ChatBot

app = FastAPI(title="AgenticCore Web UI")

# 1. Simple HTML form at /
@app.get("/", response_class=HTMLResponse)
def index():
    return """
    <form action="/agentic" method="get">
        <input type="text" name="msg" placeholder="Type a message" style="width:300px">
        <input type="submit" value="Send">
    </form>
    """

# 2. Agentic endpoint
@app.get("/agentic")
def run_agentic(msg: str = Query(..., description="Message to send to ChatBot")):
    bot = ChatBot()
    return bot.reply(msg)
\n================================================================================\nEND FILE: agenticcore\web_agentic.py\n================================================================================\n\n================================================================================\nBEGIN FILE: anon_bot\handler.py\n================================================================================\n\n# anon_bot/handler.py
"""
Stateless(ish) turn handler for the anonymous chatbot.
Signature kept tiny: handle_turn(message, history, user) -> new_history
- message: str (user text)
- history: list of [speaker, text] or None
- user: dict-like info (ignored here, but accepted for compatibility)
"""

from __future__ import annotations
from typing import List, Tuple, Any
from . import rules

History = List[Tuple[str, str]]  # [("user","..."), ("bot","...")]

def _coerce_history(h: Any) -> History:
    if not h:
        return []
    # normalize to tuple pairs
    out: History = []
    for item in h:
        try:
            who, text = item[0], item[1]
        except Exception:
            continue
        out.append((str(who), str(text)))
    return out

def handle_turn(message: str, history: History | None, user: dict | None) -> History:
    hist = _coerce_history(history)
    user_text = (message or "").strip()
    if user_text:
        hist.append(("user", user_text))
    rep = rules.reply_for(user_text, hist)
    hist.append(("bot", rep.text))
    return hist

# Convenience: one-shot stringâ†’string (used by plain JSON endpoints)
def handle_text(message: str, history: History | None = None) -> str:
    new_hist = handle_turn(message, history, user=None)
    # last item is bot reply
    return new_hist[-1][1] if new_hist else ""
\n================================================================================\nEND FILE: anon_bot\handler.py\n================================================================================\n\n================================================================================\nBEGIN FILE: anon_bot\rules.py\n================================================================================\n\n# anon_bot/rules.py
"""
Lightweight rule set for an anonymous chatbot.
No external providers required. Pure-Python, deterministic.
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Tuple

# ---- Types ----
History = List[Tuple[str, str]]  # e.g., [("user","hi"), ("bot","hello!")]

@dataclass(frozen=True)
class Reply:
    text: str
    meta: Dict[str, str] | None = None


def normalize(s: str) -> str:
    return " ".join((s or "").strip().split()).lower()


def capabilities() -> List[str]:
    return [
        "help",
        "reverse <text>",
        "echo <text>",
        "small talk (hi/hello/hey)",
    ]


def intent_of(text: str) -> str:
    t = normalize(text)
    if not t:
        return "empty"
    if t in {"help", "/help", "capabilities"}:
        return "help"
    if t.startswith("reverse "):
        return "reverse"
    if t.startswith("echo "):
        return "echo"
    if t in {"hi", "hello", "hey"}:
        return "greet"
    return "chat"


def handle_help() -> Reply:
    lines = ["I can:"]
    for c in capabilities():
        lines.append(f"- {c}")
    return Reply("\n".join(lines))


def handle_reverse(t: str) -> Reply:
    payload = t.split(" ", 1)[1] if " " in t else ""
    return Reply(payload[::-1] if payload else "(nothing to reverse)")


def handle_echo(t: str) -> Reply:
    payload = t.split(" ", 1)[1] if " " in t else ""
    return Reply(payload or "(nothing to echo)")


def handle_greet() -> Reply:
    return Reply("Hello! ðŸ‘‹  Type 'help' to see what I can do.")


def handle_chat(t: str, history: History) -> Reply:
    # Very simple â€œELIZA-ishâ€ fallback.
    if "help" in t:
        return handle_help()
    if "you" in t and "who" in t:
        return Reply("I'm a tiny anonymous chatbot kernel.")
    return Reply("Noted. (anonymous mode)  Type 'help' for commands.")


def reply_for(text: str, history: History) -> Reply:
    it = intent_of(text)
    if it == "empty":
        return Reply("Please type something. Try 'help'.")
    if it == "help":
        return handle_help()
    if it == "reverse":
        return handle_reverse(text)
    if it == "echo":
        return handle_echo(text)
    if it == "greet":
        return handle_greet()
    return handle_chat(text.lower(), history)
\n================================================================================\nEND FILE: anon_bot\rules.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\app.py\n================================================================================\n\n# /app/app.py
#!/usr/bin/env python3
# app.py â€” aiohttp + Bot Framework (root-level). Routes added explicitly.
import os, sys, json
from aiohttp import web
from pathlib import Path
from botbuilder.core import BotFrameworkAdapter, BotFrameworkAdapterSettings, TurnContext, ActivityHandler
from botbuilder.schema import Activity

# Config / logging
from core.config import settings
from core.logging import setup_logging, get_logger

setup_logging(level=settings.log_level, json_logs=settings.json_logs)
log = get_logger("bootstrap")
log.info("starting", extra={"config": settings.to_dict()})

# Bot impl: prefer user's SimpleBot, fallback to tiny bot
try:
    from bot import SimpleBot as BotImpl  # user's ActivityHandler
except Exception:
    class BotImpl(ActivityHandler):
        async def on_turn(self, turn_context: TurnContext):
            if (turn_context.activity.type or "").lower() == "message":
                text = (turn_context.activity.text or "").strip()
                if not text:
                    await turn_context.send_activity("Input was empty. Type 'help' for usage.")
                    return
                lower = text.lower()
                if lower == "help":
                    await turn_context.send_activity("Try: echo <msg> | reverse: <msg> | capabilities")
                elif lower == "capabilities":
                    await turn_context.send_activity("- echo\n- reverse\n- help\n- capabilities")
                elif lower.startswith("reverse:"):
                    payload = text.split(":", 1)[1].strip()
                    await turn_context.send_activity(payload[::-1])
                elif lower.startswith("echo "):
                    await turn_context.send_activity(text[5:])
                else:
                    await turn_context.send_activity("Unsupported command. Type 'help' for examples.")
            else:
                await turn_context.send_activity(f"[{turn_context.activity.type}] event received.")

# Adapter / credentials
APP_ID = os.environ.get("MicrosoftAppId") or settings.microsoft_app_id
APP_PASSWORD = os.environ.get("MicrosoftAppPassword") or settings.microsoft_app_password
adapter_settings = BotFrameworkAdapterSettings(APP_ID, APP_PASSWORD)
adapter = BotFrameworkAdapter(adapter_settings)

async def on_error(context: TurnContext, error: Exception):
    print(f"[on_turn_error] {error}", file=sys.stderr, flush=True)
    try:
        await context.send_activity("Oops. Something went wrong!")
    except Exception as send_err:
        print(f"[on_turn_error][send_activity_failed] {send_err}", file=sys.stderr, flush=True)

adapter.on_turn_error = on_error
bot = BotImpl()

# Prefer project logic for /plain-chat; otherwise fallback to simple helpers
try:
    from logic import handle_text as _handle_text
except Exception:
    from skills import normalize, reverse_text, is_empty
    def _handle_text(user_text: str) -> str:
        text = (user_text or "").strip()
        if not text:
            return "Please provide text."
        cmd = normalize(text)
        if cmd in {"help", "capabilities"}:
            return "Try: reverse <text> | or just say anything"
        if cmd.startswith("reverse "):
            original = text.split(" ", 1)[1] if " " in text else ""
            return reverse_text(original)
        return f"You said: {text}"

# -------------------- HTTP handlers (module-level) --------------------
async def messages(req: web.Request) -> web.Response:
    ctype = (req.headers.get("Content-Type") or "").lower()
    if "application/json" not in ctype:
        return web.Response(status=415, text="Unsupported Media Type: expected application/json")
    try:
        body = await req.json()
    except json.JSONDecodeError:
        return web.Response(status=400, text="Invalid JSON body")

    activity = Activity().deserialize(body)
    auth_header = req.headers.get("Authorization")
    invoke_response = await adapter.process_activity(activity, auth_header, bot.on_turn)
    if invoke_response:
        return web.json_response(data=invoke_response.body, status=invoke_response.status)
    return web.Response(status=202, text="Accepted")

async def messages_get(_req: web.Request) -> web.Response:
    return web.Response(
        text="This endpoint only accepts POST (Bot Framework activities).",
        content_type="text/plain",
        status=405
    )

async def home(_req: web.Request) -> web.Response:
    return web.Response(
        text="Bot is running. POST Bot Framework activities to /api/messages.",
        content_type="text/plain"
    )

async def healthz(_req: web.Request) -> web.Response:
    return web.json_response({"status": "ok"})

async def plain_chat(req: web.Request) -> web.Response:
    try:
        payload = await req.json()
    except Exception:
        return web.json_response({"error": "Invalid JSON"}, status=400)
    user_text = payload.get("text", "")
    reply = _handle_text(user_text)
    return web.json_response({"reply": reply})

# -------------------- App factory --------------------
def create_app() -> web.Application:
    app = web.Application()

    # Add routes explicitly (as requested)
    app.router.add_get("/", home)
    app.router.add_get("/healthz", healthz)
    app.router.add_get("/api/messages", messages_get)
    app.router.add_post("/api/messages", messages)
    app.router.add_post("/plain-chat", plain_chat)

    # Optional CORS (if installed)
    try:
        import aiohttp_cors
        cors = aiohttp_cors.setup(app, defaults={
            "*": aiohttp_cors.ResourceOptions(
                allow_credentials=True,
                expose_headers="*",
                allow_headers="*",
                allow_methods=["GET","POST","OPTIONS"],
            )
        })
        for route in list(app.router.routes()):
            cors.add(route)
    except Exception:
        pass

    # Static (./static)
    static_dir = Path(__file__).parent / "static"
    if static_dir.exists():
        app.router.add_static("/static/", path=static_dir, show_index=True)
    else:
        log.warning("static directory not found", extra={"path": str(static_dir)})

    return app

app = create_app()

if __name__ == "__main__":
    web.run_app(app, host=settings.host, port=settings.port)
\n================================================================================\nEND FILE: app\app.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\assets\html\agenticcore_frontend.html\n================================================================================\n\n<!-- /app/assets/html/agenticcore_frontend.html -->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AgenticCore Chatbot Frontend</title>
  <style>
    :root {
      --bg: #0b0d12;
      --panel: #0f172a;
      --panel-2: #111827;
      --text: #e5e7eb;
      --muted: #9ca3af;
      --accent: #60a5fa;
      --border: #1f2940;
      --danger: #ef4444;
      --success: #22c55e;
    }
    * { box-sizing: border-box; }
    body { margin: 0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; background: var(--bg); color: var(--text); }
    .wrap { max-width: 920px; margin: 32px auto; padding: 0 16px; }
    header { display: flex; align-items: center; justify-content: space-between; margin-bottom: 16px; gap: 16px; }
    header h1 { font-size: 18px; margin: 0; letter-spacing: .3px; }
    header .badge { font-size: 12px; opacity: .85; padding: 4px 8px; border:1px solid var(--border); border-radius: 999px; background: rgba(255,255,255,0.03); }
    .card { background: var(--panel); border: 1px solid var(--border); border-radius: 16px; padding: 16px; }
    .row { display: flex; gap: 10px; align-items: center; }
    .stack { display: grid; gap: 12px; }
    label { font-size: 12px; color: var(--muted); }
    input[type=text] { flex: 1; padding: 12px 14px; border-radius: 12px; border: 1px solid var(--border); background: var(--panel-2); color: var(--text); outline: none; }
    input[type=text]::placeholder { color: #6b7280; }
    button { padding: 10px 14px; border-radius: 12px; border: 1px solid var(--border); background: #1f2937; color: var(--text); cursor: pointer; transition: transform .02s ease, background .2s; }
    button:hover { background: #273449; }
    button:active { transform: translateY(1px); }
    .btn-primary { background: #1f2937; border-color: #31405a; }
    .btn-ghost { background: transparent; border-color: var(--border); }
    .grid { display: grid; gap: 12px; }
    .grid-2 { grid-template-columns: 1fr 1fr; }
    .log { margin-top: 16px; display: grid; gap: 10px; }
    .bubble { max-width: 80%; padding: 12px 14px; border-radius: 14px; line-height: 1.35; }
    .user { background: #1e293b; border:1px solid #2b3b55; margin-left: auto; border-bottom-right-radius: 4px; }
    .bot  { background: #0d1b2a; border:1px solid #223049; margin-right: auto; border-bottom-left-radius: 4px; }
    .meta { font-size: 12px; color: var(--muted); margin-top: 4px; }
    pre { margin: 0; white-space: pre-wrap; word-break: break-word; }
    .status { display:flex; align-items:center; gap:8px; font-size: 12px; color: var(--muted); }
    .dot { width:8px; height:8px; border-radius:999px; background: #64748b; display:inline-block; }
    .dot.ok { background: var(--success); }
    .dot.bad { background: var(--danger); }
    footer { margin: 24px 0; text-align:center; color: var(--muted); font-size: 12px; }
    .small { font-size: 12px; }
    @media (max-width: 700px) { .grid-2 { grid-template-columns: 1fr; } }
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <h1>AgenticCore Chatbot Frontend</h1>
      <div class="badge">Frontend â†’ FastAPI â†’ providers_unified</div>
    </header>

    <section class="card stack">
      <div class="grid grid-2">
        <div class="stack">
          <label for="backend">Backend URL</label>
          <div class="row">
            <input id="backend" type="text" placeholder="http://127.0.0.1:8000" />
            <button id="save" class="btn-ghost">Save</button>
          </div>
          <div class="status" id="status"><span class="dot"></span><span>Not checked</span></div>
        </div>
        <div class="stack">
          <label for="message">Message</label>
          <div class="row">
            <input id="message" type="text" placeholder="Type a messageâ€¦" />
            <button id="send" class="btn-primary">Send</button>
          </div>
          <div class="row">
            <button id="cap" class="btn-ghost small">Capabilities</button>
            <button id="health" class="btn-ghost small">Health</button>
            <button id="clear" class="btn-ghost small">Clear</button>
          </div>
        </div>
      </div>
      <div class="log" id="log"></div>
    </section>

    <footer>
      Use with your FastAPI backend at <code>/chatbot/message</code>. Configure CORS if you serve this file from a different origin.
    </footer>
  </div>

  <script>
    const $ = (sel) => document.querySelector(sel);
    const backendInput = $('#backend');
    const sendBtn = $('#send');
    const saveBtn = $('#save');
    const msgInput = $('#message');
    const capBtn = $('#cap');
    const healthBtn = $('#health');
    const clearBtn = $('#clear');
    const log = $('#log');
    const status = $('#status');
    const dot = status.querySelector('.dot');
    const statusText = status.querySelector('span:last-child');

    function getBackendUrl() {
      return localStorage.getItem('BACKEND_URL') || 'http://127.0.0.1:8000';
    }
    function setBackendUrl(v) {
      localStorage.setItem('BACKEND_URL', v);
    }
    function cardUser(text) {
      const div = document.createElement('div');
      div.className = 'bubble user';
      div.textContent = text;
      log.appendChild(div);
      log.scrollTop = log.scrollHeight;
    }
    function cardBot(obj) {
      const wrap = document.createElement('div');
      wrap.className = 'bubble bot';
      const pre = document.createElement('pre');
      pre.textContent = typeof obj === 'string' ? obj : JSON.stringify(obj, null, 2);
      wrap.appendChild(pre);
      log.appendChild(wrap);
      log.scrollTop = log.scrollHeight;
    }
    function setStatus(ok, text) {
      dot.classList.toggle('ok', !!ok);
      dot.classList.toggle('bad', ok === false);
      statusText.textContent = text || (ok ? 'OK' : 'Error');
    }
    async function api(path, init) {
      const base = backendInput.value.trim().replace(/\/$/, '');
      const url = base + path;
      const resp = await fetch(url, init);
      if (!resp.ok) {
        let t = await resp.text().catch(() => '');
        throw new Error(`HTTP ${resp.status} ${resp.statusText} â€” ${t}`);
      }
      const contentType = resp.headers.get('content-type') || '';
      if (contentType.includes('application/json')) return resp.json();
      return resp.text();
    }

    async function checkHealth() {
      try {
        const h = await api('/health', { method: 'GET' });
        setStatus(true, 'Healthy');
        cardBot({ health: h });
      } catch (e) {
        setStatus(false, String(e.message || e));
        cardBot({ error: String(e.message || e) });
      }
    }

    async function sendMessage() {
      const text = msgInput.value.trim();
      if (!text) return;
      cardUser(text);
      msgInput.value = '';
      try {
        const data = await api('/chatbot/message', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ message: text })
        });
        cardBot(data);
      } catch (e) {
        cardBot({ error: String(e.message || e) });
      }
    }

    async function showCapabilities() {
      try {
        // Prefer API if available; if 404, fall back to library-like prompt.
        const data = await api('/chatbot/message', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ message: 'help' })
        });
        cardBot(data);
      } catch (e) {
        cardBot({ capabilities: ['text-input','sentiment-analysis','help'], note: 'API help failed, showing defaults', error: String(e.message || e) });
      }
    }

    // Wire up
    backendInput.value = getBackendUrl();
    saveBtn.onclick = () => { setBackendUrl(backendInput.value.trim()); setStatus(null, 'Saved'); };
    sendBtn.onclick = sendMessage;
    msgInput.addEventListener('keydown', (ev) => { if (ev.key === 'Enter') sendMessage(); });
    capBtn.onclick = showCapabilities;
    healthBtn.onclick = checkHealth;
    clearBtn.onclick = () => { log.innerHTML = ''; setStatus(null, 'Idle'); };

    // Initial health ping
    checkHealth();
  </script>
</body>
</html>
\n================================================================================\nEND FILE: app\assets\html\agenticcore_frontend.html\n================================================================================\n\n================================================================================\nBEGIN FILE: app\assets\html\chat.html\n================================================================================\n\n<!-- /app/assets/html/chat.html -->
<!doctype html>
<html><head><meta charset="utf-8"/><title>Simple Chat</title>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<style>
:root { --bg:#f6f7f9; --card:#fff; --me:#dff1ff; --bot:#ffffff; --text:#23262b; --muted:#8a9099; }
body { margin:0; font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif; background:var(--bg); color:var(--text); }
.app { max-width:840px; margin:24px auto; padding:0 16px; }
.card { background:var(--card); border:1px solid #e3e6ea; border-radius:14px; box-shadow:0 1px 2px rgba(0,0,0,.04); overflow:hidden; }
.header { padding:14px 16px; border-bottom:1px solid #e9edf2; font-weight:600; }
.chat { height:480px; overflow:auto; padding:16px; display:flex; flex-direction:column; gap:12px; }
.row { display:flex; }
.row.me { justify-content:flex-end; }
.bubble { max-width:70%; padding:10px 12px; border-radius:12px; line-height:1.35; white-space:pre-wrap; }
.me .bubble { background:var(--me); border:1px solid #c3e5ff; }
.bot .bubble { background:var(--bot); border:1px solid #e5e8ec; }
.footer { display:flex; gap:8px; padding:12px; border-top:1px solid #e9edf2; }
input[type=text] { flex:1; padding:10px 12px; border-radius:10px; border:1px solid #d5dbe3; font-size:15px; }
button { padding:10px 14px; border-radius:10px; border:1px solid #2b6cb0; background:#2b6cb0; color:#fff; font-weight:600; cursor:pointer; }
button:disabled { opacity:.6; cursor:not-allowed; }
.hint { color:var(--muted); font-size:12px; padding:0 16px 12px; }
</style></head>
<body>
<div class="app"><div class="card">
  <div class="header">Traditional Chatbot (Local)</div>
  <div id="chat" class="chat"></div>
  <div class="hint">Try: <code>reverse: hello world</code>, <code>help</code>, <code>capabilities</code></div>
  <div class="footer">
    <input id="msg" type="text" placeholder="Type a message..." autofocus />
    <button id="send">Send</button>
  </div>
</div></div>
<script>
const API = "http://127.0.0.1:3978/plain-chat";
const chat = document.getElementById("chat");
const input = document.getElementById("msg");
const sendBtn = document.getElementById("send");
function addBubble(text, who) {
  const row = document.createElement("div"); row.className = "row " + who;
  const wrap = document.createElement("div"); wrap.className = who === "me" ? "me" : "bot";
  const b = document.createElement("div"); b.className = "bubble"; b.textContent = text;
  wrap.appendChild(b); row.appendChild(wrap); chat.appendChild(row); chat.scrollTop = chat.scrollHeight;
}
async function send() {
  const text = input.value.trim(); if (!text) return; input.value = ""; addBubble(text, "me"); sendBtn.disabled = true;
  try {
    const res = await fetch(API, { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ text }) });
    if (!res.ok) throw new Error("HTTP " + res.status);
    const data = await res.json(); addBubble(data.reply ?? "(no reply)", "bot");
  } catch (err) { addBubble("Error: " + err.message, "bot"); }
  finally { sendBtn.disabled = false; input.focus(); }
}
sendBtn.addEventListener("click", send);
input.addEventListener("keydown", (e)=>{ if (e.key === "Enter") send(); });
addBubble("Connected to local bot at /plain-chat", "bot");
</script>
</body></html>
\n================================================================================\nEND FILE: app\assets\html\chat.html\n================================================================================\n\n================================================================================\nBEGIN FILE: app\assets\html\chat_console.html\n================================================================================\n\n<!-- /app/assets/html/chat_console.html -->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Console Chat Tester</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body{ font-family: ui-sans-serif, system-ui, Arial; margin:20px; }
    .row{ display:flex; gap:8px; align-items:center; margin:6px 0; }
    input[type=text]{ flex:1; padding:8px; }
    button{ padding:8px 10px; }
    pre{ background:#0b1020; color:#d6e7ff; padding:10px; height:320px; overflow:auto; }
    .chip{ display:inline-block; padding:3px 8px; background:#eef; border-radius:12px; margin-left:8px; }
  </style>
</head>
<body>
<h2>AgenticCore Console</h2>

<div class="row">
  <label>Backend</label>
  <input id="base" type="text" value="http://127.0.0.1:8000" />
  <button id="btnHealth">Health</button>
  <button id="btnRoutes">Routes</button>
</div>

<div class="row">
  <input id="msg" type="text" placeholder="Say somethingâ€¦" />
  <button id="btnSend">POST /chatbot/message</button>
</div>

<div>
  <span>Mode:</span>
  <span id="mode" class="chip">API</span>
</div>

<pre id="out"></pre>

<script>
const $ = id => document.getElementById(id);
const out = $("out");
function print(o){ out.textContent += (typeof o==="string" ? o : JSON.stringify(o,null,2)) + "\n"; out.scrollTop = out.scrollHeight; }
function join(b, p){ return b.replace(/\/+$/,"") + p; }

async function health(){
  try{
    const r = await fetch(join($("base").value, "/health"));
    print(await r.json());
  }catch(e){ print("health error: " + e); }
}
async function routes(){
  try{
    const r = await fetch(join($("base").value, "/openapi.json"));
    const j = await r.json();
    print({ routes: Object.keys(j.paths) });
  }catch(e){ print("routes error: " + e); }
}
async function send(){
  const text = $("msg").value.trim();
  if(!text){ print("enter a message first"); return; }
  try{
    const r = await fetch(join($("base").value, "/chatbot/message"), {
      method:"POST",
      headers:{ "Content-Type":"application/json" },
      body: JSON.stringify({ message: text })
    });
    print(await r.json());
  }catch(e){ print("send error: " + e); }
}
$("btnHealth").onclick = health;
$("btnRoutes").onclick = routes;
$("btnSend").onclick = send;

// boot
health();
</script>
</body>
</html>
\n================================================================================\nEND FILE: app\assets\html\chat_console.html\n================================================================================\n\n================================================================================\nBEGIN FILE: app\assets\html\chat_minimal.html\n================================================================================\n\n<!-- /app/assets/html/chat_minimal.html -->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Minimal Chat Tester</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 24px; }
    .row { display:flex; gap:8px; align-items:center; margin-bottom:8px; }
    input[type=text]{ width:420px; padding:8px; }
    textarea{ width:100%; height:240px; padding:8px; }
    button{ padding:8px 12px; }
    .ok{ color:#1a7f37; }
    .warn{ color:#b54708; }
    .err{ color:#b42318; }
  </style>
</head>
<body>
<h2>Minimal Chat Tester â†’ FastAPI /chatbot/message</h2>

<div class="row">
  <label>Backend URL:</label>
  <input id="base" type="text" value="http://127.0.0.1:8000" />
  <button id="btnHealth">Health</button>
  <button id="btnCaps">Capabilities</button>
</div>

<div class="row">
  <input id="msg" type="text" placeholder="Type a messageâ€¦" />
  <button id="btnSend">Send</button>
</div>

<p id="status"></p>
<textarea id="log" readonly></textarea>

<script>
const $ = id => document.getElementById(id);
const log = (o, cls="") => {
  const line = (typeof o === "string") ? o : JSON.stringify(o, null, 2);
  $("log").value += line + "\n";
  $("log").scrollTop = $("log").scrollHeight;
  if(cls) { $("status").className = cls; $("status").textContent = line; }
};

function urlJoin(base, path) {
  return base.replace(/\/+$/,"") + path;
}

async function health() {
  try {
    const r = await fetch(urlJoin($("base").value, "/health"));
    const j = await r.json();
    log(j, "ok");
  } catch (e) { log("Health error: " + e, "err"); }
}

async function caps() {
  try {
    // Prefer library-like caps endpoint if you expose one; otherwise call /openapi.json for visibility
    const r = await fetch(urlJoin($("base").value, "/openapi.json"));
    const j = await r.json();
    log({paths: Object.keys(j.paths).slice(0,20)}, "ok");
  } catch (e) { log("Caps error: " + e, "err"); }
}

async function sendMsg() {
  const text = $("msg").value.trim();
  if(!text) { log("Please type a message.", "warn"); return; }
  try {
    const r = await fetch(urlJoin($("base").value, "/chatbot/message"), {
      method:"POST",
      headers:{ "Content-Type":"application/json" },
      body: JSON.stringify({ message: text })
    });
    if(!r.ok) throw new Error(`${r.status} ${r.statusText}`);
    const j = await r.json();
    log(j, "ok");
  } catch (e) { log("Send error: " + e, "err"); }
}

$("btnHealth").onclick = health;
$("btnCaps").onclick = caps;
$("btnSend").onclick = sendMsg;

// Warmup
health();
</script>
</body>
</html>
\n================================================================================\nEND FILE: app\assets\html\chat_minimal.html\n================================================================================\n\n================================================================================\nBEGIN FILE: app\mbf_bot\__init__.py\n================================================================================\n\n\n================================================================================\nEND FILE: app\mbf_bot\__init__.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\mbf_bot\bot.py\n================================================================================\n\n# /app/bot.py
"""
Simple MBF bot:
- 'help' / 'capabilities' shows features
- 'reverse <text>' returns reversed text
- otherwise delegates to AgenticCore ChatBot (sentiment) if available
"""

from typing import List, Optional, Dict, Any
from botbuilder.core import ActivityHandler, TurnContext
from botbuilder.schema import ChannelAccount, ActivityTypes

from skills import normalize, reverse_text, capabilities, is_empty

# Try to import AgenticCore; if unavailable, provide a tiny fallback.
try:
    from agenticcore.chatbot.services import ChatBot  # real provider-backed bot
except Exception:
    class ChatBot:  # fallback shim for offline/dev
        def reply(self, message: str) -> Dict[str, Any]:
            return {
                "reply": "Noted. (local fallback reply)",
                "sentiment": "neutral",
                "confidence": 0.5,
            }

def _format_sentiment(res: Dict[str, Any]) -> str:
    """Compose a user-facing string from ChatBot reply payload."""
    reply = (res.get("reply") or "").strip()
    label: Optional[str] = res.get("sentiment")
    conf = res.get("confidence")
    if label is not None and conf is not None:
        return f"{reply} (sentiment: {label}, confidence: {float(conf):.2f})"
    return reply or "I'm not sure what to say."

def _help_text() -> str:
    """Single source of truth for the help/capability text."""
    feats = "\n".join(f"- {c}" for c in capabilities())
    return (
        "I can reverse text and provide concise replies with sentiment.\n"
        "Commands:\n"
        "- help | capabilities\n"
        "- reverse <text>\n"
        "General text will be handled by the ChatBot service.\n\n"
        f"My capabilities:\n{feats}"
    )

class SimpleBot(ActivityHandler):
    """Minimal ActivityHandler with local commands + ChatBot fallback."""

    def __init__(self, chatbot: Optional[ChatBot] = None):
        self._chatbot = chatbot or ChatBot()

    async def on_members_added_activity(
        self, members_added: List[ChannelAccount], turn_context: TurnContext
    ):
        for member in members_added:
            if member.id != turn_context.activity.recipient.id:
                await turn_context.send_activity("Hello! Type 'help' to see what I can do.")

    async def on_message_activity(self, turn_context: TurnContext):
        if turn_context.activity.type != ActivityTypes.message:
            return

        text = (turn_context.activity.text or "").strip()
        if is_empty(text):
            await turn_context.send_activity("Please enter a message (try 'help').")
            return

        cmd = normalize(text)

        if cmd in {"help", "capabilities"}:
            await turn_context.send_activity(_help_text())
            return

        if cmd.startswith("reverse "):
            original = text.split(" ", 1)[1] if " " in text else ""
            await turn_context.send_activity(reverse_text(original))
            return

        # ChatBot fallback (provider-agnostic sentiment/reply)
        try:
            result = self._chatbot.reply(text)
            await turn_context.send_activity(_format_sentiment(result))
        except Exception:
            await turn_context.send_activity(f"You said: {text}")
\n================================================================================\nEND FILE: app\mbf_bot\bot.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\mbf_bot\skills.py\n================================================================================\n\n# /app/skills.py
"""
Small, dependency-free helpers used by the MBF SimpleBot.
"""

from typing import List

_CAPS: List[str] = [
    "echo-reverse",          # reverse <text>
    "help",                  # help / capabilities
    "chatbot-sentiment",     # delegate to ChatBot() if available
]

def normalize(text: str) -> str:
    """Normalize user text for lightweight command routing."""
    return (text or "").strip().lower()

def reverse_text(text: str) -> str:
    """Return the input string reversed."""
    return (text or "")[::-1]

def capabilities() -> List[str]:
    """Return a stable list of bot capabilities."""
    return list(_CAPS)

def is_empty(text: str) -> bool:
    """True if message is blank after trimming."""
    return len((text or "").strip()) == 0
\n================================================================================\nEND FILE: app\mbf_bot\skills.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\routes.py\n================================================================================\n\n# /app/routes.py â€” HTTP handlers
# routes.py â€” HTTP handlers (root-level, no /app package)
import json
from aiohttp import web
from botbuilder.schema import Activity

# Prefer project logic if available
try:
    from logic import handle_text as _handle_text  # user-defined
except Exception:
    from skills import normalize, reverse_text, is_empty
    def _handle_text(user_text: str) -> str:
        text = (user_text or "").strip()
        if not text:
            return "Please provide text."
        cmd = normalize(text)
        if cmd in {"help", "capabilities"}:
            return "Try: reverse <text> | or just say anything"
        if cmd.startswith("reverse "):
            original = text.split(" ", 1)[1] if " " in text else ""
            return reverse_text(original)
        return f"You said: {text}"

def init_routes(app: web.Application, adapter, bot) -> None:
    async def messages(req: web.Request) -> web.Response:
        ctype = (req.headers.get("Content-Type") or "").lower()
        if "application/json" not in ctype:
            return web.Response(status=415, text="Unsupported Media Type: expected application/json")
        try:
            body = await req.json()
        except json.JSONDecodeError:
            return web.Response(status=400, text="Invalid JSON body")

        activity = Activity().deserialize(body)
        auth_header = req.headers.get("Authorization")

        invoke_response = await adapter.process_activity(activity, auth_header, bot.on_turn)
        if invoke_response:
            return web.json_response(data=invoke_response.body, status=invoke_response.status)
        return web.Response(status=202, text="Accepted")

    async def messages_get(_req: web.Request) -> web.Response:
        return web.Response(
            text="This endpoint only accepts POST (Bot Framework activities).",
            content_type="text/plain",
            status=405
        )

    async def home(_req: web.Request) -> web.Response:
        return web.Response(
            text="Bot is running. POST Bot Framework activities to /api/messages.",
            content_type="text/plain"
        )

    async def healthz(_req: web.Request) -> web.Response:
        return web.json_response({"status": "ok"})

    async def plain_chat(req: web.Request) -> web.Response:
        try:
            payload = await req.json()
        except Exception:
            return web.json_response({"error": "Invalid JSON"}, status=400)
        user_text = payload.get("text", "")
        reply = _handle_text(user_text)
        return web.json_response({"reply": reply})

    # Wire routes
    app.router.add_get("/", home)
    app.router.add_get("/healthz", healthz)
    app.router.add_get("/api/messages", messages_get)
    app.router.add_post("/api/messages", messages)
    app.router.add_post("/plain-chat", plain_chat)
\n================================================================================\nEND FILE: app\routes.py\n================================================================================\n\n================================================================================\nBEGIN FILE: core\config.py\n================================================================================\n\n# /core/config.py
from __future__ import annotations
import os
from dataclasses import dataclass, field
from typing import List, Optional


def _as_bool(v: Optional[str], default: bool = False) -> bool:
    if v is None:
        return default
    return v.strip().lower() in {"1", "true", "yes", "y", "on"}

def _as_int(v: Optional[str], default: int) -> int:
    try:
        return int(v) if v is not None else default
    except ValueError:
        return default

def _as_list(v: Optional[str], default: List[str] | None = None) -> List[str]:
    if not v:
        return list(default or [])
    return [item.strip() for item in v.split(",") if item.strip()]


@dataclass(slots=True)
class Settings:
    # Runtime / environment
    env: str = field(default_factory=lambda: os.getenv("ENV", "dev"))
    debug: bool = field(default_factory=lambda: _as_bool(os.getenv("DEBUG"), False))

    # Host/port
    host: str = field(default_factory=lambda: os.getenv("HOST", "127.0.0.1"))
    port: int = field(default_factory=lambda: _as_int(os.getenv("PORT"), 3978))

    # Logging
    log_level: str = field(default_factory=lambda: os.getenv("LOG_LEVEL", "INFO"))
    json_logs: bool = field(default_factory=lambda: _as_bool(os.getenv("JSON_LOGS"), False))

    # CORS
    cors_allow_origins: List[str] = field(
        default_factory=lambda: _as_list(os.getenv("CORS_ALLOW_ORIGINS"), ["*"])
    )
    cors_allow_methods: List[str] = field(
        default_factory=lambda: _as_list(os.getenv("CORS_ALLOW_METHODS"), ["GET", "POST", "OPTIONS"])
    )
    cors_allow_headers: List[str] = field(
        default_factory=lambda: _as_list(os.getenv("CORS_ALLOW_HEADERS"), ["*"])
    )

    # Bot Framework credentials
    microsoft_app_id: Optional[str] = field(default_factory=lambda: os.getenv("MicrosoftAppId"))
    microsoft_app_password: Optional[str] = field(default_factory=lambda: os.getenv("MicrosoftAppPassword"))

    def to_dict(self) -> dict:
        return {
            "env": self.env,
            "debug": self.debug,
            "host": self.host,
            "port": self.port,
            "log_level": self.log_level,
            "json_logs": self.json_logs,
            "cors_allow_origins": self.cors_allow_origins,
            "cors_allow_methods": self.cors_allow_methods,
            "cors_allow_headers": self.cors_allow_headers,
            "microsoft_app_id": bool(self.microsoft_app_id),
            "microsoft_app_password": bool(self.microsoft_app_password),
        }


# singleton-style settings object
settings = Settings()
\n================================================================================\nEND FILE: core\config.py\n================================================================================\n\n================================================================================\nBEGIN FILE: core\logging.py\n================================================================================\n\n# /core/logging.py
from __future__ import annotations
import json
import logging
import sys
from datetime import datetime
from typing import Optional

try:
    # Optional: human-friendly console colors if installed
    import colorama  # type: ignore
    colorama.init()
    _HAS_COLOR = True
except Exception:  # pragma: no cover
    _HAS_COLOR = False

# Very small JSON formatter (avoids extra deps)
class JsonFormatter(logging.Formatter):
    def format(self, record: logging.LogRecord) -> str:  # type: ignore[override]
        payload = {
            "ts": datetime.utcfromtimestamp(record.created).isoformat(timespec="milliseconds") + "Z",
            "level": record.levelname,
            "logger": record.name,
            "msg": record.getMessage(),
        }
        if record.exc_info:
            payload["exc_info"] = self.formatException(record.exc_info)
        return json.dumps(payload, ensure_ascii=False)

class ConsoleFormatter(logging.Formatter):
    def format(self, record: logging.LogRecord) -> str:  # type: ignore[override]
        ts = datetime.utcfromtimestamp(record.created).strftime("%H:%M:%S")
        lvl = record.levelname
        name = record.name
        msg = record.getMessage()

        if _HAS_COLOR:
            COLORS = {
                "DEBUG": "\033[37m",
                "INFO": "\033[36m",
                "WARNING": "\033[33m",
                "ERROR": "\033[31m",
                "CRITICAL": "\033[41m",
            }
            RESET = "\033[0m"
            color = COLORS.get(lvl, "")
            return f"{ts} {color}{lvl:<8}{RESET} {name}: {msg}"
        return f"{ts} {lvl:<8} {name}: {msg}"


_initialized = False

def setup_logging(level: str = "INFO", json_logs: bool = False) -> None:
    """
    Initialize root logger once.
    """
    global _initialized
    if _initialized:
        return
    _initialized = True

    root = logging.getLogger()
    root.setLevel(level.upper())

    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(JsonFormatter() if json_logs else ConsoleFormatter())
    root.handlers[:] = [handler]


def get_logger(name: Optional[str] = None) -> logging.Logger:
    """
    Get a logger (call setup_logging() first to configure formatting).
    """
    return logging.getLogger(name or "app")
\n================================================================================\nEND FILE: core\logging.py\n================================================================================\n\n================================================================================\nBEGIN FILE: core\types.py\n================================================================================\n\n# /core/types.py
from __future__ import annotations
from dataclasses import dataclass, field, asdict
from typing import Any, Dict, List, Literal, Optional, Tuple, TypedDict

Role = Literal["system", "user", "assistant"]

# Basic chat message
@dataclass(slots=True)
class ChatMessage:
    role: Role
    content: str

# Pair-based history (simple UI / anon_bot style)
ChatTurn = List[str]                # [user, bot]
ChatHistory = List[ChatTurn]        # [[u,b], [u,b], ...]

# Plain chat API payloads (/plain-chat)
@dataclass(slots=True)
class PlainChatRequest:
    text: str

@dataclass(slots=True)
class PlainChatResponse:
    reply: str
    meta: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

# Optional error shape for consistent JSON error responses
class ErrorPayload(TypedDict, total=False):
    error: str
    detail: str
\n================================================================================\nEND FILE: core\types.py\n================================================================================\n\n================================================================================\nBEGIN FILE: docs\architecture.md\n================================================================================\n\n<!-- /docs/slides/architecture.md -->
# Architecture

This system follows a **modular chatbot architecture** built around a clear flow of data from the user interface to external services and back. The design emphasizes separation of concerns, allowing each module to handle a specific responsibility while keeping the overall system simple to test and extend.

---

## High-Level Flow (tied to flowchart)

1. **User Interface (UI)**  
   - The entry point for user interaction.  
   - Implemented through a web client (e.g., Gradio, HTML templates, or API endpoint).  
   - Captures user input and displays bot responses.

2. **Router / Core Logic**  
   - Handles conversation state and routes messages.  
   - Delegates to either the anonymous bot, logged-in bot, or agentic extensions.  
   - Imports lightweight rules from `anon_bot/rules.py` for anonymous sessions, and integrates with advanced providers for logged-in sessions.

3. **NLU (Natural Language Understanding)**  
   - Managed by the `nlu/` pipeline (intent recognition, prompts, and routing).  
   - Provides preprocessing, normalization, and optional summarization/RAG.  
   - Keeps the system extensible for additional models without changing the rest of the stack.

4. **Memory & Context Layer**  
   - Implemented in `memory/` (sessions, store, and optional RAG retriever/indexer).  
   - Stores session history, enabling context-aware responses.  
   - Supports modular backends (in-memory, file-based, or vector index).

5. **External AI Service Connector (optional)**  
   - For logged-in flows, integrates with cloud AIaaS (e.g., Azure, HuggingFace, or open-source LLMs).  
   - Uses `logged_in_bot/sentiment_azure.py` or `agenticcore/providers_unified.py`.  
   - Provides NLP services like sentiment analysis or summarization.  
   - Disabled in anonymous mode for privacy.

6. **Guardrails & Safety**  
   - Defined in `guardrails/` (PII redaction, safety filters).  
   - Applied before responses are shown to the user.  
   - Ensures compliance with privacy/security requirements.

7. **Outputs**  
   - Bot response returned to the UI.  
   - Logs written via `core/logging.py` for traceability and debugging.  
   - Optional screenshots and reports recorded for evaluation.

---

## Key Principles

- **Modularity**: Each part of the flow is a self-contained module (UI, NLU, memory, guardrails).  
- **Swap-in Providers**: Agentic core can switch between local rules, RAG memory, or external APIs.  
- **Anonymous vs Logged-In**: Anonymous bot uses lightweight rules with no external calls; logged-in bot can call providers.  
- **Extensibility**: Flowchart design makes it easy to add summarization, conversation modes, or other â€œagenticâ€ behaviors without rewriting the core.  
- **Resilience**: If an external service fails, the system degrades gracefully to local responses.

---

## Mapping to Repo Structure

- `app/` â†’ User-facing entrypoint (routes, HTML, API).  
- `anon_bot/` â†’ Anonymous chatbot rules + handler.  
- `logged_in_bot/` â†’ Provider-based flows for authenticated users.  
- `nlu/` â†’ Intent routing, prompts, pipeline.  
- `memory/` â†’ Session management + RAG integration.  
- `guardrails/` â†’ Safety filters + PII redaction.  
- `agenticcore/` â†’ Core integration logic and unified providers.  
- `docs/flowchart.png` â†’ Visual representation of this architecture.

---

## Summary

The architecture ensures a **clean separation between interface, logic, and services**, enabling experimentation with different providers while guaranteeing a safe, privacy-friendly anonymous mode. The flowchart illustrates this layered approach: input â†’ logic â†’ NLU/memory â†’ optional AIaaS â†’ guardrails â†’ output.
\n================================================================================\nEND FILE: docs\architecture.md\n================================================================================\n\n================================================================================\nBEGIN FILE: docs\design.md\n================================================================================\n\n<!-- /docs/slides/design.md -->
# Design Notes

These notes document the reasoning behind major design choices, focusing on **API usage**, **security considerations**, and **tradeoffs** made during development.

---

## API Notes

- **Anonymous vs Logged-In Flows**  
  - The **anonymous chatbot** relies purely on local rules (`anon_bot/rules.py`) and does not call any external services.  
  - The **logged-in chatbot** integrates with external AIaaS endpoints (e.g., Azure, HuggingFace, or other NLP providers) via modules in `logged_in_bot/` and `agenticcore/providers_unified.py`.  

- **Endpoints**  
  - `/plain-chat` â†’ Anonymous flow; maps to `logic.handle_text`.  
  - `/api/messages` â†’ For framework compatibility (e.g., BotFramework or FastAPI demo).  
  - `/healthz` â†’ Lightweight health check for monitoring.

- **NLU Pipeline**  
  - Intent routing (`nlu/router.py`) determines if user input should be treated as a direct command, a small-talk message, or passed to providers.  
  - Prompts and transformations are managed in `nlu/prompts.py` to centralize natural language templates.

- **Memory Integration**  
  - Session memory stored in `memory/sessions.py`.  
  - Optional RAG indexer (`memory/rag/indexer.py`) allows document retrieval for extended context.

---

## Security Considerations

- **API Keys**  
  - Keys for external services are never hard-coded.  
  - They are pulled from environment variables or `.env` files (via `core/config.py`).  

- **Data Handling**  
  - Anonymous mode never sends user text outside the local process.  
  - Logged-in mode applies guardrails before making external calls.  
  - Sensitive information (emails, IDs) is redacted using `guardrails/pii_redaction.py`.

- **Logging**  
  - Logs are structured (`core/logging.py`) and omit sensitive data by default.  
  - Debug mode can be enabled for local testing but should not be used in production.

- **Privacy**  
  - Anonymous sessions are ephemeral: conversation state is stored only in memory unless explicitly persisted.  
  - Logged-in sessions may optionally persist data, but only with user consent.

---

## Tradeoffs

- **Rule-Based vs AI-Powered**  
  - Rule-based responses are deterministic, fast, and private but limited in sophistication.  
  - AI-powered responses (via providers) allow richer understanding but introduce latency, costs, and privacy risks.  

- **Extensibility vs Simplicity**  
  - Chose a **modular repo structure** (separate folders for `anon_bot`, `logged_in_bot`, `memory`, `nlu`) to allow future growth.  
  - This adds some boilerplate overhead but makes it easier to swap components.

- **Performance vs Accuracy**  
  - Non-functional requirement: responses within 2 seconds for 95% of requests.  
  - This meant prioritizing lightweight providers and caching over heavyweight models.  

- **Anonymous Mode as Default**  
  - Defaulting to anonymous mode ensures the system works offline and avoids external dependencies.  
  - Tradeoff: limits functionality until the user explicitly opts in for a logged-in session.

---

## Summary

The design balances **privacy, modularity, and extensibility**. By cleanly separating anonymous and logged-in paths, the system can run entirely offline while still supporting richer AI features when configured. Security and privacy are first-class concerns, and tradeoffs were made to keep the system lightweight, testable, and compliant with project constraints.
\n================================================================================\nEND FILE: docs\design.md\n================================================================================\n\n================================================================================\nBEGIN FILE: docs\DEV_DOC.md\n================================================================================\n\n<!-- /docs/slides/DEV_DOC.md -->

## 3. Functional Requirements

This section describes the functional requirements for connecting a chatbot to an AI-as-a-Service (AIaaS) platform. It defines the expected system behavior, outlines constraints, and sets measurable acceptance criteria. Requirements are grouped into system context, core functions, supporting functions, and non-functional aspects.

---

### 3.1 System Context

The chatbot acts as the client application. It receives user input, processes it, and communicates with an external AIaaS endpoint (e.g., Azure AI Language Service). The AI service provides natural language processing (NLP) features such as sentiment analysis. The chatbot then interprets the service output and responds back to the user.

Key components include:
- **User Interface (UI):** Chat interface for entering text.
- **Chatbot Core:** Handles request routing and conversation logic.
- **AI Service Connector:** Manages authentication and API calls to the AI service.
- **AIaaS Platform:** External cloud service providing NLP functions.

---

### 3.2 Functional Requirements

#### FR-1: User Input Handling
- The chatbot shall accept text input from users.
- The chatbot shall sanitize input to remove unsafe characters.
- The chatbot shall log all interactions for debugging and testing.

#### FR-2: API Connection
- The system shall authenticate with the AI service using API keys stored securely in environment variables.
- The chatbot shall send user text to the AIaaS endpoint in the required format.
- The chatbot shall handle and parse responses from the AIaaS.

#### FR-3: Sentiment Analysis Integration
- The chatbot shall use the AIaaS to determine the sentiment (e.g., positive, neutral, negative) of user input.
- The chatbot shall present sentiment results as part of its response or use them to adjust tone.

#### FR-4: Error and Exception Handling
- The system shall detect failed API calls and return a fallback message to the user.
- The chatbot shall notify the user if the AI service is unavailable.
- The chatbot shall log errors with timestamp and cause.

#### FR-5: Reporting and Documentation
- The chatbot shall provide a list of supported commands or features when prompted.
- The chatbot shall record system status and output for inclusion in the project report.
- The development process shall be documented with screenshots and configuration notes.

---

### 3.3 Non-Functional Requirements

#### NFR-1: Security
- API keys shall not be hard-coded in source files.
- Sensitive data shall be retrieved from environment variables or secure vaults.

#### NFR-2: Performance
- The chatbot shall return responses within 2 seconds under normal network conditions.
- The system shall process at least 20 concurrent user sessions without performance degradation.

#### NFR-3: Reliability
- The chatbot shall achieve at least 95% uptime during testing.
- The chatbot shall gracefully degrade to local responses if the AI service is unavailable.

#### NFR-4: Usability
- The chatbot shall provide clear, user-friendly error messages.
- The chatbot shall handle malformed input without crashing.

---

### 3.4 Acceptance Criteria

1. **Input Handling**
   - Given valid text input, the chatbot processes it without errors.
   - Given invalid or malformed input, the chatbot responds with a clarification request.

2. **API Connection**
   - Given a valid API key and endpoint, the chatbot connects and retrieves sentiment analysis.
   - Given an invalid API key, the chatbot logs an error and informs the user.

3. **Sentiment Analysis**
   - Given a positive statement, the chatbot labels it correctly with at least 90% accuracy.
   - Given a negative statement, the chatbot labels it correctly with at least 90% accuracy.

4. **Error Handling**
   - When the AI service is unavailable, the chatbot informs the user and continues functioning with local responses.
   - All failures are recorded in a log file.

5. **Usability**
   - The chatbot returns responses in less than 2 seconds for 95% of requests.
   - The chatbot displays a list of features when the user requests â€œhelp.â€

---

### Glossary

- **AIaaS (AI-as-a-Service):** Cloud-based artificial intelligence services accessible via APIs.
- **API (Application Programming Interface):** A set of rules for software applications to communicate with each other.
- **NLP (Natural Language Processing):** A field of AI focused on enabling computers to understand human language.
- **Sentiment Analysis:** An NLP technique that determines the emotional tone behind a text.

\n================================================================================\nEND FILE: docs\DEV_DOC.md\n================================================================================\n\n================================================================================\nBEGIN FILE: docs\results.md\n================================================================================\n\n<!-- /docs/slides/results.md -->
# Results\n\nChallenges, metrics, screenshots.\n\n================================================================================\nEND FILE: docs\results.md\n================================================================================\n\n================================================================================\nBEGIN FILE: examples\example.py\n================================================================================\n\n# /example/example.py
"""Simple CLI example that sends a message to the ChatBot and prints the JSON reply."""
import json
from agenticcore.chatbot.services import ChatBot

if __name__ == "__main__":
    bot = ChatBot()
    result = bot.reply("hello world")
    print(json.dumps(result, indent=2))
\n================================================================================\nEND FILE: examples\example.py\n================================================================================\n\n================================================================================\nBEGIN FILE: flat_tree_filter.py\n================================================================================\n\n#!/usr/bin/env python3
# flatten_anytree.py â€” Flatten a folder tree (code/config) into one text file.
# Usage:
#   python flatten_anytree.py [ROOT_DIR] [OUTPUT_FILE]
# Examples:
#   python flatten_anytree.py C:\path\to\repo FLATTENED_CODE.txt
#   python flatten_anytree.py . out.txt --include-exts .py,.ipynb --exclude-dirs .git,node_modules
#
# New in this patched version:
#   - Skips common .gitignore-style junk by default (node_modules, .venv, __pycache__, caches, etc.).
#   - Skips noisy/secret files like .env, .env.*, *.log, *.tmp, *.pyc by default.
#   - Adds CLI flags: --exclude-dirs, --exclude-files, --exclude-globs to extend ignores.
#   - Removes ".env" from default INCLUDE_EXTS for safety (you can still include via flags).
#
import json
import os
import sys
import fnmatch
from pathlib import Path
from typing import Iterable, Set, List

INCLUDE_EXTS: Set[str] = {
    ".py", ".ipynb", ".json", ".md", ".txt", ".yml", ".yaml",
    ".ini", ".cfg", ".conf", ".service", ".sh", ".bat",
    ".js", ".ts", ".tsx", ".jsx", ".css", ".html",
    ".toml", ".dockerfile"
}

EXCLUDE_DIRS: Set[str] = {
    ".git", ".hg", ".svn", "__pycache__", "node_modules",
    ".venv", "venv", "env", "dist", "build",
    "artifacts", "logs", ".idea", ".vscode", ".pytest_cache",
    ".mypy_cache", ".ruff_cache", ".tox", ".nox", ".hypothesis",
    ".cache", ".gradle", ".parcel-cache", ".next", ".turbo",
    ".pnpm-store", ".yarn", ".yarn/cache", ".nuxt", ".svelte-kit"
}

# Filenames to always skip
EXCLUDE_FILES: Set[str] = {
    ".DS_Store", "Thumbs.db", ".coverage", ".python-version",
}

# Glob patterns to skip (gitignore-like, simple fnmatch on the basename)
EXCLUDE_GLOBS: List[str] = [
    "*.log", "*.tmp", "*.temp", "*.bak", "*.swp", "*.swo",
    "*.pyc", "*.pyo", "*.pyd", "*.class",
    "*.lock", "*.pid",
    "*.egg-info", "*.eggs",
    "*.sqlite", "*.sqlite3", "*.db", "*.pkl",
    ".env", ".env.*",
]

MAX_FILE_BYTES_DEFAULT = 2_000_000  # 2 MB safety default


def is_included_file(path: Path, include_exts: Set[str]) -> bool:
    if not path.is_file():
        return False
    # Dockerfile special-case: no suffix
    if path.name.lower() == "dockerfile":
        return True
    return path.suffix.lower() in include_exts


def read_ipynb_code_cells(nb_path: Path) -> str:
    try:
        data = json.loads(nb_path.read_text(encoding="utf-8"))
    except Exception as e:
        return f"[ERROR reading notebook JSON: {e}]"
    cells = data.get("cells", [])
    out_lines: List[str] = []
    count = 0
    for c in cells:
        if c.get("cell_type") == "code":
            count += 1
            src = c.get("source", [])
            code = "".join(src)
            out_lines.append(f"# %% [code cell {count}]")
            out_lines.append(code.rstrip() + "\\n")
    if not out_lines:
        return "[No code cells found]"
    return "\\n".join(out_lines)


def read_text_file(path: Path) -> str:
    try:
        if path.suffix.lower() == ".ipynb":
            return read_ipynb_code_cells(path)
        return path.read_text(encoding="utf-8", errors="replace")
    except Exception as e:
        return f"[ERROR reading file: {e}]"


def walk_files(root: Path,
               exclude_dirs: Set[str],
               include_exts: Set[str],
               max_bytes: int,
               follow_symlinks: bool,
               exclude_files: Set[str],
               exclude_globs: List[str]) -> Iterable[Path]:
    for dirpath, dirnames, filenames in os.walk(root, followlinks=follow_symlinks):
        # prune excluded dirs in-place
        dirnames[:] = [d for d in dirnames if d not in exclude_dirs]
        for name in filenames:
            # filename-level filters
            if name in exclude_files:
                continue
            if any(fnmatch.fnmatch(name, pat) for pat in exclude_globs):
                continue

            p = Path(dirpath) / name
            if is_included_file(p, include_exts):
                try:
                    if p.stat().st_size <= max_bytes:
                        yield p
                except Exception:
                    continue


def parse_str_set_arg(raw: str, default: Set[str]) -> Set[str]:
    # Parse comma-separated items into a set of strings (filenames or dirnames).
    if raw is None or not str(raw).strip():
        return set(default)
    return {s.strip() for s in raw.split(",") if s.strip()}


def parse_list_arg(raw: str, default: Set[str]) -> Set[str]:
    # Parse comma-separated items; empty -> default. Example: ".py,.ipynb,.md"
    if raw is None or not str(raw).strip():
        return set(default)
    items = [s.strip() for s in raw.split(",") if s.strip()]
    # normalize extensions to lowercase with a leading dot when applicable
    norm: Set[str] = set()
    for it in items:
        it_low = it.lower()
        if it_low == "dockerfile":
            norm.add("dockerfile")  # handled specially
        elif it_low.startswith("."):
            norm.add(it_low)
        else:
            norm.add("." + it_low)
    return norm


def main(argv: List[str]) -> int:
    import argparse

    ap = argparse.ArgumentParser(
        description="Flatten a folder tree (code/config) into one text file with file headers."
    )
    ap.add_argument("root", nargs="?", default=".", help="Root directory to scan (default: current dir)")
    ap.add_argument("out", nargs="?", default="FLATTENED_CODE.txt", help="Output text file (default: FLATTENED_CODE.txt)")
    ap.add_argument("--include-exts", dest="include_exts", default="",
                    help="Comma-separated list of extensions to include (e.g. .py,.ipynb,.md). Default uses a sane preset.")
    ap.add_argument("--exclude-dirs", dest="exclude_dirs", default="",
                    help="Comma-separated list of directory names to exclude (in addition to defaults).")
    ap.add_argument("--exclude-files", dest="exclude_files", default="",
                    help="Comma-separated list of filenames to exclude (in addition to defaults).")
    ap.add_argument("--exclude-globs", dest="exclude_globs", default="",
                    help="Comma-separated list of glob patterns to exclude (e.g. *.log,*.tmp,.env, .env.*).")
    ap.add_argument("--max-bytes", dest="max_bytes", type=int, default=MAX_FILE_BYTES_DEFAULT,
                    help=f"Skip files larger than this many bytes (default: {MAX_FILE_BYTES_DEFAULT}).")
    ap.add_argument("--follow-symlinks", action="store_true", help="Follow symlinks while walking the tree.")
    args = ap.parse_args(argv)

    root = Path(args.root).expanduser()
    out_path = Path(args.out).expanduser()

    if not root.exists():
        print(f"Root path not found: {root}", file=sys.stderr)
        return 1

    include_exts = parse_list_arg(args.include_exts, INCLUDE_EXTS)

    exclude_dirs = set(EXCLUDE_DIRS)
    if args.exclude_dirs:
        exclude_dirs |= {d.strip() for d in args.exclude_dirs.split(",") if d.strip()}

    exclude_files = set(EXCLUDE_FILES)
    if args.exclude_files:
        exclude_files |= {f.strip() for f in args.exclude_files.split(",") if f.strip()}

    exclude_globs = list(EXCLUDE_GLOBS)
    if args.exclude_globs:
        exclude_globs += [g.strip() for g in args.exclude_globs.split(",") if g.strip()]

    files = sorted(
        walk_files(root, exclude_dirs, include_exts, args.max_bytes, args.follow_symlinks, exclude_files, exclude_globs)
    )

    out_path.parent.mkdir(parents=True, exist_ok=True)
    with out_path.open("w", encoding="utf-8") as out:
        out.write(f"# Flattened code dump for: {root.resolve()}\\n")
        out.write(f"# Files included: {len(files)}\\n\\n")
        for p in files:
            try:
                rel = p.relative_to(root)
            except Exception:
                rel = p
            out.write("\\n" + "=" * 80 + "\\n")
            out.write(f"BEGIN FILE: {rel}\\n")
            out.write("=" * 80 + "\\n\\n")
            out.write(read_text_file(p))
            out.write("\\n" + "=" * 80 + "\\n")
            out.write(f"END FILE: {rel}\\n")
            out.write("=" * 80 + "\\n")

    print(f"Wrote: {out_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
\n================================================================================\nEND FILE: flat_tree_filter.py\n================================================================================\n\n================================================================================\nBEGIN FILE: FLATTENED_CODE.txt\n================================================================================\n\n# Flattened code dump for: C:\Users\User\Agentic-Chat-bot-\n# Files included: 67\n\n\n================================================================================\nBEGIN FILE: agenticcore\__init__.py\n================================================================================\n\n# package
\n================================================================================\nEND FILE: agenticcore\__init__.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\chatbot\__init__.py\n================================================================================\n\n# package
\n================================================================================\nEND FILE: agenticcore\chatbot\__init__.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\chatbot\services.py\n================================================================================\n\n# /agenticcore/chatbot/services.py
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from typing import Dict

# Delegate sentiment to the unified provider layer
# If you put providers_unified.py under agenticcore/chatbot/, change the import to:
#   from agenticcore.chatbot.providers_unified import analyze_sentiment
from agenticcore.providers_unified import analyze_sentiment
from ..providers_unified import analyze_sentiment


def _trim(s: str, max_len: int = 2000) -> str:
    s = (s or "").strip()
    return s if len(s) <= max_len else s[: max_len - 1] + "â€¦"


@dataclass(frozen=True)
class SentimentResult:
    label: str          # "positive" | "neutral" | "negative" | "mixed" | "unknown"
    confidence: float   # 0.0 .. 1.0


class ChatBot:
    """
    Minimal chatbot that uses provider-agnostic sentiment via providers_unified.
    Public API:
      - reply(text: str) -> Dict[str, object]
      - capabilities() -> Dict[str, object]
    """

    def __init__(self, system_prompt: str = "You are a concise helper.") -> None:
        self._system_prompt = _trim(system_prompt, 800)
        # Expose which provider is intended/active (for diagnostics)
        self._mode = os.getenv("AI_PROVIDER") or "auto"

    def capabilities(self) -> Dict[str, object]:
        """List what this bot can do."""
        return {
            "system": "chatbot",
            "mode": self._mode,  # "auto" or a pinned provider (hf/azure/openai/cohere/deepai/offline)
            "features": ["text-input", "sentiment-analysis", "help"],
            "commands": {"help": "Describe capabilities and usage."},
        }

    def reply(self, text: str) -> Dict[str, object]:
        """Produce a reply and sentiment for one user message."""
        user = _trim(text)
        if not user:
            return self._make_response(
                "I didn't catch that. Please provide some text.",
                SentimentResult("unknown", 0.0),
            )

        if user.lower() in {"help", "/help"}:
            return {"reply": self._format_help(), "capabilities": self.capabilities()}

        s = analyze_sentiment(user)  # -> {"provider", "label", "score", ...}
        sr = SentimentResult(label=str(s.get("label", "neutral")), confidence=float(s.get("score", 0.5)))
        return self._make_response(self._compose(sr), sr)

    # ---- internals ----

    def _format_help(self) -> str:
        caps = self.capabilities()
        feats = ", ".join(caps["features"])
        return f"I can analyze sentiment and respond concisely. Features: {feats}. Send any text or type 'help'."

    @staticmethod
    def _make_response(reply: str, s: SentimentResult) -> Dict[str, object]:
        return {"reply": reply, "sentiment": s.label, "confidence": round(float(s.confidence), 2)}

    @staticmethod
    def _compose(s: SentimentResult) -> str:
        if s.label == "positive":
            return "Thanks for sharing. I detected a positive sentiment."
        if s.label == "negative":
            return "I hear your concern. I detected a negative sentiment."
        if s.label == "neutral":
            return "Noted. The sentiment appears neutral."
        if s.label == "mixed":
            return "Your message has mixed signals. Can you clarify?"
        return "I could not determine the sentiment. Please rephrase."


# Optional: local REPL for quick manual testing
def _interactive_loop() -> None:
    bot = ChatBot()
    try:
        while True:
            msg = input("> ").strip()
            if msg.lower() in {"exit", "quit"}:
                break
            print(json.dumps(bot.reply(msg), ensure_ascii=False))
    except (EOFError, KeyboardInterrupt):
        pass


if __name__ == "__main__":
    _interactive_loop()
\n================================================================================\nEND FILE: agenticcore\chatbot\services.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\cli.py\n================================================================================\n\n# /agenticcore/cli.py
"""
agenticcore.cli
Console entrypoints:
  - agentic: send a message to ChatBot and print reply JSON
  - repo-tree: print a filtered tree view (uses tree.txt if present)
  - repo-flatten: flatten code listing to stdout (uses FLATTENED_CODE.txt if present)
"""
import argparse, json, sys, traceback
from pathlib import Path
from dotenv import load_dotenv
import os

# Load .env variables into os.environ (project root .env by default)
load_dotenv()


def cmd_agentic(argv=None):
    # Lazy import so other commands don't require ChatBot to be importable
    from agenticcore.chatbot.services import ChatBot
    # We call analyze_sentiment only for 'status' to reveal the actual chosen provider
    try:
        from agenticcore.providers_unified import analyze_sentiment
    except Exception:
        analyze_sentiment = None  # still fine; we'll show mode only

    p = argparse.ArgumentParser(prog="agentic", description="Chat with AgenticCore ChatBot")
    p.add_argument("message", nargs="*", help="Message to send")
    p.add_argument("--debug", action="store_true", help="Print debug info")
    args = p.parse_args(argv)
    msg = " ".join(args.message).strip() or "hello"

    if args.debug:
        print(f"DEBUG argv={sys.argv}", flush=True)
        print(f"DEBUG raw message='{msg}'", flush=True)

    bot = ChatBot()

    # Special commands for testing / assignments
        # Special commands for testing / assignments
    if msg.lower() == "status":
        import requests  # local import to avoid hard dep for other commands

        # Try a lightweight provider probe via analyze_sentiment
        provider = None
        if analyze_sentiment is not None:
            try:
                probe = analyze_sentiment("status ping")
                provider = (probe or {}).get("provider")
            except Exception:
                if args.debug:
                    traceback.print_exc()

        # Hugging Face whoami auth probe
        tok = os.getenv("HF_API_KEY", "")
        who = None
        auth_ok = False
        err = None
        try:
            if tok:
                r = requests.get(
                    "https://huggingface.co/api/whoami-v2",
                    headers={"Authorization": f"Bearer {tok}"},
                    timeout=15,
                )
                auth_ok = (r.status_code == 200)
                who = r.json() if auth_ok else None
                if not auth_ok:
                    err = r.text  # e.g., {"error":"Invalid credentials in Authorization header"}
            else:
                err = "HF_API_KEY not set (load .env or export it)"
        except Exception as e:
            err = str(e)

        # Extract fine-grained scopes for visibility
        fg = (((who or {}).get("auth") or {}).get("accessToken") or {}).get("fineGrained") or {}
        scoped = fg.get("scoped") or []
        global_scopes = fg.get("global") or []

        # ---- tiny inference ping (proves 'Make calls to Inference Providers') ----
        infer_ok, infer_err = False, None
        try:
            if tok:
                model = os.getenv(
                    "HF_MODEL_SENTIMENT",
                    "distilbert-base-uncased-finetuned-sst-2-english"
                )
                r2 = requests.post(
                    f"https://api-inference.huggingface.co/models/{model}",
                    headers={"Authorization": f"Bearer {tok}", "x-wait-for-model": "true"},
                    json={"inputs": "ping"},
                    timeout=int(os.getenv("HTTP_TIMEOUT", "60")),
                )
                infer_ok = (r2.status_code == 200)
                if not infer_ok:
                    infer_err = f"HTTP {r2.status_code}: {r2.text}"
        except Exception as e:
            infer_err = str(e)
        # -------------------------------------------------------------------------

        # Mask + length to verify what .env provided
        mask = (tok[:3] + "..." + tok[-4:]) if tok else None
        out = {
            "provider": provider or "unknown",
            "mode": getattr(bot, "_mode", "auto"),
            "auth_ok": auth_ok,
            "whoami": who,
            "token_scopes": {            # <--- added
                "global": global_scopes,
                "scoped": scoped,
            },
            "inference_ok": infer_ok,
            "inference_error": infer_err,
            "env": {
                "HF_API_KEY_len": len(tok) if tok else 0,
                "HF_API_KEY_mask": mask,
                "HF_MODEL_SENTIMENT": os.getenv("HF_MODEL_SENTIMENT"),
                "HTTP_TIMEOUT": os.getenv("HTTP_TIMEOUT"),
            },
            "capabilities": bot.capabilities(),
            "error": err,
        }

    elif msg.lower() == "help":
        out = {"capabilities": bot.capabilities()}

    else:
        try:
            out = bot.reply(msg)
        except Exception as e:
            if args.debug:
                traceback.print_exc()
            out = {"error": str(e), "message": msg}

    if args.debug:
        print(f"DEBUG out={out}", flush=True)

    print(json.dumps(out, indent=2), flush=True)


def cmd_repo_tree(argv=None):
    p = argparse.ArgumentParser(prog="repo-tree", description="Print repo tree (from tree.txt if available)")
    p.add_argument("--path", default="tree.txt", help="Path to precomputed tree file")
    args = p.parse_args(argv)
    path = Path(args.path)
    if path.exists():
        print(path.read_text(encoding="utf-8"), flush=True)
    else:
        print("(no tree.txt found)", flush=True)


def cmd_repo_flatten(argv=None):
    p = argparse.ArgumentParser(prog="repo-flatten", description="Print flattened code listing")
    p.add_argument("--path", default="FLATTENED_CODE.txt", help="Path to pre-flattened code file")
    args = p.parse_args(argv)
    path = Path(args.path)
    if path.exists():
        print(path.read_text(encoding="utf-8"), flush=True)
    else:
        print("(no FLATTENED_CODE.txt found)", flush=True)


def _dispatch():
    # Allow: python -m agenticcore.cli <subcommand> [args...]
    if len(sys.argv) <= 1:
        print("Usage: python -m agenticcore.cli <agentic|repo-tree|repo-flatten> [args]", file=sys.stderr)
        sys.exit(2)
    cmd, argv = sys.argv[1], sys.argv[2:]
    try:
        if cmd == "agentic":
            cmd_agentic(argv)
        elif cmd == "repo-tree":
            cmd_repo_tree(argv)
        elif cmd == "repo-flatten":
            cmd_repo_flatten(argv)
        else:
            print(f"Unknown subcommand: {cmd}", file=sys.stderr)
            sys.exit(2)
    except SystemExit:
        raise
    except Exception:
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    _dispatch()
\n================================================================================\nEND FILE: agenticcore\cli.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\providers_unified.py\n================================================================================\n\n# /agenticcore/providers_unified.py
"""
providers_unified.py
Unified, switchable providers for sentiment + (optional) text generation.
Selection order unless AI_PROVIDER is set:
  HF -> AZURE -> OPENAI -> COHERE -> DEEPAI -> OFFLINE
Env vars:
  HF_API_KEY
  MICROSOFT_AI_SERVICE_ENDPOINT, MICROSOFT_AI_API_KEY
  OPENAI_API_KEY,  OPENAI_MODEL=gpt-3.5-turbo
  COHERE_API_KEY,  COHERE_MODEL=command
  DEEPAI_API_KEY
  AI_PROVIDER = hf|azure|openai|cohere|deepai|offline
  HTTP_TIMEOUT = 20
"""
from __future__ import annotations
import os, json
from typing import Dict, Any, Optional
import requests

TIMEOUT = float(os.getenv("HTTP_TIMEOUT", "20"))

def _env(name: str, default: Optional[str] = None) -> Optional[str]:
    v = os.getenv(name)
    return v if (v is not None and str(v).strip() != "") else default

def _pick_provider() -> str:
    forced = _env("AI_PROVIDER")
    if forced in {"hf", "azure", "openai", "cohere", "deepai", "offline"}:
        return forced
    if _env("HF_API_KEY"): return "hf"
    if _env("MICROSOFT_AI_API_KEY") and _env("MICROSOFT_AI_SERVICE_ENDPOINT"): return "azure"
    if _env("OPENAI_API_KEY"): return "openai"
    if _env("COHERE_API_KEY"): return "cohere"
    if _env("DEEPAI_API_KEY"): return "deepai"
    return "offline"

# ---------------------------
# Sentiment
# ---------------------------

def analyze_sentiment(text: str) -> Dict[str, Any]:
    provider = _pick_provider()
    try:
        if provider == "hf":     return _sentiment_hf(text)
        if provider == "azure":  return _sentiment_azure(text)
        if provider == "openai": return _sentiment_openai_prompt(text)
        if provider == "cohere": return _sentiment_cohere_prompt(text)
        if provider == "deepai": return _sentiment_deepai(text)
        return _sentiment_offline(text)
    except Exception as e:
        return {"provider": provider, "label": "neutral", "score": 0.5, "error": str(e)}

def _sentiment_offline(text: str) -> Dict[str, Any]:
    t = (text or "").lower()
    pos = any(w in t for w in ["love","great","good","awesome","fantastic","thank","excellent","amazing"])
    neg = any(w in t for w in ["hate","bad","terrible","awful","worst","angry","horrible"])
    label = "positive" if pos and not neg else "negative" if neg and not pos else "neutral"
    score = 0.9 if label != "neutral" else 0.5
    return {"provider": "offline", "label": label, "score": score}

def _sentiment_hf(text: str) -> Dict[str, Any]:
    """
    Hugging Face Inference API for sentiment.
    Uses canonical repo id and handles 404/401 and various payload shapes.
    """
    key = _env("HF_API_KEY")
    if not key:
        return _sentiment_offline(text)

    # canonical repo id to avoid 404
    model = _env("HF_MODEL_SENTIMENT", "distilbert/distilbert-base-uncased-finetuned-sst-2-english")
    timeout = int(_env("HTTP_TIMEOUT", "30"))

    headers = {
        "Authorization": f"Bearer {key}",
        "x-wait-for-model": "true",
        "Accept": "application/json",
        "Content-Type": "application/json",
    }

    r = requests.post(
        f"https://api-inference.huggingface.co/models/{model}",
        headers=headers,
        json={"inputs": text},
        timeout=timeout,
    )

    if r.status_code != 200:
        return {"provider": "hf", "label": "neutral", "score": 0.5, "error": f"HTTP {r.status_code}: {r.text[:500]}"}

    try:
        data = r.json()
    except Exception as e:
        return {"provider": "hf", "label": "neutral", "score": 0.5, "error": str(e)}

    if isinstance(data, dict) and "error" in data:
        return {"provider": "hf", "label": "neutral", "score": 0.5, "error": data["error"]}

    # normalize list shape
    arr = data[0] if isinstance(data, list) and data and isinstance(data[0], list) else (data if isinstance(data, list) else [])
    if not (isinstance(arr, list) and arr):
        return {"provider": "hf", "label": "neutral", "score": 0.5, "error": f"Unexpected payload: {data}"}

    top = max(arr, key=lambda x: x.get("score", 0.0) if isinstance(x, dict) else 0.0)
    raw = str(top.get("label", "")).upper()
    score = float(top.get("score", 0.5))

    mapping = {
        "LABEL_0": "negative", "LABEL_1": "neutral", "LABEL_2": "positive",
        "NEGATIVE": "negative", "NEUTRAL": "neutral", "POSITIVE": "positive",
    }
    label = mapping.get(raw, (raw.lower() or "neutral"))

    neutral_floor = float(os.getenv("SENTIMENT_NEUTRAL_THRESHOLD", "0.65"))
    if label in {"positive", "negative"} and score < neutral_floor:
        label = "neutral"

    return {"provider": "hf", "label": label, "score": score}

def _sentiment_azure(text: str) -> Dict[str, Any]:
    try:
        from azure.core.credentials import AzureKeyCredential  # type: ignore
        from azure.ai.textanalytics import TextAnalyticsClient  # type: ignore
    except Exception:
        return _sentiment_offline(text)
    endpoint = _env("MICROSOFT_AI_SERVICE_ENDPOINT")
    key = _env("MICROSOFT_AI_API_KEY")
    if not (endpoint and key): return _sentiment_offline(text)
    client = TextAnalyticsClient(endpoint=endpoint.strip(), credential=AzureKeyCredential(key.strip()))
    resp = client.analyze_sentiment(documents=[text], show_opinion_mining=False)[0]
    scores = {
        "positive": float(getattr(resp.confidence_scores, "positive", 0.0) or 0.0),
        "neutral":  float(getattr(resp.confidence_scores, "neutral",  0.0) or 0.0),
        "negative": float(getattr(resp.confidence_scores, "negative", 0.0) or 0.0),
    }
    label = max(scores, key=scores.get)
    return {"provider": "azure", "label": label, "score": scores[label]}

def _sentiment_openai_prompt(text: str) -> Dict[str, Any]:
    key = _env("OPENAI_API_KEY")
    model = _env("OPENAI_MODEL", "gpt-3.5-turbo")
    if not key: return _sentiment_offline(text)
    url = "https://api.openai.com/v1/chat/completions"
    prompt = f"Classify the sentiment of this text as positive, negative, or neutral. Reply JSON with keys label and score (0..1). Text: {text!r}"
    r = requests.post(
        url,
        headers={"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        json={"model": model, "messages": [{"role": "user", "content": prompt}], "temperature": 0},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    content = r.json()["choices"][0]["message"]["content"]
    try:
        obj = json.loads(content)
        label = str(obj.get("label", "neutral")).lower()
        score = float(obj.get("score", 0.5))
        return {"provider": "openai", "label": label, "score": score}
    except Exception:
        l = "positive" if "positive" in content.lower() else "negative" if "negative" in content.lower() else "neutral"
        return {"provider": "openai", "label": l, "score": 0.5}

def _sentiment_cohere_prompt(text: str) -> Dict[str, Any]:
    key = _env("COHERE_API_KEY")
    model = _env("COHERE_MODEL", "command")
    if not key: return _sentiment_offline(text)
    url = "https://api.cohere.ai/v1/generate"
    prompt = f"Classify the sentiment (positive, negative, neutral) and return JSON with keys label and score (0..1). Text: {text!r}"
    r = requests.post(
        url,
        headers={
            "Authorization": f"Bearer {key}",
            "Content-Type": "application/json",
            "Cohere-Version": "2022-12-06",
        },
        json={"model": model, "prompt": prompt, "max_tokens": 30, "temperature": 0},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    gen = (r.json().get("generations") or [{}])[0].get("text", "")
    try:
        obj = json.loads(gen)
        label = str(obj.get("label", "neutral")).lower()
        score = float(obj.get("score", 0.5))
        return {"provider": "cohere", "label": label, "score": score}
    except Exception:
        l = "positive" if "positive" in gen.lower() else "negative" if "negative" in gen.lower() else "neutral"
        return {"provider": "cohere", "label": l, "score": 0.5}

def _sentiment_deepai(text: str) -> Dict[str, Any]:
    key = _env("DEEPAI_API_KEY")
    if not key: return _sentiment_offline(text)
    url = "https://api.deepai.org/api/sentiment-analysis"
    r = requests.post(url, headers={"api-key": key}, data={"text": text}, timeout=TIMEOUT)
    r.raise_for_status()
    data = r.json()
    label = (data.get("output") or ["neutral"])[0].lower()
    return {"provider": "deepai", "label": label, "score": 0.5 if label == "neutral" else 0.9}

# ---------------------------
# Text generation (optional)
# ---------------------------

def generate_text(prompt: str, max_tokens: int = 128) -> Dict[str, Any]:
    provider = _pick_provider()
    try:
        if provider == "hf":     return _gen_hf(prompt, max_tokens)
        if provider == "openai": return _gen_openai(prompt, max_tokens)
        if provider == "cohere": return _gen_cohere(prompt, max_tokens)
        if provider == "deepai": return _gen_deepai(prompt, max_tokens)
        return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    except Exception as e:
        return {"provider": provider, "text": f"(error) {str(e)}"}

def _gen_hf(prompt: str, max_tokens: int) -> Dict[str, Any]:
    key = _env("HF_API_KEY")
    if not key: return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    model = _env("HF_MODEL_GENERATION", "tiiuae/falcon-7b-instruct")
    r = requests.post(
        f"https://api-inference.huggingface.co/models/{model}",
        headers={"Authorization": f"Bearer {key}"},
        json={"inputs": prompt, "parameters": {"max_new_tokens": max_tokens}},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    data = r.json()
    if isinstance(data, list) and data and "generated_text" in data[0]:
        return {"provider": "hf", "text": data[0]["generated_text"]}
    return {"provider": "hf", "text": str(data)}

def _gen_openai(prompt: str, max_tokens: int) -> Dict[str, Any]:
    key = _env("OPENAI_API_KEY")
    model = _env("OPENAI_MODEL", "gpt-3.5-turbo")
    if not key: return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    url = "https://api.openai.com/v1/chat/completions"
    r = requests.post(
        url,
        headers={"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        json={"model": model, "messages": [{"role": "user", "content": prompt}], "max_tokens": max_tokens},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    data = r.json()
    text = data["choices"][0]["message"]["content"]
    return {"provider": "openai", "text": text}

def _gen_cohere(prompt: str, max_tokens: int) -> Dict[str, Any]:
    key = _env("COHERE_API_KEY")
    model = _env("COHERE_MODEL", "command")
    if not key: return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    url = "https://api.cohere.ai/v1/generate"
    r = requests.post(
        url,
        headers={
            "Authorization": f"Bearer {key}",
            "Content-Type": "application/json",
            "Cohere-Version": "2022-12-06",
        },
        json={"model": model, "prompt": prompt, "max_tokens": max_tokens},
        timeout=TIMEOUT,
    )
    r.raise_for_status()
    data = r.json()
    text = data.get("generations", [{}])[0].get("text", "")
    return {"provider": "cohere", "text": text}

def _gen_deepai(prompt: str, max_tokens: int) -> Dict[str, Any]:
    key = _env("DEEPAI_API_KEY")
    if not key: return {"provider": "offline", "text": f"(offline) {prompt[:160]}"}
    url = "https://api.deepai.org/api/text-generator"
    r = requests.post(url, headers={"api-key": key}, data={"text": prompt}, timeout=TIMEOUT)
    r.raise_for_status()
    data = r.json()
    return {"provider": "deepai", "text": data.get("output", "")}
\n================================================================================\nEND FILE: agenticcore\providers_unified.py\n================================================================================\n\n================================================================================\nBEGIN FILE: agenticcore\web_agentic.py\n================================================================================\n\n# agenticcore/web_agentic.py
from fastapi import FastAPI, Query
from fastapi.responses import HTMLResponse
from agenticcore.chatbot.services import ChatBot

app = FastAPI(title="AgenticCore Web UI")

# 1. Simple HTML form at /
@app.get("/", response_class=HTMLResponse)
def index():
    return """
    <form action="/agentic" method="get">
        <input type="text" name="msg" placeholder="Type a message" style="width:300px">
        <input type="submit" value="Send">
    </form>
    """

# 2. Agentic endpoint
@app.get("/agentic")
def run_agentic(msg: str = Query(..., description="Message to send to ChatBot")):
    bot = ChatBot()
    return bot.reply(msg)
\n================================================================================\nEND FILE: agenticcore\web_agentic.py\n================================================================================\n\n================================================================================\nBEGIN FILE: anon_bot\handler.py\n================================================================================\n\n# anon_bot/handler.py
"""
Stateless(ish) turn handler for the anonymous chatbot.
Signature kept tiny: handle_turn(message, history, user) -> new_history
- message: str (user text)
- history: list of [speaker, text] or None
- user: dict-like info (ignored here, but accepted for compatibility)
"""

from __future__ import annotations
from typing import List, Tuple, Any
from . import rules

History = List[Tuple[str, str]]  # [("user","..."), ("bot","...")]

def _coerce_history(h: Any) -> History:
    if not h:
        return []
    # normalize to tuple pairs
    out: History = []
    for item in h:
        try:
            who, text = item[0], item[1]
        except Exception:
            continue
        out.append((str(who), str(text)))
    return out

def handle_turn(message: str, history: History | None, user: dict | None) -> History:
    hist = _coerce_history(history)
    user_text = (message or "").strip()
    if user_text:
        hist.append(("user", user_text))
    rep = rules.reply_for(user_text, hist)
    hist.append(("bot", rep.text))
    return hist

# Convenience: one-shot stringâ†’string (used by plain JSON endpoints)
def handle_text(message: str, history: History | None = None) -> str:
    new_hist = handle_turn(message, history, user=None)
    # last item is bot reply
    return new_hist[-1][1] if new_hist else ""
\n================================================================================\nEND FILE: anon_bot\handler.py\n================================================================================\n\n================================================================================\nBEGIN FILE: anon_bot\rules.py\n================================================================================\n\n# anon_bot/rules.py
"""
Lightweight rule set for an anonymous chatbot.
No external providers required. Pure-Python, deterministic.
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Tuple

# ---- Types ----
History = List[Tuple[str, str]]  # e.g., [("user","hi"), ("bot","hello!")]

@dataclass(frozen=True)
class Reply:
    text: str
    meta: Dict[str, str] | None = None


def normalize(s: str) -> str:
    return " ".join((s or "").strip().split()).lower()


def capabilities() -> List[str]:
    return [
        "help",
        "reverse <text>",
        "echo <text>",
        "small talk (hi/hello/hey)",
    ]


def intent_of(text: str) -> str:
    t = normalize(text)
    if not t:
        return "empty"
    if t in {"help", "/help", "capabilities"}:
        return "help"
    if t.startswith("reverse "):
        return "reverse"
    if t.startswith("echo "):
        return "echo"
    if t in {"hi", "hello", "hey"}:
        return "greet"
    return "chat"


def handle_help() -> Reply:
    lines = ["I can:"]
    for c in capabilities():
        lines.append(f"- {c}")
    return Reply("\n".join(lines))


def handle_reverse(t: str) -> Reply:
    payload = t.split(" ", 1)[1] if " " in t else ""
    return Reply(payload[::-1] if payload else "(nothing to reverse)")


def handle_echo(t: str) -> Reply:
    payload = t.split(" ", 1)[1] if " " in t else ""
    return Reply(payload or "(nothing to echo)")


def handle_greet() -> Reply:
    return Reply("Hello! ðŸ‘‹  Type 'help' to see what I can do.")


def handle_chat(t: str, history: History) -> Reply:
    # Very simple â€œELIZA-ishâ€ fallback.
    if "help" in t:
        return handle_help()
    if "you" in t and "who" in t:
        return Reply("I'm a tiny anonymous chatbot kernel.")
    return Reply("Noted. (anonymous mode)  Type 'help' for commands.")


def reply_for(text: str, history: History) -> Reply:
    it = intent_of(text)
    if it == "empty":
        return Reply("Please type something. Try 'help'.")
    if it == "help":
        return handle_help()
    if it == "reverse":
        return handle_reverse(text)
    if it == "echo":
        return handle_echo(text)
    if it == "greet":
        return handle_greet()
    return handle_chat(text.lower(), history)
\n================================================================================\nEND FILE: anon_bot\rules.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\app.py\n================================================================================\n\n# /app/app.py
#!/usr/bin/env python3
# app.py â€” aiohttp + Bot Framework (root-level). Routes added explicitly.
import os, sys, json
from aiohttp import web
from pathlib import Path
from botbuilder.core import BotFrameworkAdapter, BotFrameworkAdapterSettings, TurnContext, ActivityHandler
from botbuilder.schema import Activity

# Config / logging
from core.config import settings
from core.logging import setup_logging, get_logger

setup_logging(level=settings.log_level, json_logs=settings.json_logs)
log = get_logger("bootstrap")
log.info("starting", extra={"config": settings.to_dict()})

# Bot impl: prefer user's SimpleBot, fallback to tiny bot
try:
    from bot import SimpleBot as BotImpl  # user's ActivityHandler
except Exception:
    class BotImpl(ActivityHandler):
        async def on_turn(self, turn_context: TurnContext):
            if (turn_context.activity.type or "").lower() == "message":
                text = (turn_context.activity.text or "").strip()
                if not text:
                    await turn_context.send_activity("Input was empty. Type 'help' for usage.")
                    return
                lower = text.lower()
                if lower == "help":
                    await turn_context.send_activity("Try: echo <msg> | reverse: <msg> | capabilities")
                elif lower == "capabilities":
                    await turn_context.send_activity("- echo\n- reverse\n- help\n- capabilities")
                elif lower.startswith("reverse:"):
                    payload = text.split(":", 1)[1].strip()
                    await turn_context.send_activity(payload[::-1])
                elif lower.startswith("echo "):
                    await turn_context.send_activity(text[5:])
                else:
                    await turn_context.send_activity("Unsupported command. Type 'help' for examples.")
            else:
                await turn_context.send_activity(f"[{turn_context.activity.type}] event received.")

# Adapter / credentials
APP_ID = os.environ.get("MicrosoftAppId") or settings.microsoft_app_id
APP_PASSWORD = os.environ.get("MicrosoftAppPassword") or settings.microsoft_app_password
adapter_settings = BotFrameworkAdapterSettings(APP_ID, APP_PASSWORD)
adapter = BotFrameworkAdapter(adapter_settings)

async def on_error(context: TurnContext, error: Exception):
    print(f"[on_turn_error] {error}", file=sys.stderr, flush=True)
    try:
        await context.send_activity("Oops. Something went wrong!")
    except Exception as send_err:
        print(f"[on_turn_error][send_activity_failed] {send_err}", file=sys.stderr, flush=True)

adapter.on_turn_error = on_error
bot = BotImpl()

# Prefer project logic for /plain-chat; otherwise fallback to simple helpers
try:
    from logic import handle_text as _handle_text
except Exception:
    from skills import normalize, reverse_text, is_empty
    def _handle_text(user_text: str) -> str:
        text = (user_text or "").strip()
        if not text:
            return "Please provide text."
        cmd = normalize(text)
        if cmd in {"help", "capabilities"}:
            return "Try: reverse <text> | or just say anything"
        if cmd.startswith("reverse "):
            original = text.split(" ", 1)[1] if " " in text else ""
            return reverse_text(original)
        return f"You said: {text}"

# -------------------- HTTP handlers (module-level) --------------------
async def messages(req: web.Request) -> web.Response:
    ctype = (req.headers.get("Content-Type") or "").lower()
    if "application/json" not in ctype:
        return web.Response(status=415, text="Unsupported Media Type: expected application/json")
    try:
        body = await req.json()
    except json.JSONDecodeError:
        return web.Response(status=400, text="Invalid JSON body")

    activity = Activity().deserialize(body)
    auth_header = req.headers.get("Authorization")
    invoke_response = await adapter.process_activity(activity, auth_header, bot.on_turn)
    if invoke_response:
        return web.json_response(data=invoke_response.body, status=invoke_response.status)
    return web.Response(status=202, text="Accepted")

async def messages_get(_req: web.Request) -> web.Response:
    return web.Response(
        text="This endpoint only accepts POST (Bot Framework activities).",
        content_type="text/plain",
        status=405
    )

async def home(_req: web.Request) -> web.Response:
    return web.Response(
        text="Bot is running. POST Bot Framework activities to /api/messages.",
        content_type="text/plain"
    )

async def healthz(_req: web.Request) -> web.Response:
    return web.json_response({"status": "ok"})

async def plain_chat(req: web.Request) -> web.Response:
    try:
        payload = await req.json()
    except Exception:
        return web.json_response({"error": "Invalid JSON"}, status=400)
    user_text = payload.get("text", "")
    reply = _handle_text(user_text)
    return web.json_response({"reply": reply})

# -------------------- App factory --------------------
def create_app() -> web.Application:
    app = web.Application()

    # Add routes explicitly (as requested)
    app.router.add_get("/", home)
    app.router.add_get("/healthz", healthz)
    app.router.add_get("/api/messages", messages_get)
    app.router.add_post("/api/messages", messages)
    app.router.add_post("/plain-chat", plain_chat)

    # Optional CORS (if installed)
    try:
        import aiohttp_cors
        cors = aiohttp_cors.setup(app, defaults={
            "*": aiohttp_cors.ResourceOptions(
                allow_credentials=True,
                expose_headers="*",
                allow_headers="*",
                allow_methods=["GET","POST","OPTIONS"],
            )
        })
        for route in list(app.router.routes()):
            cors.add(route)
    except Exception:
        pass

    # Static (./static)
    static_dir = Path(__file__).parent / "static"
    if static_dir.exists():
        app.router.add_static("/static/", path=static_dir, show_index=True)
    else:
        log.warning("static directory not found", extra={"path": str(static_dir)})

    return app

app = create_app()

if __name__ == "__main__":
    web.run_app(app, host=settings.host, port=settings.port)
\n================================================================================\nEND FILE: app\app.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\assets\html\agenticcore_frontend.html\n================================================================================\n\n<!-- /app/assets/html/agenticcore_frontend.html -->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AgenticCore Chatbot Frontend</title>
  <style>
    :root {
      --bg: #0b0d12;
      --panel: #0f172a;
      --panel-2: #111827;
      --text: #e5e7eb;
      --muted: #9ca3af;
      --accent: #60a5fa;
      --border: #1f2940;
      --danger: #ef4444;
      --success: #22c55e;
    }
    * { box-sizing: border-box; }
    body { margin: 0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; background: var(--bg); color: var(--text); }
    .wrap { max-width: 920px; margin: 32px auto; padding: 0 16px; }
    header { display: flex; align-items: center; justify-content: space-between; margin-bottom: 16px; gap: 16px; }
    header h1 { font-size: 18px; margin: 0; letter-spacing: .3px; }
    header .badge { font-size: 12px; opacity: .85; padding: 4px 8px; border:1px solid var(--border); border-radius: 999px; background: rgba(255,255,255,0.03); }
    .card { background: var(--panel); border: 1px solid var(--border); border-radius: 16px; padding: 16px; }
    .row { display: flex; gap: 10px; align-items: center; }
    .stack { display: grid; gap: 12px; }
    label { font-size: 12px; color: var(--muted); }
    input[type=text] { flex: 1; padding: 12px 14px; border-radius: 12px; border: 1px solid var(--border); background: var(--panel-2); color: var(--text); outline: none; }
    input[type=text]::placeholder { color: #6b7280; }
    button { padding: 10px 14px; border-radius: 12px; border: 1px solid var(--border); background: #1f2937; color: var(--text); cursor: pointer; transition: transform .02s ease, background .2s; }
    button:hover { background: #273449; }
    button:active { transform: translateY(1px); }
    .btn-primary { background: #1f2937; border-color: #31405a; }
    .btn-ghost { background: transparent; border-color: var(--border); }
    .grid { display: grid; gap: 12px; }
    .grid-2 { grid-template-columns: 1fr 1fr; }
    .log { margin-top: 16px; display: grid; gap: 10px; }
    .bubble { max-width: 80%; padding: 12px 14px; border-radius: 14px; line-height: 1.35; }
    .user { background: #1e293b; border:1px solid #2b3b55; margin-left: auto; border-bottom-right-radius: 4px; }
    .bot  { background: #0d1b2a; border:1px solid #223049; margin-right: auto; border-bottom-left-radius: 4px; }
    .meta { font-size: 12px; color: var(--muted); margin-top: 4px; }
    pre { margin: 0; white-space: pre-wrap; word-break: break-word; }
    .status { display:flex; align-items:center; gap:8px; font-size: 12px; color: var(--muted); }
    .dot { width:8px; height:8px; border-radius:999px; background: #64748b; display:inline-block; }
    .dot.ok { background: var(--success); }
    .dot.bad { background: var(--danger); }
    footer { margin: 24px 0; text-align:center; color: var(--muted); font-size: 12px; }
    .small { font-size: 12px; }
    @media (max-width: 700px) { .grid-2 { grid-template-columns: 1fr; } }
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <h1>AgenticCore Chatbot Frontend</h1>
      <div class="badge">Frontend â†’ FastAPI â†’ providers_unified</div>
    </header>

    <section class="card stack">
      <div class="grid grid-2">
        <div class="stack">
          <label for="backend">Backend URL</label>
          <div class="row">
            <input id="backend" type="text" placeholder="http://127.0.0.1:8000" />
            <button id="save" class="btn-ghost">Save</button>
          </div>
          <div class="status" id="status"><span class="dot"></span><span>Not checked</span></div>
        </div>
        <div class="stack">
          <label for="message">Message</label>
          <div class="row">
            <input id="message" type="text" placeholder="Type a messageâ€¦" />
            <button id="send" class="btn-primary">Send</button>
          </div>
          <div class="row">
            <button id="cap" class="btn-ghost small">Capabilities</button>
            <button id="health" class="btn-ghost small">Health</button>
            <button id="clear" class="btn-ghost small">Clear</button>
          </div>
        </div>
      </div>
      <div class="log" id="log"></div>
    </section>

    <footer>
      Use with your FastAPI backend at <code>/chatbot/message</code>. Configure CORS if you serve this file from a different origin.
    </footer>
  </div>

  <script>
    const $ = (sel) => document.querySelector(sel);
    const backendInput = $('#backend');
    const sendBtn = $('#send');
    const saveBtn = $('#save');
    const msgInput = $('#message');
    const capBtn = $('#cap');
    const healthBtn = $('#health');
    const clearBtn = $('#clear');
    const log = $('#log');
    const status = $('#status');
    const dot = status.querySelector('.dot');
    const statusText = status.querySelector('span:last-child');

    function getBackendUrl() {
      return localStorage.getItem('BACKEND_URL') || 'http://127.0.0.1:8000';
    }
    function setBackendUrl(v) {
      localStorage.setItem('BACKEND_URL', v);
    }
    function cardUser(text) {
      const div = document.createElement('div');
      div.className = 'bubble user';
      div.textContent = text;
      log.appendChild(div);
      log.scrollTop = log.scrollHeight;
    }
    function cardBot(obj) {
      const wrap = document.createElement('div');
      wrap.className = 'bubble bot';
      const pre = document.createElement('pre');
      pre.textContent = typeof obj === 'string' ? obj : JSON.stringify(obj, null, 2);
      wrap.appendChild(pre);
      log.appendChild(wrap);
      log.scrollTop = log.scrollHeight;
    }
    function setStatus(ok, text) {
      dot.classList.toggle('ok', !!ok);
      dot.classList.toggle('bad', ok === false);
      statusText.textContent = text || (ok ? 'OK' : 'Error');
    }
    async function api(path, init) {
      const base = backendInput.value.trim().replace(/\/$/, '');
      const url = base + path;
      const resp = await fetch(url, init);
      if (!resp.ok) {
        let t = await resp.text().catch(() => '');
        throw new Error(`HTTP ${resp.status} ${resp.statusText} â€” ${t}`);
      }
      const contentType = resp.headers.get('content-type') || '';
      if (contentType.includes('application/json')) return resp.json();
      return resp.text();
    }

    async function checkHealth() {
      try {
        const h = await api('/health', { method: 'GET' });
        setStatus(true, 'Healthy');
        cardBot({ health: h });
      } catch (e) {
        setStatus(false, String(e.message || e));
        cardBot({ error: String(e.message || e) });
      }
    }

    async function sendMessage() {
      const text = msgInput.value.trim();
      if (!text) return;
      cardUser(text);
      msgInput.value = '';
      try {
        const data = await api('/chatbot/message', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ message: text })
        });
        cardBot(data);
      } catch (e) {
        cardBot({ error: String(e.message || e) });
      }
    }

    async function showCapabilities() {
      try {
        // Prefer API if available; if 404, fall back to library-like prompt.
        const data = await api('/chatbot/message', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ message: 'help' })
        });
        cardBot(data);
      } catch (e) {
        cardBot({ capabilities: ['text-input','sentiment-analysis','help'], note: 'API help failed, showing defaults', error: String(e.message || e) });
      }
    }

    // Wire up
    backendInput.value = getBackendUrl();
    saveBtn.onclick = () => { setBackendUrl(backendInput.value.trim()); setStatus(null, 'Saved'); };
    sendBtn.onclick = sendMessage;
    msgInput.addEventListener('keydown', (ev) => { if (ev.key === 'Enter') sendMessage(); });
    capBtn.onclick = showCapabilities;
    healthBtn.onclick = checkHealth;
    clearBtn.onclick = () => { log.innerHTML = ''; setStatus(null, 'Idle'); };

    // Initial health ping
    checkHealth();
  </script>
</body>
</html>
\n================================================================================\nEND FILE: app\assets\html\agenticcore_frontend.html\n================================================================================\n\n================================================================================\nBEGIN FILE: app\assets\html\chat.html\n================================================================================\n\n<!-- /app/assets/html/chat.html -->
<!doctype html>
<html><head><meta charset="utf-8"/><title>Simple Chat</title>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<style>
:root { --bg:#f6f7f9; --card:#fff; --me:#dff1ff; --bot:#ffffff; --text:#23262b; --muted:#8a9099; }
body { margin:0; font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif; background:var(--bg); color:var(--text); }
.app { max-width:840px; margin:24px auto; padding:0 16px; }
.card { background:var(--card); border:1px solid #e3e6ea; border-radius:14px; box-shadow:0 1px 2px rgba(0,0,0,.04); overflow:hidden; }
.header { padding:14px 16px; border-bottom:1px solid #e9edf2; font-weight:600; }
.chat { height:480px; overflow:auto; padding:16px; display:flex; flex-direction:column; gap:12px; }
.row { display:flex; }
.row.me { justify-content:flex-end; }
.bubble { max-width:70%; padding:10px 12px; border-radius:12px; line-height:1.35; white-space:pre-wrap; }
.me .bubble { background:var(--me); border:1px solid #c3e5ff; }
.bot .bubble { background:var(--bot); border:1px solid #e5e8ec; }
.footer { display:flex; gap:8px; padding:12px; border-top:1px solid #e9edf2; }
input[type=text] { flex:1; padding:10px 12px; border-radius:10px; border:1px solid #d5dbe3; font-size:15px; }
button { padding:10px 14px; border-radius:10px; border:1px solid #2b6cb0; background:#2b6cb0; color:#fff; font-weight:600; cursor:pointer; }
button:disabled { opacity:.6; cursor:not-allowed; }
.hint { color:var(--muted); font-size:12px; padding:0 16px 12px; }
</style></head>
<body>
<div class="app"><div class="card">
  <div class="header">Traditional Chatbot (Local)</div>
  <div id="chat" class="chat"></div>
  <div class="hint">Try: <code>reverse: hello world</code>, <code>help</code>, <code>capabilities</code></div>
  <div class="footer">
    <input id="msg" type="text" placeholder="Type a message..." autofocus />
    <button id="send">Send</button>
  </div>
</div></div>
<script>
const API = "http://127.0.0.1:3978/plain-chat";
const chat = document.getElementById("chat");
const input = document.getElementById("msg");
const sendBtn = document.getElementById("send");
function addBubble(text, who) {
  const row = document.createElement("div"); row.className = "row " + who;
  const wrap = document.createElement("div"); wrap.className = who === "me" ? "me" : "bot";
  const b = document.createElement("div"); b.className = "bubble"; b.textContent = text;
  wrap.appendChild(b); row.appendChild(wrap); chat.appendChild(row); chat.scrollTop = chat.scrollHeight;
}
async function send() {
  const text = input.value.trim(); if (!text) return; input.value = ""; addBubble(text, "me"); sendBtn.disabled = true;
  try {
    const res = await fetch(API, { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ text }) });
    if (!res.ok) throw new Error("HTTP " + res.status);
    const data = await res.json(); addBubble(data.reply ?? "(no reply)", "bot");
  } catch (err) { addBubble("Error: " + err.message, "bot"); }
  finally { sendBtn.disabled = false; input.focus(); }
}
sendBtn.addEventListener("click", send);
input.addEventListener("keydown", (e)=>{ if (e.key === "Enter") send(); });
addBubble("Connected to local bot at /plain-chat", "bot");
</script>
</body></html>
\n================================================================================\nEND FILE: app\assets\html\chat.html\n================================================================================\n\n================================================================================\nBEGIN FILE: app\assets\html\chat_console.html\n================================================================================\n\n<!-- /app/assets/html/chat_console.html -->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Console Chat Tester</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body{ font-family: ui-sans-serif, system-ui, Arial; margin:20px; }
    .row{ display:flex; gap:8px; align-items:center; margin:6px 0; }
    input[type=text]{ flex:1; padding:8px; }
    button{ padding:8px 10px; }
    pre{ background:#0b1020; color:#d6e7ff; padding:10px; height:320px; overflow:auto; }
    .chip{ display:inline-block; padding:3px 8px; background:#eef; border-radius:12px; margin-left:8px; }
  </style>
</head>
<body>
<h2>AgenticCore Console</h2>

<div class="row">
  <label>Backend</label>
  <input id="base" type="text" value="http://127.0.0.1:8000" />
  <button id="btnHealth">Health</button>
  <button id="btnRoutes">Routes</button>
</div>

<div class="row">
  <input id="msg" type="text" placeholder="Say somethingâ€¦" />
  <button id="btnSend">POST /chatbot/message</button>
</div>

<div>
  <span>Mode:</span>
  <span id="mode" class="chip">API</span>
</div>

<pre id="out"></pre>

<script>
const $ = id => document.getElementById(id);
const out = $("out");
function print(o){ out.textContent += (typeof o==="string" ? o : JSON.stringify(o,null,2)) + "\n"; out.scrollTop = out.scrollHeight; }
function join(b, p){ return b.replace(/\/+$/,"") + p; }

async function health(){
  try{
    const r = await fetch(join($("base").value, "/health"));
    print(await r.json());
  }catch(e){ print("health error: " + e); }
}
async function routes(){
  try{
    const r = await fetch(join($("base").value, "/openapi.json"));
    const j = await r.json();
    print({ routes: Object.keys(j.paths) });
  }catch(e){ print("routes error: " + e); }
}
async function send(){
  const text = $("msg").value.trim();
  if(!text){ print("enter a message first"); return; }
  try{
    const r = await fetch(join($("base").value, "/chatbot/message"), {
      method:"POST",
      headers:{ "Content-Type":"application/json" },
      body: JSON.stringify({ message: text })
    });
    print(await r.json());
  }catch(e){ print("send error: " + e); }
}
$("btnHealth").onclick = health;
$("btnRoutes").onclick = routes;
$("btnSend").onclick = send;

// boot
health();
</script>
</body>
</html>
\n================================================================================\nEND FILE: app\assets\html\chat_console.html\n================================================================================\n\n================================================================================\nBEGIN FILE: app\assets\html\chat_minimal.html\n================================================================================\n\n<!-- /app/assets/html/chat_minimal.html -->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Minimal Chat Tester</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 24px; }
    .row { display:flex; gap:8px; align-items:center; margin-bottom:8px; }
    input[type=text]{ width:420px; padding:8px; }
    textarea{ width:100%; height:240px; padding:8px; }
    button{ padding:8px 12px; }
    .ok{ color:#1a7f37; }
    .warn{ color:#b54708; }
    .err{ color:#b42318; }
  </style>
</head>
<body>
<h2>Minimal Chat Tester â†’ FastAPI /chatbot/message</h2>

<div class="row">
  <label>Backend URL:</label>
  <input id="base" type="text" value="http://127.0.0.1:8000" />
  <button id="btnHealth">Health</button>
  <button id="btnCaps">Capabilities</button>
</div>

<div class="row">
  <input id="msg" type="text" placeholder="Type a messageâ€¦" />
  <button id="btnSend">Send</button>
</div>

<p id="status"></p>
<textarea id="log" readonly></textarea>

<script>
const $ = id => document.getElementById(id);
const log = (o, cls="") => {
  const line = (typeof o === "string") ? o : JSON.stringify(o, null, 2);
  $("log").value += line + "\n";
  $("log").scrollTop = $("log").scrollHeight;
  if(cls) { $("status").className = cls; $("status").textContent = line; }
};

function urlJoin(base, path) {
  return base.replace(/\/+$/,"") + path;
}

async function health() {
  try {
    const r = await fetch(urlJoin($("base").value, "/health"));
    const j = await r.json();
    log(j, "ok");
  } catch (e) { log("Health error: " + e, "err"); }
}

async function caps() {
  try {
    // Prefer library-like caps endpoint if you expose one; otherwise call /openapi.json for visibility
    const r = await fetch(urlJoin($("base").value, "/openapi.json"));
    const j = await r.json();
    log({paths: Object.keys(j.paths).slice(0,20)}, "ok");
  } catch (e) { log("Caps error: " + e, "err"); }
}

async function sendMsg() {
  const text = $("msg").value.trim();
  if(!text) { log("Please type a message.", "warn"); return; }
  try {
    const r = await fetch(urlJoin($("base").value, "/chatbot/message"), {
      method:"POST",
      headers:{ "Content-Type":"application/json" },
      body: JSON.stringify({ message: text })
    });
    if(!r.ok) throw new Error(`${r.status} ${r.statusText}`);
    const j = await r.json();
    log(j, "ok");
  } catch (e) { log("Send error: " + e, "err"); }
}

$("btnHealth").onclick = health;
$("btnCaps").onclick = caps;
$("btnSend").onclick = sendMsg;

// Warmup
health();
</script>
</body>
</html>
\n================================================================================\nEND FILE: app\assets\html\chat_minimal.html\n================================================================================\n\n================================================================================\nBEGIN FILE: app\mbf_bot\__init__.py\n================================================================================\n\n\n================================================================================\nEND FILE: app\mbf_bot\__init__.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\mbf_bot\bot.py\n================================================================================\n\n# /app/bot.py
"""
Simple MBF bot:
- 'help' / 'capabilities' shows features
- 'reverse <text>' returns reversed text
- otherwise delegates to AgenticCore ChatBot (sentiment) if available
"""

from typing import List, Optional, Dict, Any
from botbuilder.core import ActivityHandler, TurnContext
from botbuilder.schema import ChannelAccount, ActivityTypes

from skills import normalize, reverse_text, capabilities, is_empty

# Try to import AgenticCore; if unavailable, provide a tiny fallback.
try:
    from agenticcore.chatbot.services import ChatBot  # real provider-backed bot
except Exception:
    class ChatBot:  # fallback shim for offline/dev
        def reply(self, message: str) -> Dict[str, Any]:
            return {
                "reply": "Noted. (local fallback reply)",
                "sentiment": "neutral",
                "confidence": 0.5,
            }

def _format_sentiment(res: Dict[str, Any]) -> str:
    """Compose a user-facing string from ChatBot reply payload."""
    reply = (res.get("reply") or "").strip()
    label: Optional[str] = res.get("sentiment")
    conf = res.get("confidence")
    if label is not None and conf is not None:
        return f"{reply} (sentiment: {label}, confidence: {float(conf):.2f})"
    return reply or "I'm not sure what to say."

def _help_text() -> str:
    """Single source of truth for the help/capability text."""
    feats = "\n".join(f"- {c}" for c in capabilities())
    return (
        "I can reverse text and provide concise replies with sentiment.\n"
        "Commands:\n"
        "- help | capabilities\n"
        "- reverse <text>\n"
        "General text will be handled by the ChatBot service.\n\n"
        f"My capabilities:\n{feats}"
    )

class SimpleBot(ActivityHandler):
    """Minimal ActivityHandler with local commands + ChatBot fallback."""

    def __init__(self, chatbot: Optional[ChatBot] = None):
        self._chatbot = chatbot or ChatBot()

    async def on_members_added_activity(
        self, members_added: List[ChannelAccount], turn_context: TurnContext
    ):
        for member in members_added:
            if member.id != turn_context.activity.recipient.id:
                await turn_context.send_activity("Hello! Type 'help' to see what I can do.")

    async def on_message_activity(self, turn_context: TurnContext):
        if turn_context.activity.type != ActivityTypes.message:
            return

        text = (turn_context.activity.text or "").strip()
        if is_empty(text):
            await turn_context.send_activity("Please enter a message (try 'help').")
            return

        cmd = normalize(text)

        if cmd in {"help", "capabilities"}:
            await turn_context.send_activity(_help_text())
            return

        if cmd.startswith("reverse "):
            original = text.split(" ", 1)[1] if " " in text else ""
            await turn_context.send_activity(reverse_text(original))
            return

        # ChatBot fallback (provider-agnostic sentiment/reply)
        try:
            result = self._chatbot.reply(text)
            await turn_context.send_activity(_format_sentiment(result))
        except Exception:
            await turn_context.send_activity(f"You said: {text}")
\n================================================================================\nEND FILE: app\mbf_bot\bot.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\mbf_bot\skills.py\n================================================================================\n\n# /app/skills.py
"""
Small, dependency-free helpers used by the MBF SimpleBot.
"""

from typing import List

_CAPS: List[str] = [
    "echo-reverse",          # reverse <text>
    "help",                  # help / capabilities
    "chatbot-sentiment",     # delegate to ChatBot() if available
]

def normalize(text: str) -> str:
    """Normalize user text for lightweight command routing."""
    return (text or "").strip().lower()

def reverse_text(text: str) -> str:
    """Return the input string reversed."""
    return (text or "")[::-1]

def capabilities() -> List[str]:
    """Return a stable list of bot capabilities."""
    return list(_CAPS)

def is_empty(text: str) -> bool:
    """True if message is blank after trimming."""
    return len((text or "").strip()) == 0
\n================================================================================\nEND FILE: app\mbf_bot\skills.py\n================================================================================\n\n================================================================================\nBEGIN FILE: app\routes.py\n================================================================================\n\n# /app/routes.py â€” HTTP handlers
# routes.py â€” HTTP handlers (root-level, no /app package)
import json
from aiohttp import web
from botbuilder.schema import Activity

# Prefer project logic if available
try:
    from logic import handle_text as _handle_text  # user-defined
except Exception:
    from skills import normalize, reverse_text, is_empty
    def _handle_text(user_text: str) -> str:
        text = (user_text or "").strip()
        if not text:
            return "Please provide text."
        cmd = normalize(text)
        if cmd in {"help", "capabilities"}:
            return "Try: reverse <text> | or just say anything"
        if cmd.startswith("reverse "):
            original = text.split(" ", 1)[1] if " " in text else ""
            return reverse_text(original)
        return f"You said: {text}"

def init_routes(app: web.Application, adapter, bot) -> None:
    async def messages(req: web.Request) -> web.Response:
        ctype = (req.headers.get("Content-Type") or "").lower()
        if "application/json" not in ctype:
            return web.Response(status=415, text="Unsupported Media Type: expected application/json")
        try:
            body = await req.json()
        except json.JSONDecodeError:
            return web.Response(status=400, text="Invalid JSON body")

        activity = Activity().deserialize(body)
        auth_header = req.headers.get("Authorization")

        invoke_response = await adapter.process_activity(activity, auth_header, bot.on_turn)
        if invoke_response:
            return web.json_response(data=invoke_response.body, status=invoke_response.status)
        return web.Response(status=202, text="Accepted")

    async def messages_get(_req: web.Request) -> web.Response:
        return web.Response(
            text="This endpoint only accepts POST (Bot Framework activities).",
            content_type="text/plain",
            status=405
        )

    async def home(_req: web.Request) -> web.Response:
        return web.Response(
            text="Bot is running. POST Bot Framework activities to /api/messages.",
            content_type="text/plain"
        )

    async def healthz(_req: web.Request) -> web.Response:
        return web.json_response({"status": "ok"})

    async def plain_chat(req: web.Request) -> web.Response:
        try:
            payload = await req.json()
        except Exception:
            return web.json_response({"error": "Invalid JSON"}, status=400)
        user_text = payload.get("text", "")
        reply = _handle_text(user_text)
        return web.json_response({"reply": reply})

    # Wire routes
    app.router.add_get("/", home)
    app.router.add_get("/healthz", healthz)
    app.router.add_get("/api/messages", messages_get)
    app.router.add_post("/api/messages", messages)
    app.router.add_post("/plain-chat", plain_chat)
\n================================================================================\nEND FILE: app\routes.py\n================================================================================\n\n================================================================================\nBEGIN FILE: core\config.py\n================================================================================\n\n# /core/config.py
from __future__ import annotations
import os
from dataclasses import dataclass, field
from typing import List, Optional


def _as_bool(v: Optional[str], default: bool = False) -> bool:
    if v is None:
        return default
    return v.strip().lower() in {"1", "true", "yes", "y", "on"}

def _as_int(v: Optional[str], default: int) -> int:
    try:
        return int(v) if v is not None else default
    except ValueError:
        return default

def _as_list(v: Optional[str], default: List[str] | None = None) -> List[str]:
    if not v:
        return list(default or [])
    return [item.strip() for item in v.split(",") if item.strip()]


@dataclass(slots=True)
class Settings:
    # Runtime / environment
    env: str = field(default_factory=lambda: os.getenv("ENV", "dev"))
    debug: bool = field(default_factory=lambda: _as_bool(os.getenv("DEBUG"), False))

    # Host/port
    host: str = field(default_factory=lambda: os.getenv("HOST", "127.0.0.1"))
    port: int = field(default_factory=lambda: _as_int(os.getenv("PORT"), 3978))

    # Logging
    log_level: str = field(default_factory=lambda: os.getenv("LOG_LEVEL", "INFO"))
    json_logs: bool = field(default_factory=lambda: _as_bool(os.getenv("JSON_LOGS"), False))

    # CORS
    cors_allow_origins: List[str] = field(
        default_factory=lambda: _as_list(os.getenv("CORS_ALLOW_ORIGINS"), ["*"])
    )
    cors_allow_methods: List[str] = field(
        default_factory=lambda: _as_list(os.getenv("CORS_ALLOW_METHODS"), ["GET", "POST", "OPTIONS"])
    )
    cors_allow_headers: List[str] = field(
        default_factory=lambda: _as_list(os.getenv("CORS_ALLOW_HEADERS"), ["*"])
    )

    # Bot Framework credentials
    microsoft_app_id: Optional[str] = field(default_factory=lambda: os.getenv("MicrosoftAppId"))
    microsoft_app_password: Optional[str] = field(default_factory=lambda: os.getenv("MicrosoftAppPassword"))

    def to_dict(self) -> dict:
        return {
            "env": self.env,
            "debug": self.debug,
            "host": self.host,
            "port": self.port,
            "log_level": self.log_level,
            "json_logs": self.json_logs,
            "cors_allow_origins": self.cors_allow_origins,
            "cors_allow_methods": self.cors_allow_methods,
            "cors_allow_headers": self.cors_allow_headers,
            "microsoft_app_id": bool(self.microsoft_app_id),
            "microsoft_app_password": bool(self.microsoft_app_password),
        }


# singleton-style settings object
settings = Settings()
\n================================================================================\nEND FILE: core\config.py\n================================================================================\n\n================================================================================\nBEGIN FILE: core\logging.py\n================================================================================\n\n# /core/logging.py
from __future__ import annotations
import json
import logging
import sys
from datetime import datetime
from typing import Optional

try:
    # Optional: human-friendly console colors if installed
    import colorama  # type: ignore
    colorama.init()
    _HAS_COLOR = True
except Exception:  # pragma: no cover
    _HAS_COLOR = False

# Very small JSON formatter (avoids extra deps)
class JsonFormatter(logging.Formatter):
    def format(self, record: logging.LogRecord) -> str:  # type: ignore[override]
        payload = {
            "ts": datetime.utcfromtimestamp(record.created).isoformat(timespec="milliseconds") + "Z",
            "level": record.levelname,
            "logger": record.name,
            "msg": record.getMessage(),
        }
        if record.exc_info:
            payload["exc_info"] = self.formatException(record.exc_info)
        return json.dumps(payload, ensure_ascii=False)

class ConsoleFormatter(logging.Formatter):
    def format(self, record: logging.LogRecord) -> str:  # type: ignore[override]
        ts = datetime.utcfromtimestamp(record.created).strftime("%H:%M:%S")
        lvl = record.levelname
        name = record.name
        msg = record.getMessage()

        if _HAS_COLOR:
            COLORS = {
                "DEBUG": "\033[37m",
                "INFO": "\033[36m",
                "WARNING": "\033[33m",
                "ERROR": "\033[31m",
                "CRITICAL": "\033[41m",
            }
            RESET = "\033[0m"
            color = COLORS.get(lvl, "")
            return f"{ts} {color}{lvl:<8}{RESET} {name}: {msg}"
        return f"{ts} {lvl:<8} {name}: {msg}"


_initialized = False

def setup_logging(level: str = "INFO", json_logs: bool = False) -> None:
    """
    Initialize root logger once.
    """
    global _initialized
    if _initialized:
        return
    _initialized = True

    root = logging.getLogger()
    root.setLevel(level.upper())

    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(JsonFormatter() if json_logs else ConsoleFormatter())
    root.handlers[:] = [handler]


def get_logger(name: Optional[str] = None) -> logging.Logger:
    """
    Get a logger (call setup_logging() first to configure formatting).
    """
    return logging.getLogger(name or "app")
\n================================================================================\nEND FILE: core\logging.py\n================================================================================\n\n================================================================================\nBEGIN FILE: core\types.py\n================================================================================\n\n# /core/types.py
from __future__ import annotations
from dataclasses import dataclass, field, asdict
from typing import Any, Dict, List, Literal, Optional, Tuple, TypedDict

Role = Literal["system", "user", "assistant"]

# Basic chat message
@dataclass(slots=True)
class ChatMessage:
    role: Role
    content: str

# Pair-based history (simple UI / anon_bot style)
ChatTurn = List[str]                # [user, bot]
ChatHistory = List[ChatTurn]        # [[u,b], [u,b], ...]

# Plain chat API payloads (/plain-chat)
@dataclass(slots=True)
class PlainChatRequest:
    text: str

@dataclass(slots=True)
class PlainChatResponse:
    reply: str
    meta: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

# Optional error shape for consistent JSON error responses
class ErrorPayload(TypedDict, total=False):
    error: str
    detail: str
\n================================================================================\nEND FILE: core\types.py\n================================================================================\n\n================================================================================\nBEGIN FILE: docs\architecture.md\n================================================================================\n\n<!-- /docs/slides/architecture.md -->
# Architecture

This system follows a **modular chatbot architecture** built around a clear flow of data from the user interface to external services and back. The design emphasizes separation of concerns, allowing each module to handle a specific responsibility while keeping the overall system simple to test and extend.

---

## High-Level Flow (tied to flowchart)

1. **User Interface (UI)**  
   - The entry point for user interaction.  
   - Implemented through a web client (e.g., Gradio, HTML templates, or API endpoint).  
   - Captures user input and displays bot responses.

2. **Router / Core Logic**  
   - Handles conversation state and routes messages.  
   - Delegates to either the anonymous bot, logged-in bot, or agentic extensions.  
   - Imports lightweight rules from `anon_bot/rules.py` for anonymous sessions, and integrates with advanced providers for logged-in sessions.

3. **NLU (Natural Language Understanding)**  
   - Managed by the `nlu/` pipeline (intent recognition, prompts, and routing).  
   - Provides preprocessing, normalization, and optional summarization/RAG.  
   - Keeps the system extensible for additional models without changing the rest of the stack.

4. **Memory & Context Layer**  
   - Implemented in `memory/` (sessions, store, and optional RAG retriever/indexer).  
   - Stores session history, enabling context-aware responses.  
   - Supports modular backends (in-memory, file-based, or vector index).

5. **External AI Service Connector (optional)**  
   - For logged-in flows, integrates with cloud AIaaS (e.g., Azure, HuggingFace, or open-source LLMs).  
   - Uses `logged_in_bot/sentiment_azure.py` or `agenticcore/providers_unified.py`.  
   - Provides NLP services like sentiment analysis or summarization.  
   - Disabled in anonymous mode for privacy.

6. **Guardrails & Safety**  
   - Defined in `guardrails/` (PII redaction, safety filters).  
   - Applied before responses are shown to the user.  
   - Ensures compliance with privacy/security requirements.

7. **Outputs**  
   - Bot response returned to the UI.  
   - Logs written via `core/logging.py` for traceability and debugging.  
   - Optional screenshots and reports recorded for evaluation.

---

## Key Principles

- **Modularity**: Each part of the flow is a self-contained module (UI, NLU, memory, guardrails).  
- **Swap-in Providers**: Agentic core can switch between local rules, RAG memory, or external APIs.  
- **Anonymous vs Logged-In**: Anonymous bot uses lightweight rules with no external calls; logged-in bot can call providers.  
- **Extensibility**: Flowchart design makes it easy to add summarization, conversation modes, or other â€œagenticâ€ behaviors without rewriting the core.  
- **Resilience**: If an external service fails, the system degrades gracefully to local responses.

---

## Mapping to Repo Structure

- `app/` â†’ User-facing entrypoint (routes, HTML, API).  
- `anon_bot/` â†’ Anonymous chatbot rules + handler.  
- `logged_in_bot/` â†’ Provider-based flows for authenticated users.  
- `nlu/` â†’ Intent routing, prompts, pipeline.  
- `memory/` â†’ Session management + RAG integration.  
- `guardrails/` â†’ Safety filters + PII redaction.  
- `agenticcore/` â†’ Core integration logic and unified providers.  
- `docs/flowchart.png` â†’ Visual representation of this architecture.

---

## Summary

The architecture ensures a **clean separation between interface, logic, and services**, enabling experimentation with different providers while guaranteeing a safe, privacy-friendly anonymous mode. The flowchart illustrates this layered approach: input â†’ logic â†’ NLU/memory â†’ optional AIaaS â†’ guardrails â†’ output.
\n================================================================================\nEND FILE: docs\architecture.md\n================================================================================\n\n================================================================================\nBEGIN FILE: docs\design.md\n================================================================================\n\n<!-- /docs/slides/design.md -->
# Design Notes

These notes document the reasoning behind major design choices, focusing on **API usage**, **security considerations**, and **tradeoffs** made during development.

---

## API Notes

- **Anonymous vs Logged-In Flows**  
  - The **anonymous chatbot** relies purely on local rules (`anon_bot/rules.py`) and does not call any external services.  
  - The **logged-in chatbot** integrates with external AIaaS endpoints (e.g., Azure, HuggingFace, or other NLP providers) via modules in `logged_in_bot/` and `agenticcore/providers_unified.py`.  

- **Endpoints**  
  - `/plain-chat` â†’ Anonymous flow; maps to `logic.handle_text`.  
  - `/api/messages` â†’ For framework compatibility (e.g., BotFramework or FastAPI demo).  
  - `/healthz` â†’ Lightweight health check for monitoring.

- **NLU Pipeline**  
  - Intent routing (`nlu/router.py`) determines if user input should be treated as a direct command, a small-talk message, or passed to providers.  
  - Prompts and transformations are managed in `nlu/prompts.py` to centralize natural language templates.

- **Memory Integration**  
  - Session memory stored in `memory/sessions.py`.  
  - Optional RAG indexer (`memory/rag/indexer.py`) allows document retrieval for extended context.

---

## Security Considerations

- **API Keys**  
  - Keys for external services are never hard-coded.  
  - They are pulled from environment variables or `.env` files (via `core/config.py`).  

- **Data Handling**  
  - Anonymous mode never sends user text outside the local process.  
  - Logged-in mode applies guardrails before making external calls.  
  - Sensitive information (emails, IDs) is redacted using `guardrails/pii_redaction.py`.

- **Logging**  
  - Logs are structured (`core/logging.py`) and omit sensitive data by default.  
  - Debug mode can be enabled for local testing but should not be used in production.

- **Privacy**  
  - Anonymous sessions are ephemeral: conversation state is stored only in memory unless explicitly persisted.  
  - Logged-in sessions may optionally persist data, but only with user consent.

---

## Tradeoffs

- **Rule-Based vs AI-Powered**  
  - Rule-based responses are deterministic, fast, and private but limited in sophistication.  
  - AI-powered responses (via providers) allow richer understanding but introduce latency, costs, and privacy risks.  

- **Extensibility vs Simplicity**  
  - Chose a **modular repo structure** (separate folders for `anon_bot`, `logged_in_bot`, `memory`, `nlu`) to allow future growth.  
  - This adds some boilerplate overhead but makes it easier to swap components.

- **Performance vs Accuracy**  
  - Non-functional requirement: responses within 2 seconds for 95% of requests.  
  - This meant prioritizing lightweight providers and caching over heavyweight models.  

- **Anonymous Mode as Default**  
  - Defaulting to anonymous mode ensures the system works offline and avoids external dependencies.  
  - Tradeoff: limits functionality until the user explicitly opts in for a logged-in session.

---

## Summary

The design balances **privacy, modularity, and extensibility**. By cleanly separating anonymous and logged-in paths, the system can run entirely offline while still supporting richer AI features when configured. Security and privacy are first-class concerns, and tradeoffs were made to keep the system lightweight, testable, and compliant with project constraints.
\n================================================================================\nEND FILE: docs\design.md\n================================================================================\n\n================================================================================\nBEGIN FILE: docs\DEV_DOC.md\n================================================================================\n\n<!-- /docs/slides/DEV_DOC.md -->

## 3. Functional Requirements

This section describes the functional requirements for connecting a chatbot to an AI-as-a-Service (AIaaS) platform. It defines the expected system behavior, outlines constraints, and sets measurable acceptance criteria. Requirements are grouped into system context, core functions, supporting functions, and non-functional aspects.

---

### 3.1 System Context

The chatbot acts as the client application. It receives user input, processes it, and communicates with an external AIaaS endpoint (e.g., Azure AI Language Service). The AI service provides natural language processing (NLP) features such as sentiment analysis. The chatbot then interprets the service output and responds back to the user.

Key components include:
- **User Interface (UI):** Chat interface for entering text.
- **Chatbot Core:** Handles request routing and conversation logic.
- **AI Service Connector:** Manages authentication and API calls to the AI service.
- **AIaaS Platform:** External cloud service providing NLP functions.

---

### 3.2 Functional Requirements

#### FR-1: User Input Handling
- The chatbot shall accept text input from users.
- The chatbot shall sanitize input to remove unsafe characters.
- The chatbot shall log all interactions for debugging and testing.

#### FR-2: API Connection
- The system shall authenticate with the AI service using API keys stored securely in environment variables.
- The chatbot shall send user text to the AIaaS endpoint in the required format.
- The chatbot shall handle and parse responses from the AIaaS.

#### FR-3: Sentiment Analysis Integration
- The chatbot shall use the AIaaS to determine the sentiment (e.g., positive, neutral, negative) of user input.
- The chatbot shall present sentiment results as part of its response or use them to adjust tone.

#### FR-4: Error and Exception Handling
- The system shall detect failed API calls and return a fallback message to the user.
- The chatbot shall notify the user if the AI service is unavailable.
- The chatbot shall log errors with timestamp and cause.

#### FR-5: Reporting and Documentation
- The chatbot shall provide a list of supported commands or features when prompted.
- The chatbot shall record system status and output for inclusion in the project report.
- The development process shall be documented with screenshots and configuration notes.

---

### 3.3 Non-Functional Requirements

#### NFR-1: Security
- API keys shall not be hard-coded in source files.
- Sensitive data shall be retrieved from environment variables or secure vaults.

#### NFR-2: Performance
- The chatbot shall return responses within 2 seconds under normal network conditions.
- The system shall process at least 20 concurrent user sessions without performance degradation.

#### NFR-3: Reliability
- The chatbot shall achieve at least 95% uptime during testing.
- The chatbot shall gracefully degrade to local responses if the AI service is unavailable.

#### NFR-4: Usability
- The chatbot shall provide clear, user-friendly error messages.
- The chatbot shall handle malformed input without crashing.

---

### 3.4 Acceptance Criteria

1. **Input Handling**
   - Given valid text input, the chatbot processes it without errors.
   - Given invalid or malformed input, the chatbot responds with a clarification request.

2. **API Connection**
   - Given a valid API key and endpoint, the chatbot connects and retrieves sentiment analysis.
   - Given an invalid API key, the chatbot logs an error and informs the user.

3. **Sentiment Analysis**
   - Given a positive statement, the chatbot labels it correctly with at least 90% accuracy.
   - Given a negative statement, the chatbot labels it correctly with at least 90% accuracy.

4. **Error Handling**
   - When the AI service is unavailable, the chatbot informs the user and continues functioning with local responses.
   - All failures are recorded in a log file.

5. **Usability**
   - The chatbot returns responses in less than 2 seconds for 95% of requests.
   - The chatbot displays a list of features when the user requests â€œhelp.â€

---

### Glossary

- **AIaaS (AI-as-a-Service):** Cloud-based artificial intelligence services accessible via APIs.
- **API (Application Programming Interface):** A set of rules for software applications to communicate with each other.
- **NLP (Natural Language Processing):** A field of AI focused on enabling computers to understand human language.
- **Sentiment Analysis:** An NLP technique that determines the emotional tone behind a text.

\n================================================================================\nEND FILE: docs\DEV_DOC.md\n================================================================================\n\n================================================================================\nBEGIN FILE: docs\results.md\n================================================================================\n\n<!-- /docs/slides/results.md -->
# Results\n\nChallenges, metrics, screenshots.\n\n================================================================================\nEND FILE: docs\results.md\n================================================================================\n\n================================================================================\nBEGIN FILE: examples\example.py\n================================================================================\n\n# /example/example.py
"""Simple CLI example that sends a message to the ChatBot and prints the JSON reply."""
import json
from agenticcore.chatbot.services import ChatBot

if __name__ == "__main__":
    bot = ChatBot()
    result = bot.reply("hello world")
    print(json.dumps(result, indent=2))
\n================================================================================\nEND FILE: examples\example.py\n================================================================================\n\n================================================================================\nBEGIN FILE: flat_tree_filter.py\n================================================================================\n\n#!/usr/bin/env python3
# flatten_anytree.py â€” Flatten a folder tree (code/config) into one text file.
# Usage:
#   python flatten_anytree.py [ROOT_DIR] [OUTPUT_FILE]
# Examples:
#   python flatten_anytree.py C:\path\to\repo FLATTENED_CODE.txt
#   python flatten_anytree.py . out.txt --include-exts .py,.ipynb --exclude-dirs .git,node_modules
#
# New in this patched version:
#   - Skips common .gitignore-style junk by default (node_modules, .venv, __pycache__, caches, etc.).
#   - Skips noisy/secret files like .env, .env.*, *.log, *.tmp, *.pyc by default.
#   - Adds CLI flags: --exclude-dirs, --exclude-files, --exclude-globs to extend ignores.
#   - Removes ".env" from default INCLUDE_EXTS for safety (you can still include via flags).
#
import json
import os
import sys
import fnmatch
from pathlib import Path
from typing import Iterable, Set, List

INCLUDE_EXTS: Set[str] = {
    ".py", ".ipynb", ".json", ".md", ".txt", ".yml", ".yaml",
    ".ini", ".cfg", ".conf", ".service", ".sh", ".bat",
    ".js", ".ts", ".tsx", ".jsx", ".css", ".html",
    ".toml", ".dockerfile"
}

EXCLUDE_DIRS: Set[str] = {
    ".git", ".hg", ".svn", "__pycache__", "node_modules",
    ".venv", "venv", "env", "dist", "build",
    "artifacts", "logs", ".idea", ".vscode", ".pytest_cache",
    ".mypy_cache", ".ruff_cache", ".tox", ".nox", ".hypothesis",
    ".cache", ".gradle", ".parcel-cache", ".next", ".turbo",
    ".pnpm-store", ".yarn", ".yarn/cache", ".nuxt", ".svelte-kit"
}

# Filenames to always skip
EXCLUDE_FILES: Set[str] = {
    ".DS_Store", "Thumbs.db", ".coverage", ".python-version",
}

# Glob patterns to skip (gitignore-like, simple fnmatch on the basename)
EXCLUDE_GLOBS: List[str] = [
    "*.log", "*.tmp", "*.temp", "*.bak", "*.swp", "*.swo",
    "*.pyc", "*.pyo", "*.pyd", "*.class",
    "*.lock", "*.pid",
    "*.egg-info", "*.eggs",
    "*.sqlite", "*.sqlite3", "*.db", "*.pkl",
    ".env", ".env.*",
]

MAX_FILE_BYTES_DEFAULT = 2_000_000  # 2 MB safety default


def is_included_file(path: Path, include_exts: Set[str]) -> bool:
    if not path.is_file():
        return False
    # Dockerfile special-case: no suffix
    if path.name.lower() == "dockerfile":
        return True
    return path.suffix.lower() in include_exts


def read_ipynb_code_cells(nb_path: Path) -> str:
    try:
        data = json.loads(nb_path.read_text(encoding="utf-8"))
    except Exception as e:
        return f"[ERROR reading notebook JSON: {e}]"
    cells = data.get("cells", [])
    out_lines: List[str] = []
    count = 0
    for c in cells:
        if c.get("cell_type") == "code":
            count += 1
            src = c.get("source", [])
            code = "".join(src)
            out_lines.append(f"# %% [code cell {count}]")
            out_lines.append(code.rstrip() + "\\n")
    if not out_lines:
        return "[No code cells found]"
    return "\\n".join(out_lines)


def read_text_file(path: Path) -> str:
    try:
        if path.suffix.lower() == ".ipynb":
            return read_ipynb_code_cells(path)
        return path.read_text(encoding="utf-8", errors="replace")
    except Exception as e:
        return f"[ERROR reading file: {e}]"


def walk_files(root: Path,
               exclude_dirs: Set[str],
               include_exts: Set[str],
               max_bytes: int,
               follow_symlinks: bool,
               exclude_files: Set[str],
               exclude_globs: List[str]) -> Iterable[Path]:
    for dirpath, dirnames, filenames in os.walk(root, followlinks=follow_symlinks):
        # prune excluded dirs in-place
        dirnames[:] = [d for d in dirnames if d not in exclude_dirs]
        for name in filenames:
            # filename-level filters
            if name in exclude_files:
                continue
            if any(fnmatch.fnmatch(name, pat) for pat in exclude_globs):
                continue

            p = Path(dirpath) / name
            if is_included_file(p, include_exts):
                try:
                    if p.stat().st_size <= max_bytes:
                        yield p
                except Exception:
                    continue


def parse_str_set_arg(raw: str, default: Set[str]) -> Set[str]:
    # Parse comma-separated items into a set of strings (filenames or dirnames).
    if raw is None or not str(raw).strip():
        return set(default)
    return {s.strip() for s in raw.split(",") if s.strip()}


def parse_list_arg(raw: str, default: Set[str]) -> Set[str]:
    # Parse comma-separated items; empty -> default. Example: ".py,.ipynb,.md"
    if raw is None or not str(raw).strip():
        return set(default)
    items = [s.strip() for s in raw.split(",") if s.strip()]
    # normalize extensions to lowercase with a leading dot when applicable
    norm: Set[str] = set()
    for it in items:
        it_low = it.lower()
        if it_low == "dockerfile":
            norm.add("dockerfile")  # handled specially
        elif it_low.startswith("."):
            norm.add(it_low)
        else:
            norm.add("." + it_low)
    return norm


def main(argv: List[str]) -> int:
    import argparse

    ap = argparse.ArgumentParser(
        description="Flatten a folder tree (code/config) into one text file with file headers."
    )
    ap.add_argument("root", nargs="?", default=".", help="Root directory to scan (default: current dir)")
    ap.add_argument("out", nargs="?", default="FLATTENED_CODE.txt", help="Output text file (default: FLATTENED_CODE.txt)")
    ap.add_argument("--include-exts", dest="include_exts", default="",
                    help="Comma-separated list of extensions to include (e.g. .py,.ipynb,.md). Default uses a sane preset.")
    ap.add_argument("--exclude-dirs", dest="exclude_dirs", default="",
                    help="Comma-separated list of directory names to exclude (in addition to defaults).")
    ap.add_argument("--exclude-files", dest="exclude_files", default="",
                    help="Comma-separated list of filenames to exclude (in addition to defaults).")
    ap.add_argument("--exclude-globs", dest="exclude_globs", default="",
                    help="Comma-separated list of glob patterns to exclude (e.g. *.log,*.tmp,.env, .env.*).")
    ap.add_argument("--max-bytes", dest="max_bytes", type=int, default=MAX_FILE_BYTES_DEFAULT,
                    help=f"Skip files larger than this many bytes (default: {MAX_FILE_BYTES_DEFAULT}).")
    ap.add_argument("--follow-symlinks", action="store_true", help="Follow symlinks while walking the tree.")
    args = ap.parse_args(argv)

    root = Path(args.root).expanduser()
    out_path = Path(args.out).expanduser()

    if not root.exists():
        print(f"Root path not found: {root}", file=sys.stderr)
        return 1

    include_exts = parse_list_arg(args.include_exts, INCLUDE_EXTS)

    exclude_dirs = set(EXCLUDE_DIRS)
    if args.exclude_dirs:
        exclude_dirs |= {d.strip() for d in args.exclude_dirs.split(",") if d.strip()}

    exclude_files = set(EXCLUDE_FILES)
    if args.exclude_files:
        exclude_files |= {f.strip() for f in args.exclude_files.split(",") if f.strip()}

    exclude_globs = list(EXCLUDE_GLOBS)
    if args.exclude_globs:
        exclude_globs += [g.strip() for g in args.exclude_globs.split(",") if g.strip()]

    files = sorted(
        walk_files(root, exclude_dirs, include_exts, args.max_bytes, args.follow_symlinks, exclude_files, exclude_globs)
    )

    out_path.parent.mkdir(parents=True, exist_ok=True)
    with out_path.open("w", encoding="utf-8") as out:
        out.write(f"# Flattened code dump for: {root.resolve()}\\n")
        out.write(f"# Files included: {len(files)}\\n\\n")
        for p in files:
            try:
                rel = p.relative_to(root)
            except Exception:
                rel = p
            out.write("\\n" + "=" * 80 + "\\n")
            out.write(f"BEGIN FILE: {rel}\\n")
            out.write("=" * 80 + "\\n\\n")
            out.write(read_text_file(p))
            out.write("\\n" + "=" * 80 + "\\n")
            out.write(f"END FILE: {rel}\\n")
            out.write("=" * 80 + "\\n")

    print(f"Wrote: {out_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
\n================================================================================\nEND FILE: FLATTENED_CODE.txt\n================================================================================\n\n================================================================================\nBEGIN FILE: guardrails\pii_redaction.py\n================================================================================\n\n# /guardrails/pii_redaction.py
from __future__ import annotations
import re
from dataclasses import dataclass
from typing import Dict, List, Tuple

# ---- Types -------------------------------------------------------------------
@dataclass(frozen=True)
class PiiMatch:
    kind: str
    value: str
    span: Tuple[int, int]
    replacement: str

# ---- Patterns ----------------------------------------------------------------
# Focus on high-signal, low-false-positive patterns
_PATTERNS: Dict[str, re.Pattern] = {
    "email": re.compile(r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b"),
    "phone": re.compile(
        r"\b(?:\+?\d{1,3}[-.\s]?)?(?:\(?\d{3}\)?[-.\s]?)\d{3}[-.\s]?\d{4}\b"
    ),
    "ssn": re.compile(r"\b\d{3}-\d{2}-\d{4}\b"),
    "ip": re.compile(
        r"\b(?:(?:25[0-5]|2[0-4]\d|1?\d{1,2})\.){3}(?:25[0-5]|2[0-4]\d|1?\d{1,2})\b"
    ),
    "url": re.compile(r"\bhttps?://[^\s]+"),
    # Broad CC finder; we filter with Luhn
    "cc": re.compile(r"\b(?:\d[ -]?){13,19}\b"),
}

def _only_digits(s: str) -> str:
    return "".join(ch for ch in s if ch.isdigit())

def _luhn_ok(number: str) -> bool:
    try:
        digits = [int(x) for x in number]
    except ValueError:
        return False
    parity = len(digits) % 2
    total = 0
    for i, d in enumerate(digits):
        if i % 2 == parity:
            d *= 2
            if d > 9:
                d -= 9
        total += d
    return total % 10 == 0

# ---- Redaction core -----------------------------------------------------------
def redact_with_report(
    text: str,
    *,
    mask_map: Dict[str, str] | None = None,
    preserve_cc_last4: bool = True,
) -> tuple[str, List[PiiMatch]]:
    """
    Return (redacted_text, findings). Keeps non-overlapping highest-priority matches.
    """
    if not text:
        return text, []

    mask_map = mask_map or {
        "email": "[EMAIL]",
        "phone": "[PHONE]",
        "ssn": "[SSN]",
        "ip": "[IP]",
        "url": "[URL]",
        "cc": "[CC]",  # overridden if preserve_cc_last4
    }

    matches: List[PiiMatch] = []
    for kind, pat in _PATTERNS.items():
        for m in pat.finditer(text):
            raw = m.group(0)
            if kind == "cc":
                digits = _only_digits(raw)
                if len(digits) < 13 or len(digits) > 19 or not _luhn_ok(digits):
                    continue
                if preserve_cc_last4 and len(digits) >= 4:
                    repl = f"[CCâ€¢â€¢â€¢â€¢{digits[-4:]}]"
                else:
                    repl = mask_map["cc"]
            else:
                repl = mask_map.get(kind, "[REDACTED]")

            matches.append(PiiMatch(kind=kind, value=raw, span=m.span(), replacement=repl))

    # Resolve overlaps by keeping earliest, then skipping overlapping tails
    matches.sort(key=lambda x: (x.span[0], -(x.span[1] - x.span[0])))
    resolved: List[PiiMatch] = []
    last_end = -1
    for m in matches:
        if m.span[0] >= last_end:
            resolved.append(m)
            last_end = m.span[1]

    # Build redacted string
    out = []
    idx = 0
    for m in resolved:
        s, e = m.span
        out.append(text[idx:s])
        out.append(m.replacement)
        idx = e
    out.append(text[idx:])
    return "".join(out), resolved

# ---- Minimal compatibility API -----------------------------------------------
def redact(t: str) -> str:
    """
    Backwards-compatible simple API: return redacted text only.
    """
    return redact_with_report(t)[0]
\n================================================================================\nEND FILE: guardrails\pii_redaction.py\n================================================================================\n\n================================================================================\nBEGIN FILE: guardrails\safety.py\n================================================================================\n\n# /guardrails/safety.py
from __future__ import annotations
import re
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Tuple

from .pii_redaction import redact_with_report, PiiMatch

# ---- Config ------------------------------------------------------------------
@dataclass(slots=True)
class SafetyConfig:
    redact_pii: bool = True
    block_on_jailbreak: bool = True
    block_on_malicious_code: bool = True
    mask_secrets: str = "[SECRET]"

# Signals kept intentionally lightweight (no extra deps)
_PROMPT_INJECTION = [
    r"\bignore (all|previous) (instructions|directions)\b",
    r"\boverride (your|all) (rules|guardrails|safety)\b",
    r"\bpretend to be (?:an|a) (?:unfiltered|unsafe) model\b",
    r"\bjailbreak\b",
    r"\bdisabl(e|ing) (safety|guardrails)\b",
]
_MALICIOUS_CODE = [
    r"\brm\s+-rf\b", r"\bdel\s+/s\b", r"\bformat\s+c:\b",
    r"\b(?:curl|wget)\s+.+\|\s*(?:bash|sh)\b",
    r"\bnc\s+-e\b", r"\bpowershell\b",
]
# Common token patterns (subset; add more as needed)
_SECRETS = [
    r"\bAKIA[0-9A-Z]{16}\b",                # AWS access key id
    r"\bgh[pousr]_[A-Za-z0-9]{36}\b",       # GitHub token
    r"\bxox[abprs]-[A-Za-z0-9-]{10,}\b",    # Slack token
    r"\bAIza[0-9A-Za-z\-_]{35}\b",          # Google API key
    r"\bS[Kk]-[A-Za-z0-9-]{20,}\b",         # generic "sk-" style keys
]
# Keep profanity list mild to avoid overblocking
_PROFANITY = [r"\bdamn\b", r"\bhell\b"]

def _scan(patterns: List[str], text: str) -> List[Tuple[str, Tuple[int, int]]]:
    hits: List[Tuple[str, Tuple[int, int]]] = []
    for p in patterns:
        for m in re.finditer(p, text, flags=re.IGNORECASE):
            hits.append((m.group(0), m.span()))
    return hits

# ---- Report ------------------------------------------------------------------
@dataclass(slots=True)
class SafetyReport:
    original_text: str
    sanitized_text: str
    pii: List[PiiMatch] = field(default_factory=list)
    secrets: List[Tuple[str, Tuple[int, int]]] = field(default_factory=list)
    prompt_injection: List[Tuple[str, Tuple[int, int]]] = field(default_factory=list)
    malicious_code: List[Tuple[str, Tuple[int, int]]] = field(default_factory=list)
    profanity: List[Tuple[str, Tuple[int, int]]] = field(default_factory=list)
    action: str = "allow"  # "allow" | "warn" | "block"

    def to_dict(self) -> Dict[str, object]:
        d = asdict(self)
        d["pii"] = [asdict(p) for p in self.pii]
        return d

# ---- API ---------------------------------------------------------------------
def assess(text: str, cfg: SafetyConfig | None = None) -> SafetyReport:
    cfg = cfg or SafetyConfig()
    sanitized = text or ""

    # 1) PII redaction
    pii_hits: List[PiiMatch] = []
    if cfg.redact_pii:
        sanitized, pii_hits = redact_with_report(sanitized)

    # 2) Secrets detection (masked, but keep record)
    secrets = _scan(_SECRETS, sanitized)
    for val, (s, e) in secrets:
        sanitized = sanitized[:s] + cfg.mask_secrets + sanitized[e:]

    # 3) Prompt-injection & malicious code
    inj = _scan(_PROMPT_INJECTION, sanitized)
    mal = _scan(_MALICIOUS_CODE, sanitized)

    # 4) Mild profanity signal (does not block)
    prof = _scan(_PROFANITY, sanitized)

    # Decide action
    action = "allow"
    if (cfg.block_on_jailbreak and inj) or (cfg.block_on_malicious_code and mal):
        action = "block"
    elif secrets or pii_hits or prof:
        action = "warn"

    return SafetyReport(
        original_text=text or "",
        sanitized_text=sanitized,
        pii=pii_hits,
        secrets=secrets,
        prompt_injection=inj,
        malicious_code=mal,
        profanity=prof,
        action=action,
    )

def sanitize_user_input(text: str, cfg: SafetyConfig | None = None) -> tuple[str, SafetyReport]:
    """Convenience wrapper used by HTTP routes/bots."""
    rep = assess(text, cfg)
    return rep.sanitized_text, rep
\n================================================================================\nEND FILE: guardrails\safety.py\n================================================================================\n\n================================================================================\nBEGIN FILE: integrations\azure\bot_framework.py\n================================================================================\n\n# integrations/azure/bot_framework.py
"""
Azure Bot Framework integration (stub).

This module is a placeholder for connecting the chatbot
to Microsoft Azure Bot Framework. It is optional â€”
the anonymous bot does not depend on this code.

If you want to enable Azure:
    1. Install `botbuilder` SDK (pip install botbuilder-core aiohttp).
    2. Fill in the adapter setup and message handling below.
"""

from typing import Any, Dict


class AzureBotFrameworkNotConfigured(Exception):
    """Raised when Azure Bot Framework is called but not set up."""


def init_adapter(config: Dict[str, Any] | None = None):
    """
    Placeholder for BotFrameworkAdapter initialization.
    Returns a dummy object unless replaced with actual Azure code.
    """
    raise AzureBotFrameworkNotConfigured(
        "Azure Bot Framework integration is not configured. "
        "Use anon_bot for local testing."
    )


def handle_activity(activity: Dict[str, Any]) -> Dict[str, Any]:
    """
    Placeholder for handling an incoming Bot Framework activity.
    Echoes back a dummy response if called directly.
    """
    if not activity:
        return {"type": "message", "text": "(no activity received)"}
    return {"type": "message", "text": f"Echo: {activity.get('text', '')}"}
\n================================================================================\nEND FILE: integrations\azure\bot_framework.py\n================================================================================\n\n================================================================================\nBEGIN FILE: integrations\botframework\app.py\n================================================================================\n\n# /intergrations/botframework/app.py â€” aiohttp + Bot Framework Echo bot
#!/usr/bin/env python3

import os
import sys
import json
from logic import handle_text
from aiohttp import web
from botbuilder.core import BotFrameworkAdapter, BotFrameworkAdapterSettings, TurnContext
from botbuilder.schema import Activity
import aiohttp_cors
from pathlib import Path


# -------------------------------------------------------------------
# Your bot implementation
# -------------------------------------------------------------------
# Make sure this exists at packages/bots/echo_bot.py
# from bots.echo_bot import EchoBot
# Minimal inline fallback if you want to test quickly:
class EchoBot:
    async def on_turn(self, turn_context: TurnContext):
        if turn_context.activity.type == "message":
            text = (turn_context.activity.text or "").strip()
            if not text:
                await turn_context.send_activity("Input was empty. Type 'help' for usage.")
                return

            lower = text.lower()
            if lower == "help":
                await turn_context.send_activity("Try: echo <msg> | reverse: <msg> | capabilities")
            elif lower == "capabilities":
                await turn_context.send_activity("- echo\n- reverse\n- help\n- capabilities")
            elif lower.startswith("reverse:"):
                payload = text.split(":", 1)[1].strip()
                await turn_context.send_activity(payload[::-1])
            elif lower.startswith("echo "):
                await turn_context.send_activity(text[5:])
            else:
                await turn_context.send_activity("Unsupported command. Type 'help' for examples.")
        else:
            await turn_context.send_activity(f"[{turn_context.activity.type}] event received.")

# -------------------------------------------------------------------
# Adapter / bot setup
# -------------------------------------------------------------------
APP_ID = os.environ.get("MicrosoftAppId") or None
APP_PASSWORD = os.environ.get("MicrosoftAppPassword") or None

adapter_settings = BotFrameworkAdapterSettings(APP_ID, APP_PASSWORD)
adapter = BotFrameworkAdapter(adapter_settings)

async def on_error(context: TurnContext, error: Exception):
    print(f"[on_turn_error] {error}", file=sys.stderr, flush=True)
    try:
        await context.send_activity("Oops. Something went wrong!")
    except Exception as send_err:
        print(f"[on_turn_error][send_activity_failed] {send_err}", file=sys.stderr, flush=True)

adapter.on_turn_error = on_error
bot = EchoBot()

# -------------------------------------------------------------------
# HTTP handlers
# -------------------------------------------------------------------
async def messages(req: web.Request) -> web.Response:
    # Content-Type can include charset; do a contains check
    ctype = (req.headers.get("Content-Type") or "").lower()
    if "application/json" not in ctype:
        return web.Response(status=415, text="Unsupported Media Type: expected application/json")

    try:
        body = await req.json()
    except json.JSONDecodeError:
        return web.Response(status=400, text="Invalid JSON body")

    activity = Activity().deserialize(body)
    auth_header = req.headers.get("Authorization")

    invoke_response = await adapter.process_activity(activity, auth_header, bot.on_turn)
    if invoke_response:
        # For invoke activities, adapter returns explicit status/body
        return web.json_response(data=invoke_response.body, status=invoke_response.status)
    # Acknowledge standard message activities
    return web.Response(status=202, text="Accepted")

async def home(_req: web.Request) -> web.Response:
    return web.Response(
        text="Bot is running. POST Bot Framework activities to /api/messages.",
        content_type="text/plain"
    )

async def messages_get(_req: web.Request) -> web.Response:
    return web.Response(
        text="This endpoint only accepts POST (Bot Framework activities).",
        content_type="text/plain",
        status=405
    )

async def healthz(_req: web.Request) -> web.Response:
    return web.json_response({"status": "ok"})

async def plain_chat(req: web.Request) -> web.Response:
    try:
        payload = await req.json()
    except Exception:
        return web.json_response({"error": "Invalid JSON"}, status=400)
    user_text = payload.get("text", "")
    reply = handle_text(user_text)
    return web.json_response({"reply": reply})

# -------------------------------------------------------------------
# App factory and entrypoint
# -------------------------------------------------------------------
from pathlib import Path

def create_app() -> web.Application:
    app = web.Application()
    app.router.add_get("/", home)
    app.router.add_get("/healthz", healthz)
    app.router.add_get("/api/messages", messages_get)
    app.router.add_post("/api/messages", messages)
    app.router.add_post("/plain-chat", plain_chat)

    static_dir = Path(__file__).parent / "static"
    if static_dir.exists():
        app.router.add_static("/static/", path=static_dir, show_index=True)
    else:
        print(f"[warn] static directory not found: {static_dir}", flush=True)

    return app

app = create_app()

if __name__ == "__main__":
    host = os.environ.get("HOST", "127.0.0.1")  # use 0.0.0.0 in containers
    port = int(os.environ.get("PORT", 3978))
    web.run_app(app, host=host, port=port)
\n================================================================================\nEND FILE: integrations\botframework\app.py\n================================================================================\n\n================================================================================\nBEGIN FILE: integrations\botframework\bot.py\n================================================================================\n\n# /intergrations/botframework/bot.py
"""
Simple MBF bot:
- 'help' / 'capabilities' shows features
- 'reverse <text>' returns reversed text
- otherwise delegates to AgenticCore ChatBot (sentiment) if available
"""

from typing import List, Optional, Dict, Any
from botbuilder.core import ActivityHandler, TurnContext
from botbuilder.schema import ChannelAccount, ActivityTypes

from skills import normalize, reverse_text, capabilities, is_empty

# Try to import AgenticCore; if unavailable, provide a tiny fallback.
try:
    from agenticcore.chatbot.services import ChatBot  # real provider-backed bot
except Exception:
    class ChatBot:  # fallback shim for offline/dev
        def reply(self, message: str) -> Dict[str, Any]:
            return {
                "reply": "Noted. (local fallback reply)",
                "sentiment": "neutral",
                "confidence": 0.5,
            }

def _format_sentiment(res: Dict[str, Any]) -> str:
    """Compose a user-facing string from ChatBot reply payload."""
    reply = (res.get("reply") or "").strip()
    label: Optional[str] = res.get("sentiment")
    conf = res.get("confidence")
    if label is not None and conf is not None:
        return f"{reply} (sentiment: {label}, confidence: {float(conf):.2f})"
    return reply or "I'm not sure what to say."

def _help_text() -> str:
    """Single source of truth for the help/capability text."""
    feats = "\n".join(f"- {c}" for c in capabilities())
    return (
        "I can reverse text and provide concise replies with sentiment.\n"
        "Commands:\n"
        "- help | capabilities\n"
        "- reverse <text>\n"
        "General text will be handled by the ChatBot service.\n\n"
        f"My capabilities:\n{feats}"
    )

class SimpleBot(ActivityHandler):
    """Minimal ActivityHandler with local commands + ChatBot fallback."""

    def __init__(self, chatbot: Optional[ChatBot] = None):
        self._chatbot = chatbot or ChatBot()

    async def on_members_added_activity(
        self, members_added: List[ChannelAccount], turn_context: TurnContext
    ):
        for member in members_added:
            if member.id != turn_context.activity.recipient.id:
                await turn_context.send_activity("Hello! Type 'help' to see what I can do.")

    async def on_message_activity(self, turn_context: TurnContext):
        if turn_context.activity.type != ActivityTypes.message:
            return

        text = (turn_context.activity.text or "").strip()
        if is_empty(text):
            await turn_context.send_activity("Please enter a message (try 'help').")
            return

        cmd = normalize(text)

        if cmd in {"help", "capabilities"}:
            await turn_context.send_activity(_help_text())
            return

        if cmd.startswith("reverse "):
            original = text.split(" ", 1)[1] if " " in text else ""
            await turn_context.send_activity(reverse_text(original))
            return

        # ChatBot fallback (provider-agnostic sentiment/reply)
        try:
            result = self._chatbot.reply(text)
            await turn_context.send_activity(_format_sentiment(result))
        except Exception:
            await turn_context.send_activity(f"You said: {text}")
\n================================================================================\nEND FILE: integrations\botframework\bot.py\n================================================================================\n\n================================================================================\nBEGIN FILE: integrations\botframework\bots\echo_bot.py\n================================================================================\n\n# bots/echo_bot.py
from botbuilder.core import ActivityHandler, TurnContext
from botbuilder.schema import ChannelAccount

def simple_sentiment(text: str):
    """
    Tiny, no-cost heuristic so you can demo behavior without extra services.
    You can swap this later for HF/OpenAI/Azure easily.
    """
    t = (text or "").lower()
    pos = any(w in t for w in ["love","great","good","awesome","fantastic","excellent","amazing"])
    neg = any(w in t for w in ["hate","bad","terrible","awful","worst","horrible","angry"])
    if pos and not neg:  return "positive", 0.9
    if neg and not pos:  return "negative", 0.9
    return "neutral", 0.5

CAPS = [
    "Echo what you say (baseline).",
    "Show my capabilities with 'help' or 'capabilities'.",
    "Handle malformed/empty input politely.",
    "Classify simple sentiment (positive/negative/neutral).",
]

class EchoBot(ActivityHandler):
    async def on_members_added_activity(
        self, members_added: [ChannelAccount], turn_context: TurnContext
    ):
        for member in members_added:
            if member.id != turn_context.activity.recipient.id:
                await turn_context.send_activity(
                    "Hi! Iâ€™m your sample bot.\n"
                    "- Try typing: **help**\n"
                    "- Or any sentence and Iâ€™ll echo it + sentiment."
                )

    async def on_message_activity(self, turn_context: TurnContext):
        text = (turn_context.activity.text or "").strip()

        # Handle empty/malformed
        if not text:
            await turn_context.send_activity(
                "I didnâ€™t catch anything. Please type a message (or 'help')."
            )
            return

        # Capabilities
        if text.lower() in {"help","capabilities","what can you do"}:
            caps = "\n".join(f"â€¢ {c}" for c in CAPS)
            await turn_context.send_activity(
                "Hereâ€™s what I can do:\n" + caps
            )
            return

        # Normal message â†’ echo + sentiment
        label, score = simple_sentiment(text)
        reply = f"You said: **{text}**\nSentiment: **{label}** (conf {score:.2f})"
        await turn_context.send_activity(reply)
\n================================================================================\nEND FILE: integrations\botframework\bots\echo_bot.py\n================================================================================\n\n================================================================================\nBEGIN FILE: integrations\email\ticket_stub.py\n================================================================================\n\n# /intergrations/email/ticket_stub.py
"""
Email / Ticket System Stub.

This module simulates creating a support ticket via email.
It is a placeholder â€” no actual emails are sent.
"""

from typing import Dict, Any
import datetime
import uuid


class TicketStub:
    """
    A stub ticketing system that generates a fake ticket ID
    and stores basic info in memory.
    """

    def __init__(self):
        self.tickets: Dict[str, Dict[str, Any]] = {}

    def create_ticket(self, subject: str, body: str, user: str | None = None) -> Dict[str, Any]:
        """
        Create a fake support ticket.
        Returns a dictionary with ticket metadata.
        """
        ticket_id = str(uuid.uuid4())
        ticket = {
            "id": ticket_id,
            "subject": subject,
            "body": body,
            "user": user or "anonymous",
            "created_at": datetime.datetime.utcnow().isoformat() + "Z",
            "status": "open",
        }
        self.tickets[ticket_id] = ticket
        return ticket

    def get_ticket(self, ticket_id: str) -> Dict[str, Any] | None:
        """Retrieve a ticket by ID if it exists."""
        return self.tickets.get(ticket_id)

    def list_tickets(self) -> list[Dict[str, Any]]:
        """Return all created tickets."""
        return list(self.tickets.values())


# Singleton for convenience
stub = TicketStub()


def create_ticket(subject: str, body: str, user: str | None = None) -> Dict[str, Any]:
    """
    Module-level shortcut.
    """
    return stub.create_ticket(subject, body, user)
\n================================================================================\nEND FILE: integrations\email\ticket_stub.py\n================================================================================\n\n================================================================================\nBEGIN FILE: integrations\web\fastapi\web_agentic.py\n================================================================================\n\n# /integrations/web/fastapi/web_agentic.py
from fastapi import FastAPI, Query
from fastapi.responses import HTMLResponse
from agenticcore.chatbot.services import ChatBot

app = FastAPI(title="AgenticCore Web UI")

# 1. Simple HTML form at /
@app.get("/", response_class=HTMLResponse)
def index():
    return """
    <form action="/agentic" method="get">
        <input type="text" name="msg" placeholder="Type a message" style="width:300px">
        <input type="submit" value="Send">
    </form>
    """

# 2. Agentic endpoint
@app.get("/agentic")
def run_agentic(msg: str = Query(..., description="Message to send to ChatBot")):
    bot = ChatBot()
    return bot.reply(msg)
\n================================================================================\nEND FILE: integrations\web\fastapi\web_agentic.py\n================================================================================\n\n================================================================================\nBEGIN FILE: logged_in_bot\handler.py\n================================================================================\n\n# /logged_in_bot/handler.py

from agenticcore.chatbot.services import ChatBot

_bot = ChatBot()

def handle_turn(message, history, user):
    history = history or []
    try:
        res = _bot.reply(message)
        reply = res.get("reply") or "Noted."
        label = res.get("sentiment")
        conf = res.get("confidence")
        if label is not None and conf is not None:
            reply = f"{reply} (sentiment: {label}, confidence: {float(conf):.2f})"
    except Exception as e:
        reply = f"Sorryâ€”error in ChatBot: {type(e).__name__}. Using fallback."
    history = history + [[message, reply]]
    return history

\n================================================================================\nEND FILE: logged_in_bot\handler.py\n================================================================================\n\n================================================================================\nBEGIN FILE: logged_in_bot\sentiment_azure.py\n================================================================================\n\n# /logged_in_bot/sentiment_azure.py
"""
Optional Azure Sentiment integration with safe local fallback.

Usage:
    from logged_in_bot.sentiment_azure import analyze_sentiment, SentimentResult

    res = analyze_sentiment("I love this!")
    print(res.label, res.score, res.backend)  # e.g., "positive", 0.92, "local"

Environment (Azure path only):
    - AZURE_LANGUAGE_ENDPOINT or MICROSOFT_AI_ENDPOINT
    - AZURE_LANGUAGE_KEY or MICROSOFT_AI_KEY

If the Azure SDK or env vars are missing, we automatically fall back to a
deterministic, dependency-free heuristic that is fast and good enough for tests.
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Optional, Tuple
import os
import re


# ---------------------------
# Public dataclass & API
# ---------------------------

@dataclass(frozen=True)
class SentimentResult:
    label: str           # "positive" | "neutral" | "negative"
    score: float         # 0.0 .. 1.0 (confidence-like)
    backend: str         # "azure" | "local"
    raw: Optional[dict] = None  # provider raw payload if available


def analyze_sentiment(text: str) -> SentimentResult:
    """
    Analyze sentiment using Azure if configured, otherwise use local heuristic.

    Never raises on normal use â€” returns a result even if Azure is misconfigured,
    satisfying 'graceful degradation' requirements.
    """
    text = (text or "").strip()
    if not text:
        return SentimentResult(label="neutral", score=0.5, backend="local", raw={"reason": "empty"})

    # Try Azure first (only if fully configured and package available)
    azure_ready, why = _is_azure_ready()
    if azure_ready:
        try:
            return _azure_sentiment(text)
        except Exception as e:
            # Degrade gracefully to local
            return _local_sentiment(text, note=f"azure_error: {e!r}")
    else:
        # Go local immediately
        return _local_sentiment(text, note=why)


# ---------------------------
# Azure path (optional)
# ---------------------------

def _is_azure_ready() -> Tuple[bool, str]:
    """
    Check env + optional SDK presence without importing heavy modules unless needed.
    """
    endpoint = os.getenv("AZURE_LANGUAGE_ENDPOINT") or os.getenv("MICROSOFT_AI_ENDPOINT")
    key = os.getenv("AZURE_LANGUAGE_KEY") or os.getenv("MICROSOFT_AI_KEY")
    if not endpoint or not key:
        return False, "missing_env"

    try:
        # Light import check
        import importlib
        client_mod = importlib.import_module("azure.ai.textanalytics")
        cred_mod = importlib.import_module("azure.core.credentials")
        # Quick sanity on expected attributes
        getattr(client_mod, "TextAnalyticsClient")
        getattr(cred_mod, "AzureKeyCredential")
    except Exception:
        return False, "sdk_not_installed"

    return True, "ok"


def _azure_sentiment(text: str) -> SentimentResult:
    """
    Call Azure Text Analytics (Sentiment). Requires:
      pip install azure-ai-textanalytics
    """
    from azure.ai.textanalytics import TextAnalyticsClient
    from azure.core.credentials import AzureKeyCredential

    endpoint = os.getenv("AZURE_LANGUAGE_ENDPOINT") or os.getenv("MICROSOFT_AI_ENDPOINT")
    key = os.getenv("AZURE_LANGUAGE_KEY") or os.getenv("MICROSOFT_AI_KEY")

    client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(key))
    # API expects a list of documents
    resp = client.analyze_sentiment(documents=[text], show_opinion_mining=False)
    doc = resp[0]

    # Map Azure scores to our schema
    label = (doc.sentiment or "neutral").lower()
    # Choose max score among pos/neu/neg as "confidence-like"
    score_map = {
        "positive": doc.confidence_scores.positive,
        "neutral": doc.confidence_scores.neutral,
        "negative": doc.confidence_scores.negative,
    }
    score = float(score_map.get(label, max(score_map.values())))
    raw = {
        "sentiment": doc.sentiment,
        "confidence_scores": {
            "positive": doc.confidence_scores.positive,
            "neutral": doc.confidence_scores.neutral,
            "negative": doc.confidence_scores.negative,
        },
    }
    return SentimentResult(label=label, score=score, backend="azure", raw=raw)


# ---------------------------
# Local fallback (no deps)
# ---------------------------

_POSITIVE = {
    "good", "great", "love", "excellent", "amazing", "awesome", "happy",
    "wonderful", "fantastic", "like", "enjoy", "cool", "nice", "positive",
}
_NEGATIVE = {
    "bad", "terrible", "hate", "awful", "horrible", "sad", "angry",
    "worse", "worst", "broken", "bug", "issue", "problem", "negative",
}
# Simple negation tokens to flip nearby polarity
_NEGATIONS = {"not", "no", "never", "n't"}

_WORD_RE = re.compile(r"[A-Za-z']+")


def _local_sentiment(text: str, note: str | None = None) -> SentimentResult:
    """
    Tiny lexicon + negation heuristic:
      - Tokenize letters/apostrophes
      - Score +1 for positive, -1 for negative
      - If a negation appears within the previous 3 tokens, flip the sign
      - Convert final score to pseudo-confidence 0..1
    """
    tokens = [t.lower() for t in _WORD_RE.findall(text)]
    score = 0
    for i, tok in enumerate(tokens):
        window_neg = any(t in _NEGATIONS for t in tokens[max(0, i - 3):i])
        if tok in _POSITIVE:
            score += -1 if window_neg else 1
        elif tok in _NEGATIVE:
            score += 1 if window_neg else -1

    # Map integer score â†’ label
    if score > 0:
        label = "positive"
    elif score < 0:
        label = "negative"
    else:
        label = "neutral"

    # Confidence-like mapping: squash by arctan-ish shape without math imports
    # Clamp |score| to 6 â†’ conf in ~[0.55, 0.95]
    magnitude = min(abs(score), 6)
    conf = 0.5 + (magnitude / 6) * 0.45  # 0.5..0.95

    raw = {"engine": "heuristic", "score_raw": score, "note": note} if note else {"engine": "heuristic", "score_raw": score}
    return SentimentResult(label=label, score=round(conf, 3), backend="local", raw=raw)


# ---------------------------
# Convenience (module-level)
# ---------------------------

def sentiment_label(text: str) -> str:
    """Return only 'positive' | 'neutral' | 'negative'."""
    return analyze_sentiment(text).label


def sentiment_score(text: str) -> float:
    """Return only the 0..1 confidence-like score."""
    return analyze_sentiment(text).score
\n================================================================================\nEND FILE: logged_in_bot\sentiment_azure.py\n================================================================================\n\n================================================================================\nBEGIN FILE: logged_in_bot\tools.py\n================================================================================\n\n# /logged_in_bot/tools.py
"""
Utilities for the logged-in chatbot flow.

Features
- PII redaction (optional) via guardrails.pii_redaction
- Sentiment (optional) via logged_in_bot.sentiment_azure (falls back locally)
- Tiny intent router: summarize | echo | chat
- Deterministic, dependency-light; safe to import in any environment
"""

from __future__ import annotations
from dataclasses import asdict, dataclass
from typing import Any, Dict, List, Optional, Tuple
import os
import re

# -------------------------
# Optional imports (safe)
# -------------------------

# Sentiment (ours): falls back to a local heuristic if Azure SDK/env missing
try:
    from .sentiment_azure import analyze_sentiment, SentimentResult  # type: ignore
except Exception:  # pragma: no cover
    analyze_sentiment = None
    SentimentResult = None  # type: ignore

# Guardrails redaction (optional)
try:
    from guardrails.pii_redaction import redact as pii_redact  # type: ignore
except Exception:  # pragma: no cover
    pii_redact = None

# core types (optional shape for JSON response)
try:
    from core.types import PlainChatResponse  # dataclass with .to_dict()
except Exception:  # pragma: no cover
    @dataclass
    class PlainChatResponse:  # lightweight fallback shape
        reply: str
        meta: Optional[Dict[str, Any]] = None

        def to_dict(self) -> Dict[str, Any]:
            return asdict(self)


History = List[Tuple[str, str]]  # [("user","..."), ("bot","...")]


# -------------------------
# Helpers
# -------------------------

_WHITESPACE_RE = re.compile(r"\s+")


def sanitize_text(text: str) -> str:
    """Basic sanitize/normalize; keep CPU-cheap & deterministic."""
    text = (text or "").strip()
    text = _WHITESPACE_RE.sub(" ", text)
    # Optionally cap extremely large payloads to protect inference/services
    max_len = int(os.getenv("MAX_INPUT_CHARS", "4000"))
    if len(text) > max_len:
        text = text[:max_len] + "â€¦"
    return text


def redact_text(text: str) -> str:
    """Apply optional PII redaction if available; otherwise return text."""
    if pii_redact:
        try:
            return pii_redact(text)
        except Exception:
            # Fail open but safe
            return text
    return text


def intent_of(text: str) -> str:
    """Ultra-tiny intent: summarize|echo|help|chat."""
    t = text.lower().strip()
    if not t:
        return "empty"
    if t.startswith("summarize ") or t.startswith("summarise ") or " summarize " in f" {t} ":
        return "summarize"
    if t.startswith("echo "):
        return "echo"
    if t in {"help", "/help", "capabilities"}:
        return "help"
    return "chat"


def summarize_text(text: str, target_len: int = 120) -> str:
    """
    CPU-cheap pseudo-summarizer:
    - Extract first sentence; if long, truncate to target_len with ellipsis.
    Later you can swap this for a real HF model while keeping the same API.
    """
    # naive sentence boundary
    m = re.split(r"(?<=[.!?])\s+", text.strip())
    first = m[0] if m else text.strip()
    if len(first) <= target_len:
        return first
    return first[: target_len - 1].rstrip() + "â€¦"


def capabilities() -> List[str]:
    return [
        "help",
        "echo <text>",
        "summarize <paragraph>",
        "sentiment tagging (logged-in mode)",
    ]


# -------------------------
# Main entry
# -------------------------

def handle_logged_in_turn(message: str, history: Optional[History], user: Optional[dict]) -> Dict[str, Any]:
    """
    Process one user turn in 'logged-in' mode.

    Returns a PlainChatResponse (dict) with:
      - reply: str
      - meta: { intent, sentiment: {label, score, backend}, redacted: bool }
    """
    history = history or []
    user_text_raw = message or ""
    user_text = sanitize_text(user_text_raw)
    redacted = False

    # Redact PII if available
    redacted_text = redact_text(user_text)
    redacted = (redacted_text != user_text)

    it = intent_of(redacted_text)

    # ---------- route ----------
    if it == "empty":
        reply = "Please type something. Try 'help' for options."
        meta = _meta(redacted, it, redacted_text)
        return PlainChatResponse(reply=reply, meta=meta).to_dict()

    if it == "help":
        reply = "I can:\n" + "\n".join(f"- {c}" for c in capabilities())
        meta = _meta(redacted, it, redacted_text)
        return PlainChatResponse(reply=reply, meta=meta).to_dict()

    if it == "echo":
        payload = redacted_text.split(" ", 1)[1] if " " in redacted_text else ""
        reply = payload or "(nothing to echo)"
        meta = _meta(redacted, it, redacted_text)
        _attach_sentiment(meta, reply)  # sentiment on reply text
        return PlainChatResponse(reply=reply, meta=meta).to_dict()

    if it == "summarize":
        # Use everything after the keyword if present
        if redacted_text.lower().startswith("summarize "):
            payload = redacted_text.split(" ", 1)[1]
        elif redacted_text.lower().startswith("summarise "):
            payload = redacted_text.split(" ", 1)[1]
        else:
            payload = redacted_text
        reply = summarize_text(payload)
        meta = _meta(redacted, it, redacted_text)
        _attach_sentiment(meta, payload)  # sentiment on source text
        return PlainChatResponse(reply=reply, meta=meta).to_dict()

    # default: chat
    reply = _chat_fallback(redacted_text, history)
    meta = _meta(redacted, it, redacted_text)
    _attach_sentiment(meta, redacted_text)
    return PlainChatResponse(reply=reply, meta=meta).to_dict()


# -------------------------
# Internals
# -------------------------

def _chat_fallback(text: str, history: History) -> str:
    """
    Minimal deterministic fallback for general chat in logged-in mode.
    Swap this for a provider call if/when you enable one.
    """
    if "who are you" in text.lower():
        return "I'm the logged-in chatbot. I can echo, summarize, and tag sentiment."
    return "Noted! (logged-in mode). Type 'help' for options."

def _meta(redacted: bool, intent: str, redacted_text: str) -> Dict[str, Any]:
    return {
        "intent": intent,
        "redacted": redacted,
        "input_len": len(redacted_text),
    }

def _attach_sentiment(meta: Dict[str, Any], text: str) -> None:
    """Attach sentiment to meta if available; never raises."""
    try:
        if analyze_sentiment:
            res = analyze_sentiment(text)
            if hasattr(res, "__dict__"):
                meta["sentiment"] = {
                    "label": res.label,
                    "score": res.score,
                    "backend": res.backend,
                }
            else:  # unexpected object â€” store string
                meta["sentiment"] = {"label": str(res)}
        else:
            # no module available
            meta["sentiment"] = {"label": "neutral", "score": 0.5, "backend": "none"}
    except Exception as e:  # pragma: no cover
        meta["sentiment"] = {"error": f"{type(e).__name__}: {e}"}


__all__ = [
    "handle_logged_in_turn",
    "sanitize_text",
    "redact_text",
    "intent_of",
    "summarize_text",
    "capabilities",
]
\n================================================================================\nEND FILE: logged_in_bot\tools.py\n================================================================================\n\n================================================================================\nBEGIN FILE: memory\rag\indexer.py\n================================================================================\n\n# /memory/rag/data/indexer.py
"""
Minimal, dependency-free TF-IDF indexer for RAG.

Features
- Build from folder (recursive), index plain-text files
- Add individual text blobs with metadata
- Persist/load inverted index to/from JSON
- Search with TF-IDF scoring and simple query normalization
- Return top-k with tiny context snippets

This module is intentionally small and pure-Python to keep local CPU demos simple.
"""

from __future__ import annotations
from dataclasses import dataclass, asdict
from typing import Dict, List, Tuple, Iterable, Optional
from pathlib import Path
import json
import math
import hashlib
import re
import fnmatch
import time

# -----------------------------
# Types
# -----------------------------

@dataclass(frozen=True)
class DocMeta:
    doc_id: str
    source: str                   # e.g., absolute path or "inline"
    title: str | None = None
    tags: List[str] | None = None
    mtime: float | None = None    # source last modified (if file)
    hash: str | None = None       # content hash

@dataclass(frozen=True)
class Hit:
    doc_id: str
    score: float
    source: str
    snippet: str
    title: str | None = None
    tags: List[str] | None = None

# -----------------------------
# Tokenization
# -----------------------------

_WORD_RE = re.compile(r"[A-Za-z0-9']+")

def tokenize(text: str) -> List[str]:
    # simple, deterministic tokenizer; lowercased
    return [t.lower() for t in _WORD_RE.findall(text or "")]

# -----------------------------
# Index
# -----------------------------

class TfidfIndex:
    """
    Tiny TF-IDF inverted index with JSON persistence.

    Structures:
      - docs: doc_id -> {"meta": DocMeta, "len": int, "text": str (optional)}
      - inv: term -> {doc_id: tf}   (raw term frequency)
      - df: term -> document frequency
      - n_docs: total number of docs
    """

    def __init__(self) -> None:
        self.docs: Dict[str, Dict] = {}
        self.inv: Dict[str, Dict[str, int]] = {}
        self.df: Dict[str, int] = {}
        self.n_docs: int = 0

    # ---------- add documents ----------

    def add_text(self, doc_id: str, text: str, meta: DocMeta) -> None:
        if not text:
            return
        if doc_id in self.docs:
            # idempotent update: remove old postings first
            self._remove_doc_terms(doc_id)

        toks = tokenize(text)
        if not toks:
            return

        tf: Dict[str, int] = {}
        for t in toks:
            tf[t] = tf.get(t, 0) + 1

        # update inv + df
        for term, cnt in tf.items():
            bucket = self.inv.setdefault(term, {})
            bucket[doc_id] = cnt
            self.df[term] = len(bucket)

        self.docs[doc_id] = {
            "meta": meta,
            "len": len(toks),
            # keep original text for snippet extraction; you can drop this if size matters
            "text": text,
        }
        self.n_docs = len(self.docs)

    def add_file(self, path: Path, doc_id: str | None = None, title: str | None = None, tags: List[str] | None = None) -> Optional[str]:
        path = Path(path)
        if not path.is_file():
            return None
        text = path.read_text(encoding="utf-8", errors="ignore")
        h = sha256_of(text)
        stat = path.stat()
        doc_id = doc_id or str(path.resolve())

        # skip if unchanged
        prev = self.docs.get(doc_id)
        if prev:
            old_meta: DocMeta = prev["meta"]
            if old_meta.hash == h and old_meta.mtime == stat.st_mtime:
                return doc_id  # unchanged

        meta = DocMeta(
            doc_id=doc_id,
            source=str(path.resolve()),
            title=title or path.name,
            tags=tags,
            mtime=stat.st_mtime,
            hash=h,
        )
        self.add_text(doc_id, text, meta)
        return doc_id

    # ---------- build / scan ----------

    def build_from_folder(
        self,
        root: Path,
        include: Iterable[str] = ("*.txt", "*.md"),
        exclude: Iterable[str] = (".git/*",),
        recursive: bool = True,
    ) -> int:
        """
        Index all files under `root` matching any include pattern and not matching exclude.
        Returns number of files indexed or updated.
        """
        root = Path(root)
        if not root.exists():
            return 0

        count = 0
        paths = (root.rglob("*") if recursive else root.glob("*"))
        for p in paths:
            if not p.is_file():
                continue
            rel = str(p.relative_to(root).as_posix())
            if not any(fnmatch.fnmatch(rel, pat) for pat in include):
                continue
            if any(fnmatch.fnmatch(rel, pat) for pat in exclude):
                continue
            if self.add_file(p):
                count += 1
        return count

    # ---------- search ----------

    def search(self, query: str, k: int = 5) -> List[Hit]:
        q_toks = tokenize(query)
        if not q_toks or self.n_docs == 0:
            return []

        # compute query tf-idf (using binary or raw tf is fine; keep it simple)
        q_tf: Dict[str, int] = {}
        for t in q_toks:
            q_tf[t] = q_tf.get(t, 0) + 1

        # compute idf with +1 smoothing
        idf: Dict[str, float] = {}
        for t in q_tf:
            df = self.df.get(t, 0)
            idf[t] = math.log((1 + self.n_docs) / (1 + df)) + 1.0

        # accumulate scores: cosine-like with length norm
        scores: Dict[str, float] = {}
        doc_len_norm: Dict[str, float] = {}
        for term, qcnt in q_tf.items():
            postings = self.inv.get(term)
            if not postings:
                continue
            wq = (1 + math.log(qcnt)) * idf[term]  # log tf * idf
            for doc_id, dcnt in postings.items():
                wd = (1 + math.log(dcnt)) * idf[term]
                scores[doc_id] = scores.get(doc_id, 0.0) + (wq * wd)
                # cache norm
                if doc_id not in doc_len_norm:
                    L = max(1, self.docs[doc_id]["len"])
                    doc_len_norm[doc_id] = 1.0 / math.sqrt(L)

        # apply a gentle length normalization
        for d, s in list(scores.items()):
            scores[d] = s * doc_len_norm.get(d, 1.0)

        # rank and format
        ranked = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)[:k]
        hits: List[Hit] = []
        for doc_id, score in ranked:
            d = self.docs[doc_id]
            meta: DocMeta = d["meta"]
            snippet = make_snippet(d.get("text", ""), q_toks)
            hits.append(Hit(
                doc_id=doc_id,
                score=round(float(score), 4),
                source=meta.source,
                snippet=snippet,
                title=meta.title,
                tags=meta.tags,
            ))
        return hits

    # ---------- persistence ----------

    def save(self, path: Path) -> None:
        path = Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)
        # Store meta as dict to keep JSON serializable
        serial_docs = {
            doc_id: {
                "meta": asdict(d["meta"]),
                "len": d["len"],
                # store text to allow snippet generation after load (optional)
                "text": d.get("text", ""),
            }
            for doc_id, d in self.docs.items()
        }
        data = {
            "docs": serial_docs,
            "inv": self.inv,
            "df": self.df,
            "n_docs": self.n_docs,
            "saved_at": time.time(),
        }
        path.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")

    @classmethod
    def load(cls, path: Path) -> "TfidfIndex":
        path = Path(path)
        idx = cls()
        if not path.is_file():
            return idx
        data = json.loads(path.read_text(encoding="utf-8"))
        # reconstruct docs with DocMeta
        docs: Dict[str, Dict] = {}
        for doc_id, d in data.get("docs", {}).items():
            m = d.get("meta", {})
            meta = DocMeta(**m) if m else DocMeta(doc_id=doc_id, source="unknown")
            docs[doc_id] = {
                "meta": meta,
                "len": d.get("len", 0),
                "text": d.get("text", ""),
            }
        idx.docs = docs
        idx.inv = {t: {k: int(v) for k, v in postings.items()} for t, postings in data.get("inv", {}).items()}
        idx.df = {t: int(v) for t, v in data.get("df", {}).items()}
        idx.n_docs = int(data.get("n_docs", len(idx.docs)))
        return idx

    # ---------- internals ----------

    def _remove_doc_terms(self, doc_id: str) -> None:
        """Remove a document's postings before re-adding."""
        if doc_id not in self.docs:
            return
        # delete postings
        for term, postings in list(self.inv.items()):
            if doc_id in postings:
                postings.pop(doc_id, None)
                if postings:
                    self.df[term] = len(postings)
                else:
                    # remove empty term
                    self.inv.pop(term, None)
                    self.df.pop(term, None)
        # delete doc
        self.docs.pop(doc_id, None)
        self.n_docs = len(self.docs)


# -----------------------------
# Utilities
# -----------------------------

def sha256_of(text: str) -> str:
    return hashlib.sha256((text or "").encode("utf-8")).hexdigest()

def make_snippet(text: str, query_tokens: List[str], radius: int = 60) -> str:
    """
    Extract a tiny context window around the first matched token.
    """
    if not text:
        return ""
    low = text.lower()
    for qt in query_tokens:
        i = low.find(qt.lower())
        if i >= 0:
            start = max(0, i - radius)
            end = min(len(text), i + len(qt) + radius)
            snippet = text[start:end].replace("\n", " ").strip()
            if start > 0:
                snippet = "â€¦" + snippet
            if end < len(text):
                snippet = snippet + "â€¦"
            return snippet
    # fallback: beginning of the doc
    s = text[: 2 * radius].replace("\n", " ").strip()
    return (s + "â€¦") if len(text) > 2 * radius else s


# -----------------------------
# Convenience API (module-level)
# -----------------------------

DEFAULT_INDEX_PATH = Path("memory/rag/data/.index/tfidf_index.json")

def build_from_folder(
    root: str | Path,
    include: Iterable[str] = ("*.txt", "*.md"),
    exclude: Iterable[str] = (".git/*",),
    save_to: str | Path = DEFAULT_INDEX_PATH,
    recursive: bool = True,
) -> TfidfIndex:
    idx = TfidfIndex()
    idx.build_from_folder(Path(root), include=include, exclude=exclude, recursive=recursive)
    idx.save(Path(save_to))
    return idx

def load_index(path: str | Path = DEFAULT_INDEX_PATH) -> TfidfIndex:
    return TfidfIndex.load(Path(path))

def search(query: str, k: int = 5, path: str | Path = DEFAULT_INDEX_PATH) -> List[Hit]:
    idx = load_index(path)
    return idx.search(query, k=k)
\n================================================================================\nEND FILE: memory\rag\indexer.py\n================================================================================\n\n================================================================================\nBEGIN FILE: memory\rag\retriever.py\n================================================================================\n\n# /memory/rag/data/retriever.py
"""
Minimal RAG retriever that sits on top of the TF-IDF indexer.

Features
- Top-k document retrieval via indexer.search()
- Optional filters (tags, title substring)
- Passage extraction around query terms with overlap
- Lightweight proximity-based reranking of passages

No third-party dependencies; pairs with memory/rag/data/indexer.py.
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, Iterable, List, Optional, Tuple
from pathlib import Path
import math
import re

from .indexer import (
    load_index,
    search as index_search,
    DEFAULT_INDEX_PATH,
    tokenize,
    TfidfIndex,
    DocMeta,
)

# -----------------------------
# Public types
# -----------------------------

@dataclass(frozen=True)
class Passage:
    doc_id: str
    source: str
    title: Optional[str]
    tags: Optional[List[str]]
    score: float           # combined score (index score +/- rerank)
    start: int             # char start in original text
    end: int               # char end in original text
    text: str              # extracted passage
    snippet: str           # human-friendly short snippet (may equal text if short)


@dataclass(frozen=True)
class Filters:
    title_contains: Optional[str] = None        # case-insensitive containment
    require_tags: Optional[Iterable[str]] = None  # all tags must be present (AND)


# -----------------------------
# Retrieval API
# -----------------------------

def retrieve(
    query: str,
    k: int = 5,
    index_path: str | Path = DEFAULT_INDEX_PATH,
    filters: Optional[Filters] = None,
    passage_chars: int = 350,
    passage_overlap: int = 60,
    enable_rerank: bool = True,
) -> List[Passage]:
    """
    Retrieve top-k passages for a query.

    Steps:
      1. Run TF-IDF doc search
      2. Apply optional filters
      3. Extract a focused passage per doc
      4. (Optional) Rerank by term proximity within the passage
    """
    idx = load_index(index_path)
    if idx.n_docs == 0 or not query.strip():
        return []

    # initial doc hits
    hits = index_search(query, k=max(k * 3, k), path=index_path)  # overshoot; filter + rerank will trim

    # filter hits by title/tags if requested
    if filters:
        hits = _apply_filters(hits, idx, filters)

    # extract best passage per remaining doc
    q_tokens = tokenize(query)
    passages: List[Passage] = []
    for h in hits:
        doc = idx.docs.get(h.doc_id)
        if not doc:
            continue
        meta: DocMeta = doc["meta"]
        full_text: str = doc.get("text", "") or ""
        start, end, passage_text = _extract_passage(full_text, q_tokens, window=passage_chars, overlap=passage_overlap)
        snippet = passage_text if len(passage_text) <= 220 else passage_text[:220].rstrip() + "â€¦"
        passages.append(Passage(
            doc_id=h.doc_id,
            source=meta.source,
            title=meta.title,
            tags=meta.tags,
            score=float(h.score),  # base score from index
            start=start,
            end=end,
            text=passage_text,
            snippet=snippet,
        ))

    if not passages:
        return []

    # optional rerank by proximity of query terms inside the passage
    if enable_rerank:
        passages = _rerank_by_proximity(passages, q_tokens)

    # final top-k
    passages.sort(key=lambda p: p.score, reverse=True)
    return passages[:k]


def retrieve_texts(
    query: str,
    k: int = 5,
    **kwargs,
) -> List[str]:
    """
    Convenience: return only the passage texts for a query.
    """
    return [p.text for p in retrieve(query, k=k, **kwargs)]


# -----------------------------
# Internals
# -----------------------------

def _apply_filters(hits, idx: TfidfIndex, filters: Filters):
    out = []
    want_title = (filters.title_contains or "").strip().lower() or None
    want_tags = set(t.strip().lower() for t in (filters.require_tags or []) if str(t).strip())

    for h in hits:
        d = idx.docs.get(h.doc_id)
        if not d:
            continue
        meta: DocMeta = d["meta"]

        if want_title:
            t = (meta.title or "").lower()
            if want_title not in t:
                continue

        if want_tags:
            tags = set((meta.tags or []))
            tags = set(x.lower() for x in tags)
            if not want_tags.issubset(tags):
                continue

        out.append(h)
    return out


_WORD_RE = re.compile(r"[A-Za-z0-9']+")

def _find_all(term: str, text: str) -> List[int]:
    """Return starting indices of all case-insensitive matches of term in text."""
    if not term or not text:
        return []
    term_l = term.lower()
    low = text.lower()
    out: List[int] = []
    i = low.find(term_l)
    while i >= 0:
        out.append(i)
        i = low.find(term_l, i + 1)
    return out


def _extract_passage(text: str, q_tokens: List[str], window: int = 350, overlap: int = 60) -> Tuple[int, int, str]:
    """
    Pick a passage around the earliest match of any query token.
    If no match found, return the first window.
    """
    if not text:
        return 0, 0, ""

    low = text.lower()
    # choose the earliest hit among query tokens
    hit_positions: List[int] = []
    for qt in q_tokens:
        hit_positions.extend(_find_all(qt, text))
    start: int
    end: int

    if hit_positions:
        i = max(0, min(hit_positions) - overlap)
        start = i
        end = min(len(text), start + window)
    else:
        start = 0
        end = min(len(text), window)

    return start, end, text[start:end].strip()


def _rerank_by_proximity(passages: List[Passage], q_tokens: List[str]) -> List[Passage]:
    """
    Adjust scores based on how tightly query tokens cluster inside the passage.
    Heuristic:
      - For each unique query token, find all positions in the passage (word indices).
      - Compute average pairwise distance among the closest occurrences.
      - Convert to a bonus in [0, 0.25] and add to base score.
    """
    q_unique = [t for t in dict.fromkeys(q_tokens)]  # preserve order, dedupe
    if not q_unique:
        return passages

    def word_positions(text: str, term: str) -> List[int]:
        # word-level positions for term
        positions: List[int] = []
        words = [w.group(0).lower() for w in _WORD_RE.finditer(text)]
        for i, w in enumerate(words):
            if term == w:
                positions.append(i)
        return positions

    def proximity_bonus(p: Passage) -> float:
        # collect positions per term
        pos_lists = [word_positions(p.text, t) for t in q_unique]
        if all(len(ps) == 0 for ps in pos_lists):
            return 0.0

        # flatten a representative set of positions (closest aligned indices)
        reps: List[int] = []
        for ps in pos_lists:
            reps.append(ps[0] if ps else 999999)

        # average absolute distance to the median position
        med = sorted([x for x in reps if x != 999999])
        if not med:
            return 0.0
        mid = med[len(med) // 2]
        avg_dist = sum(abs((x if x != 999999 else mid) - mid) for x in reps) / max(1, len(reps))

        # squash distance â†’ bonus; closer = bigger bonus
        # dist 0 â†’ 0.25 bonus; dist 10+ â†’ ~0 bonus
        bonus = max(0.0, 0.25 * (1.0 - min(avg_dist, 10.0) / 10.0))
        return float(bonus)

    reranked: List[Passage] = []
    for p in passages:
        bonus = proximity_bonus(p)
        reranked.append(Passage(
            **{**p.__dict__, "score": p.score + bonus}
        ))
    return reranked


# -----------------------------
# CLI / quick test
# -----------------------------

if __name__ == "__main__":
    import sys
    q = " ".join(sys.argv[1:]) or "anonymous chatbot rules"
    out = retrieve(q, k=3)
    for i, p in enumerate(out, 1):
        print(f"[{i}] {p.score:.4f}  {p.title or '(untitled)'}  â€”  {p.source}")
        print("    ", (p.snippet.replace("\n", " ") if p.snippet else "")[:200])
\n================================================================================\nEND FILE: memory\rag\retriever.py\n================================================================================\n\n================================================================================\nBEGIN FILE: memory\sessions.py\n================================================================================\n\n# /memory/sessions.py
"""
Minimal session store for chat history + per-session data.

Features
- In-memory store with thread safety
- Create/get/update/delete sessions
- Append chat turns: ("user"| "bot", text)
- Optional TTL cleanup and max-history cap
- JSON persistence (save/load)
- Deterministic, dependency-free

Intended to interoperate with anon_bot and logged_in_bot:
  - History shape: List[Tuple[str, str]]  e.g., [("user","hi"), ("bot","hello")]
"""

from __future__ import annotations
from dataclasses import dataclass, asdict, field
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path
import time
import uuid
import json
import threading

History = List[Tuple[str, str]]  # [("user","..."), ("bot","...")]

# -----------------------------
# Data model
# -----------------------------

@dataclass
class Session:
    session_id: str
    user_id: Optional[str] = None
    created_at: float = field(default_factory=lambda: time.time())
    updated_at: float = field(default_factory=lambda: time.time())
    data: Dict[str, Any] = field(default_factory=dict)     # arbitrary per-session state
    history: History = field(default_factory=list)         # chat transcripts

    def to_dict(self) -> Dict[str, Any]:
        d = asdict(self)
        # dataclasses with tuples serialize fine, ensure tuples not lost if reloaded
        return d

    @staticmethod
    def from_dict(d: Dict[str, Any]) -> "Session":
        s = Session(
            session_id=d["session_id"],
            user_id=d.get("user_id"),
            created_at=float(d.get("created_at", time.time())),
            updated_at=float(d.get("updated_at", time.time())),
            data=dict(d.get("data", {})),
            history=[(str(who), str(text)) for who, text in d.get("history", [])],
        )
        return s


# -----------------------------
# Store
# -----------------------------

class SessionStore:
    """
    Thread-safe in-memory session registry with optional TTL and persistence.
    """

    def __init__(
        self,
        ttl_seconds: Optional[int] = 60 * 60,   # 1 hour default; set None to disable
        max_history: int = 200,                 # cap messages per session
    ) -> None:
        self._ttl = ttl_seconds
        self._max_history = max_history
        self._lock = threading.RLock()
        self._sessions: Dict[str, Session] = {}

    # ---- id helpers ----

    @staticmethod
    def new_id() -> str:
        return uuid.uuid4().hex

    # ---- CRUD ----

    def create(self, user_id: Optional[str] = None, session_id: Optional[str] = None) -> Session:
        with self._lock:
            sid = session_id or self.new_id()
            s = Session(session_id=sid, user_id=user_id)
            self._sessions[sid] = s
            return s

    def get(self, session_id: str, create_if_missing: bool = False, user_id: Optional[str] = None) -> Optional[Session]:
        with self._lock:
            s = self._sessions.get(session_id)
            if s is None and create_if_missing:
                s = self.create(user_id=user_id, session_id=session_id)
            return s

    def delete(self, session_id: str) -> bool:
        with self._lock:
            return self._sessions.pop(session_id, None) is not None

    def all_ids(self) -> List[str]:
        with self._lock:
            return list(self._sessions.keys())

    # ---- housekeeping ----

    def _expired(self, s: Session) -> bool:
        if self._ttl is None:
            return False
        return (time.time() - s.updated_at) > self._ttl

    def sweep(self) -> int:
        """
        Remove expired sessions. Returns number removed.
        """
        with self._lock:
            dead = [sid for sid, s in self._sessions.items() if self._expired(s)]
            for sid in dead:
                self._sessions.pop(sid, None)
            return len(dead)

    # ---- history ops ----

    def append_user(self, session_id: str, text: str) -> Session:
        return self._append(session_id, "user", text)

    def append_bot(self, session_id: str, text: str) -> Session:
        return self._append(session_id, "bot", text)

    def _append(self, session_id: str, who: str, text: str) -> Session:
        with self._lock:
            s = self._sessions.get(session_id)
            if s is None:
                s = self.create(session_id=session_id)
            s.history.append((who, text))
            if self._max_history and len(s.history) > self._max_history:
                # Keep most recent N entries
                s.history = s.history[-self._max_history :]
            s.updated_at = time.time()
            return s

    def get_history(self, session_id: str) -> History:
        with self._lock:
            s = self._sessions.get(session_id)
            return list(s.history) if s else []

    def clear_history(self, session_id: str) -> bool:
        with self._lock:
            s = self._sessions.get(session_id)
            if not s:
                return False
            s.history.clear()
            s.updated_at = time.time()
            return True

    # ---- key/value per-session data ----

    def set(self, session_id: str, key: str, value: Any) -> Session:
        with self._lock:
            s = self._sessions.get(session_id)
            if s is None:
                s = self.create(session_id=session_id)
            s.data[key] = value
            s.updated_at = time.time()
            return s

    def get_value(self, session_id: str, key: str, default: Any = None) -> Any:
        with self._lock:
            s = self._sessions.get(session_id)
            if not s:
                return default
            return s.data.get(key, default)

    def data_dict(self, session_id: str) -> Dict[str, Any]:
        with self._lock:
            s = self._sessions.get(session_id)
            return dict(s.data) if s else {}

    # ---- persistence ----

    def save(self, path: str | Path) -> None:
        p = Path(path)
        p.parent.mkdir(parents=True, exist_ok=True)
        with self._lock:
            payload = {
                "ttl_seconds": self._ttl,
                "max_history": self._max_history,
                "saved_at": time.time(),
                "sessions": {sid: s.to_dict() for sid, s in self._sessions.items()},
            }
        p.write_text(json.dumps(payload, ensure_ascii=False), encoding="utf-8")

    @classmethod
    def load(cls, path: str | Path) -> "SessionStore":
        p = Path(path)
        if not p.is_file():
            return cls()
        data = json.loads(p.read_text(encoding="utf-8"))
        store = cls(
            ttl_seconds=data.get("ttl_seconds"),
            max_history=int(data.get("max_history", 200)),
        )
        sessions = data.get("sessions", {})
        with store._lock:
            for sid, sd in sessions.items():
                store._sessions[sid] = Session.from_dict(sd)
        return store


# -----------------------------
# Module-level singleton (optional)
# -----------------------------

_default_store: Optional[SessionStore] = None

def get_store() -> SessionStore:
    global _default_store
    if _default_store is None:
        _default_store = SessionStore()
    return _default_store

def new_session(user_id: Optional[str] = None) -> Session:
    return get_store().create(user_id=user_id)

def append_user(session_id: str, text: str) -> Session:
    return get_store().append_user(session_id, text)

def append_bot(session_id: str, text: str) -> Session:
    return get_store().append_bot(session_id, text)

def history(session_id: str) -> History:
    return get_store().get_history(session_id)

def set_value(session_id: str, key: str, value: Any) -> Session:
    return get_store().set(session_id, key, value)

def get_value(session_id: str, key: str, default: Any = None) -> Any:
    return get_store().get_value(session_id, key, default)

def sweep() -> int:
    return get_store().sweep()
\n================================================================================\nEND FILE: memory\sessions.py\n================================================================================\n\n================================================================================\nBEGIN FILE: memory\store.py\n================================================================================\n\n# /memory/sessions.py

DB={}
\n================================================================================\nEND FILE: memory\store.py\n================================================================================\n\n================================================================================\nBEGIN FILE: nlu\pipeline.py\n================================================================================\n\n# /nlu/pipeline.py

def analyze(t): return {'intent':'general'}
\n================================================================================\nEND FILE: nlu\pipeline.py\n================================================================================\n\n================================================================================\nBEGIN FILE: nlu\prompts.py\n================================================================================\n\n# /nlu/prompts.py
\n================================================================================\nEND FILE: nlu\prompts.py\n================================================================================\n\n================================================================================\nBEGIN FILE: nlu\router.py\n================================================================================\n\n# /nlu/router.py
\n================================================================================\nEND FILE: nlu\router.py\n================================================================================\n\n================================================================================\nBEGIN FILE: notebooks\ChatbotIntegration.ipynb\n================================================================================\n\n# %% [code cell 1]\nfrom agenticcore.chatbot.services import ChatBot
bot = ChatBot()
print(bot.reply("Testing from notebook"))\n\n# %% [code cell 2]\nimport os

# Point to your FastAPI server (change if needed)
import os

# Default backend URL (can be overridden later via the widget)
BACKEND_URL = os.environ.get("BACKEND_URL", "http://127.0.0.1:8000")

# Provider hint (optional; providers_unified auto-detects if keys exist)
# Examples:
# os.environ["AI_PROVIDER"] = "hf"
# os.environ["HF_API_KEY"] = "hf_XXXXXXXX..."   # if using Hugging Face
# os.environ["MICROSOFT_AI_SERVICE_ENDPOINT"] = "https://<name>.cognitiveservices.azure.com/"
# os.environ["MICROSOFT_AI_API_KEY"] = "<your-azure-key>"

BACKEND_URL\n\n# %% [code cell 3]\nimport os
import json
import requests
from typing import Dict, Any

# Default backend URL
BACKEND_URL = os.environ.get("BACKEND_URL", "http://127.0.0.1:8000")

def send_via_api(message: str, url: str = BACKEND_URL) -> Dict[str, Any]:
    """POST to FastAPI /chatbot/message. Returns dict with reply/sentiment/confidence."""
    u = url.rstrip("/") + "/chatbot/message"
    r = requests.post(u, json={"message": message}, timeout=20)
    r.raise_for_status()
    return r.json()

def send_via_library(message: str) -> Dict[str, Any]:
    """Call ChatBot() directly inside this kernel."""
    from agenticcore.chatbot.services import ChatBot
    return ChatBot().reply(message)

def health(url: str = BACKEND_URL) -> Dict[str, Any]:
    r = requests.get(url.rstrip("/") + "/health", timeout=10)
    r.raise_for_status()
    return r.json()\n\n# %% [code cell 4]\nimport ipywidgets as W
from IPython.display import display, HTML, clear_output

mode = W.ToggleButtons(
    options=[("API", "api"), ("Library", "lib")],
    value="api",
    description="Route:",
)
backend = W.Text(value=BACKEND_URL, placeholder="http://127.0.0.1:8000", description="Backend:", layout=W.Layout(width="60%"))
save_btn = W.Button(description="Save", button_style="info")
msg = W.Text(placeholder="Type a messageâ€¦", description="You:", layout=W.Layout(width="60%"))
send_btn = W.Button(description="Send", button_style="primary")
cap_btn = W.Button(description="Capabilities", tooltip="Show ChatBot capabilities")
out = W.Output()

def on_save(_):
    os.environ["BACKEND_URL"] = backend.value.strip()
    with out:
        print(f"[config] BACKEND_URL = {os.environ['BACKEND_URL']}")

def on_send(_):
    text = msg.value.strip()
    if not text:
        with out:
            print("[warn] Please enter some text.")
        return
    try:
        if mode.value == "api":
            data = send_via_api(text, backend.value.strip())
        else:
            data = send_via_library(text)
        with out:
            print(json.dumps(data, indent=2, ensure_ascii=False))
    except Exception as e:
        with out:
            print(f"[error] {e}")

def on_caps(_):
    try:
        # Prefer library capabilities; keeps working even if API is down
        from agenticcore.chatbot.services import ChatBot
        data = ChatBot().capabilities()
        with out:
            print(json.dumps({"capabilities": data}, indent=2))
    except Exception as e:
        with out:
            print(f"[error capabilities] {e}")

save_btn.on_click(on_save)
send_btn.on_click(on_send)
cap_btn.on_click(on_caps)

display(W.HBox([mode, backend, save_btn]))
display(W.HBox([msg, send_btn, cap_btn]))
display(out)

# Optional visual hint
display(HTML("""
<div style="margin-top:8px;opacity:.8">
  Tip: API path requires your FastAPI server running at /chatbot/message.
  Switch to <b>Library</b> mode for offline tests.
</div>
"""))\n\n# %% [code cell 5]\nimport pandas as pd

tests = [
    "I absolutely love this project!",
    "This is awful and broken.",
    "Can you list your capabilities?",
    "",  # malformed/empty
]

rows = []
for t in tests:
    try:
        data = send_via_api(t, backend.value.strip()) if mode.value == "api" else send_via_library(t)
        rows.append({"message": t, **data})
    except Exception as e:
        rows.append({"message": t, "reply": f"(error) {e}", "sentiment": None, "confidence": None})

df = pd.DataFrame(rows)
df\n\n# %% [code cell 6]\ntry:
    print("Health:", health(backend.value.strip()))
except Exception as e:
    print("Health check failed:", e)

# Simple acceptance checks
sample = send_via_library("hello")
assert all(k in sample for k in ("reply", "sentiment", "confidence"))
print("Library OK:", sample)

sample_api = send_via_api("hello from api", backend.value.strip())
assert all(k in sample_api for k in ("reply", "sentiment", "confidence"))
print("API OK:", sample_api)\n\n# %% [code cell 7]\n\n\n# %% [code cell 8]\nimport requests, os, json
BACKEND_URL = os.environ.get("BACKEND_URL", "http://127.0.0.1:8000")
routes = requests.get(BACKEND_URL.rstrip("/") + "/openapi.json", timeout=10).json()["paths"]
print(json.dumps(list(routes.keys())[:20], indent=2))\n\n# %% [code cell 9]\nsend_via_api("hello from api", BACKEND_URL.strip())\n\n# %% [code cell 10]\nprint("Health:", health(BACKEND_URL))
sample = send_via_library("hello")
print("Library OK:", sample)

sample_api = send_via_api("hello from api", BACKEND_URL)
print("API OK:", sample_api)\n\n# %% [code cell 11]\n# Pick a clean port to avoid collisions (e.g., 8077)
uvicorn backend.app.main:app --reload --port 8077 --app-dir .\n\n# %% [code cell 12]\n\n\n# %% [code cell 13]\n\n\n# %% [code cell 14]\n\n\n# %% [code cell 15]\n\n\n================================================================================\nEND FILE: notebooks\ChatbotIntegration.ipynb\n================================================================================\n\n================================================================================\nBEGIN FILE: notebooks\SimpleTraditionalChatbot.ipynb\n================================================================================\n\n# %% [code cell 1]\nimport os
os.chdir(r"C:\Users\User\PortaeOS-skeleton\packages\agenticcore")  # <-- adjust to your repo root

# Python one-liner in the same env where the server runs
import sys; sys.path.insert(0,'.')
import backend.app.main as m
[(getattr(r,'path',None), getattr(r,'methods',None)) for r in m.app.routes]

# Expect to see ('/chatbot/message', {'POST'}) in the list\n\n# %% [code cell 2]\nimport requests, json, os
BASE = os.environ.get("BACKEND_URL","http://127.0.0.1:8000").rstrip("/")
print("Health:", requests.get(BASE+"/health").json())
r = requests.post(BASE+"/chatbot/message", json={"message":"hello via api"})
print("Reply:", r.status_code, r.json())\n\n# %% [code cell 3]\nfrom agenticcore.chatbot.services import ChatBot
print(ChatBot().reply("hello via library"))\n\n# %% [code cell 4]\n# Cell 1: config + helpers
import os, json, requests
BACKEND_URL = os.environ.get("BACKEND_URL", "http://127.0.0.1:8000").rstrip("/")

def health(url: str = BACKEND_URL): 
    r = requests.get(url + "/health", timeout=10); r.raise_for_status(); return r.json()

def send_via_api(message: str, url: str = BACKEND_URL):
    r = requests.post(url + "/chatbot/message", json={"message": message}, timeout=20)
    r.raise_for_status(); return r.json()

def send_via_library(message: str):
    from agenticcore.chatbot.services import ChatBot
    return ChatBot().reply(message)

print("BACKEND_URL =", BACKEND_URL)
print("Health:", health())\n\n# %% [code cell 5]\n# Cell 2: quick acceptance checks
lib = send_via_library("hello")
assert all(k in lib for k in ("reply","sentiment","confidence"))
print("Library OK:", lib)

api = send_via_api("hello from api")
assert all(k in api for k in ("reply","sentiment","confidence"))
print("API OK:", api)\n\n# %% [code cell 6]\n# Notebook Config
import os, json, requests
from typing import Dict, Any

BACKEND_URL = os.environ.get("BACKEND_URL", "http://127.0.0.1:8000").rstrip("/")

def health(url: str = BACKEND_URL) -> Dict[str, Any]:
    """GET /health to verify server is up."""
    r = requests.get(url + "/health", timeout=10)
    r.raise_for_status()
    return r.json()

def send_via_api(message: str, url: str = BACKEND_URL) -> Dict[str, Any]:
    """POST to FastAPI /chatbot/message. Returns reply/sentiment/confidence."""
    r = requests.post(url + "/chatbot/message", json={"message": message}, timeout=20)
    r.raise_for_status()
    return r.json()

def send_via_library(message: str) -> Dict[str, Any]:
    """Call ChatBot() directly (no server needed)."""
    from agenticcore.chatbot.services import ChatBot
    return ChatBot().reply(message)

print("BACKEND_URL =", BACKEND_URL)\n\n# %% [code cell 7]\nimport ipywidgets as W
from IPython.display import display, HTML

mode = W.ToggleButtons(options=[("API", "api"), ("Library", "lib")], value="api", description="Route:")
backend = W.Text(value=BACKEND_URL, description="Backend:", layout=W.Layout(width="60%"))
save_btn = W.Button(description="Save", button_style="info")
msg = W.Text(placeholder="Type a messageâ€¦", description="You:", layout=W.Layout(width="60%"))
send_btn = W.Button(description="Send", button_style="primary")
cap_btn = W.Button(description="Capabilities")
out = W.Output()

def on_save(_):
    os.environ["BACKEND_URL"] = backend.value.strip().rstrip("/")
    with out: print("[config] BACKEND_URL =", os.environ["BACKEND_URL"])

def on_send(_):
    text = msg.value.strip()
    if not text:
        with out: print("[warn] Please enter some text.")
        return
    try:
        data = send_via_api(text, backend.value.strip()) if mode.value == "api" else send_via_library(text)
        with out: print(json.dumps(data, indent=2, ensure_ascii=False))
    except Exception as e:
        with out: print(f"[error] {e}")

def on_caps(_):
    try:
        from agenticcore.chatbot.services import ChatBot
        with out: print(json.dumps({"capabilities": ChatBot().capabilities()}, indent=2))
    except Exception as e:
        with out: print(f"[error capabilities] {e}")

save_btn.on_click(on_save); send_btn.on_click(on_send); cap_btn.on_click(on_caps)

display(W.HBox([mode, backend, save_btn]))
display(W.HBox([msg, send_btn, cap_btn]))
display(out)
display(HTML('<div style="margin-top:8px;opacity:.8">Tip: ensure FastAPI exposes <code>/chatbot/message</code>. Switch to Library for offline tests.</div>'))\n\n# %% [code cell 8]\n# Backend health (if running)
try:
    print("Health:", health(backend.value.strip()))
except Exception as e:
    print("Health check failed:", e)

# Library path always available
sample = send_via_library("hello")
assert all(k in sample for k in ("reply", "sentiment", "confidence"))
print("Library OK:", sample)

# API path (requires uvicorn backend running)
try:
    sample_api = send_via_api("hello from api", backend.value.strip())
    assert all(k in sample_api for k in ("reply", "sentiment", "confidence"))
    print("API OK:", sample_api)
except Exception as e:
    print("API test failed (start uvicorn?):", e)\n\n# %% [code cell 9]\nfrom IPython.display import Markdown
Markdown("""
### What to capture for the report
- Screenshot of **/health** and a successful **/chatbot/message** call.
- Notebook output using **API** mode and **Library** mode.
- Short note: environment variables used (e.g., `MICROSOFT_AI_*`, `AI_PROVIDER`, `HF_API_KEY`).
- Brief discussion of any errors and fixes (e.g., route mounting, ports).
""")\n\n# %% [code cell 10]\n\n\n# %% [code cell 11]\n\n\n# %% [code cell 12]\n\n\n================================================================================\nEND FILE: notebooks\SimpleTraditionalChatbot.ipynb\n================================================================================\n\n================================================================================\nBEGIN FILE: pyproject.toml\n================================================================================\n\n# pyproject.toml
[tool.black]
line-length = 100
target-version = ["py310"]

[tool.isort]
profile = "black"

[tool.pytest.ini_options]
addopts = "-q"
\n================================================================================\nEND FILE: pyproject.toml\n================================================================================\n\n================================================================================\nBEGIN FILE: README.md\n================================================================================\n\n<!-- README.md -->
# Agentic-Chat-bot-
Agentic Chat-bot with RAG, Memory, and Privacy Considerations. 

# Storefront Chatbot

This repo follows a modular layout with a Gradio UI, NLU pipeline, anonymous and logged-in flows,
guardrails, and optional Azure sentiment.

## Quickstart
```bash
make dev
make run
# open http://localhost:7860
```

## Agentic Integration
- Core bot: `agenticcore/chatbot/services.py`
- Providers: `agenticcore/providers_unified.py`
- CLI: `python -m agenticcore.cli agentic "hello"` (loads .env)
- FastAPI demo: `uvicorn integrations.web.fastapi.web_agentic:app --reload`

## Added Samples & Tests
- chat.html â†’ `app/assets/html/chat.html`
- echo_bot.py â†’ `integrations/botframework/bots/echo_bot.py`
- ChatbotIntegration.ipynb â†’ `notebooks/ChatbotIntegration.ipynb`
- SimpleTraditionalChatbot.ipynb â†’ `notebooks/SimpleTraditionalChatbot.ipynb`
- smoke_test.py â†’ `tests/smoke_test.py`
- test_routes.py â†’ `tests/test_routes.py`
- quick_sanity.py â†’ `tools/quick_sanity.py`
- example.py â†’ `examples/example.py`
- service.py â†’ `samples/service.py`
- DEV_DOC.md â†’ `docs/DEV_DOC.md`

Run `pytest -q` for tests; open HTML in `app/assets/html/` to try local UIs.


---
This is the **unified** storefront-chatbot bundle.
Duplicates from earlier skeletons were removed; priority order was:
1) storefront_chatbot_final_bundle
2) storefront_chatbot_merged_with_agentic
3) storefront_chatbot_skeleton
\n================================================================================\nEND FILE: README.md\n================================================================================\n\n================================================================================\nBEGIN FILE: requirements.txt\n================================================================================\n\ngradio>=4.0
transformers>=4.41.0
torch>=2.2.0
scikit-learn>=1.3.0
pandas>=2.1.0
numpy>=1.26.0
pytest>=7.4.0
# Optional Azure
azure-ai-textanalytics>=5.3.0
python-dotenv>=1.0
fastapi>=0.115.0
uvicorn[standard]>=0.30.0
# Optional for Bot Framework sample:
# aiohttp>=3.9
# botbuilder-core>=4.14
\n================================================================================\nEND FILE: requirements.txt\n================================================================================\n\n================================================================================\nBEGIN FILE: samples\service.py\n================================================================================\n\n# /samples/services.py
import os
from typing import Dict, Any

# Use the unified provider layer (HF, Azure, OpenAI, Cohere, DeepAI, or offline)
from packages.agenticcore.agenticcore.providers_unified import analyze_sentiment, generate_text


class ChatBot:
    """
    Thin faÃ§ade over provider-agnostic functions.
    - Provider selection is automatic unless AI_PROVIDER is set (hf|azure|openai|cohere|deepai|offline).
    - Reply shape: {"reply": str, "sentiment": str, "confidence": float}
    """

    def __init__(self) -> None:
        # Optional: pin a provider via env; otherwise providers_unified auto-detects.
        self.provider = os.getenv("AI_PROVIDER") or "auto"

    def reply(self, message: str) -> Dict[str, Any]:
        msg = (message or "").strip()
        if not msg:
            return {"reply": "Please enter some text.", "sentiment": "unknown", "confidence": 0.0}

        if msg.lower() in {"help", "/help"}:
            return {
                "reply": self._help_text(),
                "capabilities": {
                    "system": "chatbot",
                    "mode": self.provider,
                    "features": ["text-input", "sentiment-analysis", "help"],
                    "commands": {"help": "Describe capabilities and usage."},
                },
            }

        s = analyze_sentiment(msg)  # -> {"provider","label","score",...}
        label = str(s.get("label", "neutral"))
        score = float(s.get("score", 0.5))

        # Keep the same phrasing used elsewhere so surfaces are consistent.
        reply = self._compose(label)
        return {"reply": reply, "sentiment": label, "confidence": round(score, 2)}

    @staticmethod
    def _compose(label: str) -> str:
        if label == "positive":
            return "Thanks for sharing. I detected a positive sentiment."
        if label == "negative":
            return "I hear your concern. I detected a negative sentiment."
        if label == "neutral":
            return "Noted. The sentiment appears neutral."
        if label == "mixed":
            return "Your message has mixed signals. Can you clarify?"
        return "I could not determine the sentiment. Please rephrase."

    @staticmethod
    def _help_text() -> str:
        return "I analyze sentiment and respond concisely. Send any text or type 'help'."
\n================================================================================\nEND FILE: samples\service.py\n================================================================================\n\n================================================================================\nBEGIN FILE: scripts\check_compliance.py\n================================================================================\n\n# /scripts/check_compliance.py

# Fails if disallowed deps appear (placeholder)
\n================================================================================\nEND FILE: scripts\check_compliance.py\n================================================================================\n\n================================================================================\nBEGIN FILE: scripts\run_local.sh\n================================================================================\n\n# /scripts/run_local.sh
#!/usr/bin/env bash
set -euo pipefail
export PYTHONPATH=.
python -c "from storefront_chatbot.app.app import build; build().launch(server_name='0.0.0.0', server_port=7860)"
\n================================================================================\nEND FILE: scripts\run_local.sh\n================================================================================\n\n================================================================================\nBEGIN FILE: scripts\seed_data.py\n================================================================================\n\n# /scripts/seed_data.py
# Load sample products/FAQs (placeholder)

\n================================================================================\nEND FILE: scripts\seed_data.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\smoke_test.py\n================================================================================\n\n# /test/smoke_test.py
import os, json, requests
from agenticcore.chatbot.services import ChatBot

def p(title, data): print(f"\n== {title} ==\n{json.dumps(data, indent=2)}")

bot = ChatBot()
p("Lib/Direct", bot.reply("I really love this"))

url = os.getenv("BACKEND_URL", "http://127.0.0.1:8000")
r = requests.get(f"{url}/health"); p("API/Health", r.json())
r = requests.post(f"{url}/chatbot/message", json={"message":"api path test"}); p("API/Chat", r.json())
\n================================================================================\nEND FILE: tests\smoke_test.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\test_anon_bot.py\n================================================================================\n\n# /test/test_anon_bot.py
def test_anon_stub(): assert True

\n================================================================================\nEND FILE: tests\test_anon_bot.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\test_guardrails.py\n================================================================================\n\n# /test/test_guardrails.py
def test_guardrails_stub(): assert True
\n================================================================================\nEND FILE: tests\test_guardrails.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\test_indexer.py\n================================================================================\n\n# /tests/test_indexer.py
from pathlib import Path
from memory.rag.data.indexer import TfidfIndex, search, DEFAULT_INDEX_PATH

def test_add_and_search(tmp_path: Path):
    p = tmp_path / "a.md"
    p.write_text("Hello world. This is an anonymous chatbot.\nRules are simple.", encoding="utf-8")
    idx = TfidfIndex()
    idx.add_file(p)
    hits = idx.search("anonymous rules", k=5)
    assert hits and hits[0].doc_id == str(p.resolve())

def test_persist_and_load(tmp_path: Path):
    p = tmp_path / "index.json"
    idx = TfidfIndex()
    idx.add_text("id1", "cats are great, dogs are cool", meta=__meta("id1"))
    idx.save(p)
    loaded = TfidfIndex.load(p)
    hits = loaded.search("dogs", k=1)
    assert hits and hits[0].doc_id == "id1"

def __meta(i: str):
    from memory.rag.data.indexer import DocMeta
    return DocMeta(doc_id=i, source="inline", title=i)
\n================================================================================\nEND FILE: tests\test_indexer.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\test_logged_in_bot.py\n================================================================================\n\n# /test/test_logged_in_bot.py
def test_logged_stub(): assert True
\n================================================================================\nEND FILE: tests\test_logged_in_bot.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\test_memory.py\n================================================================================\n\n# /test/test_memory.py
def test_memory_stub(): assert True
\n================================================================================\nEND FILE: tests\test_memory.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\test_nlu.py\n================================================================================\n\n# /test/test_nlu.py
def test_nlu_stub(): assert True
\n================================================================================\nEND FILE: tests\test_nlu.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\test_retriever.py\n================================================================================\n\n# tests/test_retriever.py
from pathlib import Path
from memory.rag.data.indexer import TfidfIndex, DocMeta
from memory.rag.data.retriever import retrieve, Filters

def _add(idx, did, text, title=None, tags=None):
    meta = DocMeta(doc_id=did, source="inline", title=title, tags=tags)
    idx.add_text(did, text, meta)

def test_retrieve_passage(tmp_path: Path, monkeypatch):
    # Build tiny in-memory index and save
    from memory.rag.data.indexer import DEFAULT_INDEX_PATH
    p = tmp_path / "idx.json"
    from memory.rag.data.indexer import TfidfIndex
    idx = TfidfIndex()
    _add(idx, "d1", "Rules for an anonymous chatbot are simple and fast.", title="Design", tags=["doc","slide"])
    _add(idx, "d2", "This document explains retrieval and index search.", title="RAG", tags=["doc"])
    idx.save(p)

    # Run retrieval against this saved index
    res = retrieve("anonymous chatbot rules", k=2, index_path=p)
    assert res and any("anonymous" in r.text.lower() for r in res)

def test_filters(tmp_path: Path):
    from memory.rag.data.indexer import TfidfIndex
    idx = TfidfIndex()
    _add(idx, "a", "hello world", title="Alpha", tags=["doc","slide"])
    _add(idx, "b", "hello world", title="Beta", tags=["doc"])
    p = tmp_path / "idx.json"
    idx.save(p)

    f = Filters(title_contains="alpha", require_tags=["doc","slide"])
    res = retrieve("hello", k=5, index_path=p, filters=f)
    assert len(res) == 1 and res[0].title == "Alpha"
\n================================================================================\nEND FILE: tests\test_retriever.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\test_routes.py\n================================================================================\n\n# /test/test_routes.py
def test_routes_mount():
    from backend.app.main import create_app
    app = create_app()
    paths = [getattr(r, "path", "") for r in app.routes]
    assert "/chatbot/message" in paths
    assert "/health" in paths
\n================================================================================\nEND FILE: tests\test_routes.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tests\test_sessions.py\n================================================================================\n\n# tests/test_sessions.py
from memory.sessions import SessionStore

def test_create_and_history():
    st = SessionStore(ttl_seconds=None, max_history=3)
    s = st.create(user_id="u1")
    st.append_user(s.session_id, "a")
    st.append_bot(s.session_id, "b")
    st.append_user(s.session_id, "c")
    st.append_bot(s.session_id, "d")  # caps to last 3
    h = st.get_history(s.session_id)
    assert h == [("bot","b"), ("user","c"), ("bot","d")]

def test_save_load(tmp_path):
    st = SessionStore(ttl_seconds=None)
    s = st.create()
    st.append_user(s.session_id, "hello")
    p = tmp_path / "sess.json"
    st.save(p)
    st2 = SessionStore.load(p)
    assert st2.get_history(s.session_id)[0] == ("user","hello")
\n================================================================================\nEND FILE: tests\test_sessions.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tools\quick_sanity.py\n================================================================================\n\n# tools/quick_sanity.py
"""
Tiny sanity test for MBF helpers. Run from repo root or set PYTHONPATH.
"""
import sys, os
# Add repo root so 'mbf_bot' is importable if running directly
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from mbf_bot.skills import reverse_text, capabilities, normalize

print("caps:", capabilities())
print("reverse:", reverse_text("hello"))
print("cmd:", normalize("  Help  "))
\n================================================================================\nEND FILE: tools\quick_sanity.py\n================================================================================\n\n================================================================================\nBEGIN FILE: tree.txt\n================================================================================\n\nC:\Users\User\Agentic-Chat-bot-
â”œâ”€â”€ agenticcore
â”‚   â”œâ”€â”€ chatbot
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ services.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ providers_unified.py
â”‚   â””â”€â”€ web_agentic.py
â”œâ”€â”€ anon_bot
â”‚   â”œâ”€â”€ handler.py
â”‚   â””â”€â”€ rules.py
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ app
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”œâ”€â”€ assets
â”‚   â”‚   â””â”€â”€ html
â”‚   â”‚       â”œâ”€â”€ agenticcore_frontend.html
â”‚   â”‚       â”œâ”€â”€ chat.html
â”‚   â”‚       â”œâ”€â”€ chat_console.html
â”‚   â”‚       â””â”€â”€ chat_minimal.html
â”‚   â”œâ”€â”€ components
â”‚   â”œâ”€â”€ mbf_bot
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bot.py
â”‚   â”‚   â””â”€â”€ skills.py
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ routes.py
â”œâ”€â”€ core
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ logging.py
â”‚   â””â”€â”€ types.py
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ slides
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ design.md
â”‚   â”œâ”€â”€ DEV_DOC.md
â”‚   â”œâ”€â”€ flowchart.png
â”‚   â””â”€â”€ results.md
â”œâ”€â”€ examples
â”‚   â””â”€â”€ example.py
â”œâ”€â”€ guardrails
â”‚   â”œâ”€â”€ pii_redaction.py
â”‚   â””â”€â”€ safety.py
â”œâ”€â”€ integrations
â”‚   â”œâ”€â”€ azure
â”‚   â”‚   â””â”€â”€ bot_framework.py
â”‚   â”œâ”€â”€ botframework
â”‚   â”‚   â”œâ”€â”€ bots
â”‚   â”‚   â”‚   â””â”€â”€ echo_bot.py
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ bot.py
â”‚   â”œâ”€â”€ email
â”‚   â”‚   â””â”€â”€ ticket_stub.py
â”‚   â””â”€â”€ web
â”‚       â””â”€â”€ fastapi
â”‚           â””â”€â”€ web_agentic.py
â”œâ”€â”€ logged_in_bot
â”‚   â”œâ”€â”€ handler.py
â”‚   â”œâ”€â”€ sentiment_azure.py
â”‚   â””â”€â”€ tools.py
â”œâ”€â”€ memory
â”‚   â”œâ”€â”€ rag
â”‚   â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ indexer.py
â”‚   â”‚   â””â”€â”€ retriever.py
â”‚   â”œâ”€â”€ sessions.py
â”‚   â””â”€â”€ store.py
â”œâ”€â”€ nlu
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â””â”€â”€ router.py
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ ChatbotIntegration.ipynb
â”‚   â””â”€â”€ SimpleTraditionalChatbot.ipynb
â”œâ”€â”€ samples
â”‚   â””â”€â”€ service.py
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ check_compliance.py
â”‚   â”œâ”€â”€ run_local.sh
â”‚   â””â”€â”€ seed_data.py
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ smoke_test.py
â”‚   â”œâ”€â”€ test_anon_bot.py
â”‚   â”œâ”€â”€ test_guardrails.py
â”‚   â”œâ”€â”€ test_logged_in_bot.py
â”‚   â”œâ”€â”€ test_memory.py
â”‚   â”œâ”€â”€ test_nlu.py
â”‚   â””â”€â”€ test_routes.py
â”œâ”€â”€ tools
â”‚   â””â”€â”€ quick_sanity.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ app.zip
â”œâ”€â”€ flat_tree_filter.py
â”œâ”€â”€ FLATTENED_CODE.txt
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ tree.txt
â””â”€â”€ tree_filter.py
\n================================================================================\nEND FILE: tree.txt\n================================================================================\n\n================================================================================\nBEGIN FILE: tree_filter.py\n================================================================================\n\n#!/usr/bin/env python3
r"""
Write a tree view of a folder to a file.

Usage:
  python tree.py             # current folder -> tree.txt
  python tree.py C:\proj -o proj-tree.txt
  python tree.py . --max-depth 3
"""

import os, argparse, fnmatch

EXCLUDE_DIRS = {
    ".git", ".hg", ".svn", "__pycache__", "node_modules",
    ".venv", "venv", "env", "dist", "build",
    "artifacts", "logs", ".idea", ".vscode", ".pytest_cache",
    ".mypy_cache", ".ruff_cache", ".tox", ".nox", ".hypothesis",
    ".cache", ".gradle", ".parcel-cache", ".next", ".turbo",
    ".pnpm-store", ".yarn", ".yarn/cache", ".nuxt", ".svelte-kit",
}

EXCLUDE_FILES = {".DS_Store", "Thumbs.db", ".coverage", ".python-version"}

EXCLUDE_GLOBS = [
    "*.log", "*.tmp", "*.temp", "*.bak", "*.swp", "*.swo",
    "*.pyc", "*.pyo", "*.pyd", "*.class",
    "*.lock", "*.pid",
    "*.egg-info", "*.eggs",
    "*.sqlite", "*.sqlite3", "*.db", "*.pkl",
    ".env", ".env.*",
]


def _entries_sorted(path, exclude_dirs=None, exclude_files=None, exclude_globs=None):
    exclude_dirs = set(EXCLUDE_DIRS if exclude_dirs is None else exclude_dirs)
    exclude_files = set(EXCLUDE_FILES if exclude_files is None else exclude_files)
    exclude_globs = list(EXCLUDE_GLOBS if exclude_globs is None else exclude_globs)
    try:
        with os.scandir(path) as it:
            items = []
            for e in it:
                name = e.name
                if name in exclude_files:
                    continue
                if any(fnmatch.fnmatch(name, pat) for pat in exclude_globs):
                    continue
                if e.is_dir(follow_symlinks=False) and name in exclude_dirs:
                    continue
                items.append(e)
    except PermissionError:
        return []
    items.sort(key=lambda e: (not e.is_dir(follow_symlinks=False), e.name.lower()))
    return items


def _draw(root, out, max_depth=None, follow_symlinks=False, prefix="", exclude_dirs=None, exclude_files=None, exclude_globs=None):
    if max_depth is not None and max_depth < 0:
        return
    items = _entries_sorted(root, exclude_dirs=exclude_dirs, exclude_files=exclude_files, exclude_globs=exclude_globs)
    for i, e in enumerate(items):
        last = (i == len(items) - 1)
        connector = "â””â”€â”€ " if last else "â”œâ”€â”€ "
        line = f"{prefix}{connector}{e.name}"
        if e.is_symlink():
            try:
                line += f" -> {os.readlink(e.path)}"
            except OSError:
                pass
        print(line, file=out)
        if e.is_dir(follow_symlinks=follow_symlinks):
            new_prefix = prefix + ("    " if last else "â”‚   ")
            next_depth = None if max_depth is None else max_depth - 1
            if next_depth is None or next_depth >= 0:
                _draw(e.path, out, next_depth, follow_symlinks, new_prefix, exclude_dirs, exclude_files, exclude_globs)


def main():
    ap = argparse.ArgumentParser(description="Print a folder tree to a file.")
    ap.add_argument("path", nargs="?", default=".", help="Root folder (default: .)")
    ap.add_argument("-o", "--out", default="tree.txt", help="Output file (default: tree.txt)")
    ap.add_argument("--max-depth", type=int, help="Limit recursion depth")
    ap.add_argument("--follow-symlinks", action="store_true", help="Recurse into symlinked dirs")
    ap.add_argument("--exclude-dirs", default="", help="Comma-separated dir names to exclude (in addition to defaults).")
    ap.add_argument("--exclude-files", default="", help="Comma-separated file names to exclude (in addition to defaults).")
    ap.add_argument("--exclude-globs", default="", help="Comma-separated glob patterns to exclude (e.g. *.log,*.tmp,.env,.env.*).")
    args = ap.parse_args()

    # Merge defaults with CLI-specified excludes
    exclude_dirs = set(EXCLUDE_DIRS)
    if args.exclude_dirs:
        exclude_dirs |= {d.strip() for d in args.exclude_dirs.split(",") if d.strip()}
    exclude_files = set(EXCLUDE_FILES)
    if args.exclude_files:
        exclude_files |= {f.strip() for f in args.exclude_files.split(",") if f.strip()}
    exclude_globs = list(EXCLUDE_GLOBS)
    if args.exclude_globs:
        exclude_globs += [g.strip() for g in args.exclude_globs.split(",") if g.strip()]

    root = os.path.abspath(args.path)
    with open(args.out, "w", encoding="utf-8") as f:
        print(root, file=f)
        _draw(root, f, args.max_depth, args.follow_symlinks, "", exclude_dirs, exclude_files, exclude_globs)

    print(f"Wrote {args.out}")


if __name__ == "__main__":
    main()
\n================================================================================\nEND FILE: tree_filter.py\n================================================================================\n